{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5821a2-eb84-41d4-81e6-9bb91153e010",
   "metadata": {},
   "source": [
    "# Retrieve Graph\n",
    "\n",
    "#### Node Dictionaries\n",
    "+ track_dict\n",
    "+ playlist_dict\n",
    "\n",
    "#### Edge Dictionaries\n",
    "+ shared_album_edges\n",
    "+ shared_artist_edges\n",
    "+ shared_genre_edges\n",
    "+ cosine_similarity_edges\n",
    "+ contains_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700e65e6-7612-44b2-878f-da250644ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "uri = \"...\"\n",
    "username = \"...\"\n",
    "password = \"...\"\n",
    "graph = Graph(uri, auth=(username, password))\n",
    "\n",
    "# Retrieve track nodes and their properties\n",
    "track_query = '''\n",
    "MATCH (t:Track)\n",
    "RETURN t.acousticness, t.album_id, t.artist_ids, t.danceability, t.duration_ms, t.energy, t.explicit,\n",
    "       t.genre, t.id, t.key, t.liveness, t.loudness, t.mode, t.popularity, t.speechiness, t.tempo, t.valence\n",
    "'''\n",
    "\n",
    "track_result = graph.run(track_query).data()\n",
    "\n",
    "# Create dictionary for tracks\n",
    "track_dict = {row['t.id']: {\n",
    "    'acousticness': row['t.acousticness'],\n",
    "    'album_id': row['t.album_id'],\n",
    "    'artist_ids': row['t.artist_ids'],\n",
    "    'danceability': row['t.danceability'],\n",
    "    'duration_ms': row['t.duration_ms'],\n",
    "    'energy': row['t.energy'],\n",
    "    'explicit': row['t.explicit'],\n",
    "    'genre': row['t.genre'],\n",
    "    'key': row['t.key'],\n",
    "    'liveness': row['t.liveness'],\n",
    "    'loudness': row['t.loudness'],\n",
    "    'mode': row['t.mode'],\n",
    "    'popularity': row['t.popularity'],\n",
    "    'speechiness': row['t.speechiness'],\n",
    "    'tempo': row['t.tempo'],\n",
    "    'valence': row['t.valence'],\n",
    "} for row in track_result}\n",
    "\n",
    "# Retrieve playlist nodes and their properties\n",
    "playlist_query = '''\n",
    "MATCH (p:Playlist)\n",
    "RETURN p.playlist_id, p.tracklist\n",
    "'''\n",
    "\n",
    "playlist_result = graph.run(playlist_query).data()\n",
    "\n",
    "# Create dictionary playlists\n",
    "playlist_dict = {row['p.playlist_id']: row['p.tracklist'] for row in playlist_result}\n",
    "\n",
    "# Create defaultdicts for relationships\n",
    "shared_album_edges = defaultdict(list)\n",
    "shared_artist_edges = defaultdict(list)\n",
    "shared_genre_edges = defaultdict(list)\n",
    "cosine_similarity_edges = defaultdict(list)\n",
    "contains_edges = defaultdict(list)\n",
    "\n",
    "# Retrieve SHARED_ALBUM relationships\n",
    "shared_album_query = '''\n",
    "MATCH (t1:Track)-[:SHARED_ALBUM]->(t2:Track)\n",
    "RETURN t1.id, t2.id\n",
    "'''\n",
    "shared_album_result = graph.run(shared_album_query).data()\n",
    "\n",
    "for row in shared_album_result:\n",
    "    track1_id, track2_id = row['t1.id'], row['t2.id']\n",
    "    shared_album_edges[track1_id].append(track2_id)\n",
    "    shared_album_edges[track2_id].append(track1_id)\n",
    "\n",
    "# Retrieve SHARED_ARTIST relationships\n",
    "shared_artist_query = '''\n",
    "MATCH (t1:Track)-[:SHARED_ARTIST]->(t2:Track)\n",
    "RETURN t1.id, t2.id\n",
    "'''\n",
    "shared_artist_result = graph.run(shared_artist_query).data()\n",
    "\n",
    "for row in shared_artist_result:\n",
    "    track1_id, track2_id = row['t1.id'], row['t2.id']\n",
    "    shared_artist_edges[track1_id].append(track2_id)\n",
    "    shared_artist_edges[track2_id].append(track1_id)\n",
    "\n",
    "# Retrieve SHARED_GENRE relationships\n",
    "shared_genre_query = '''\n",
    "MATCH (t1:Track)-[:SHARED_GENRE]->(t2:Track)\n",
    "RETURN t1.id, t2.id\n",
    "'''\n",
    "shared_genre_result = graph.run(shared_genre_query).data()\n",
    "\n",
    "for row in shared_genre_result:\n",
    "    track1_id, track2_id = row['t1.id'], row['t2.id']\n",
    "    shared_genre_edges[track1_id].append(track2_id)\n",
    "    shared_genre_edges[track2_id].append(track1_id)\n",
    "    \n",
    "# Retrieve COSINE_SIMILARITY relationships\n",
    "cosine_similarity_query = '''\n",
    "MATCH (t1:Track)-[r:COSINE_SIMILARITY]->(t2:Track)\n",
    "RETURN t1.id, t2.id, r.value\n",
    "'''\n",
    "cosine_similarity_result = graph.run(cosine_similarity_query).data()\n",
    "\n",
    "for row in cosine_similarity_result:\n",
    "    track1_id, track2_id, similarity = row['t1.id'], row['t2.id'], row['r.value']\n",
    "    cosine_similarity_edges[track1_id].append(track2_id)\n",
    "    cosine_similarity_edges[track2_id].append(track1_id)\n",
    "\n",
    "# Retrieve CONTAINS relationships\n",
    "contains_query = '''\n",
    "MATCH (p:Playlist)-[:CONTAINS]->(t:Track)\n",
    "RETURN p.playlist_id, t.id\n",
    "'''\n",
    "contains_result = graph.run(contains_query).data()\n",
    "\n",
    "for row in contains_result:\n",
    "    playlist_id, track_id = row['p.playlist_id'], row['t.id']\n",
    "    contains_edges[playlist_id].append(track_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a2b0f-e812-4a37-ac66-525546a8edc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe158dd7-b9ad-4c3f-bf94-46b5af815ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "# Get unique track IDs\n",
    "unique_track_ids = list(track_dict.keys())\n",
    "\n",
    "# Create a track ID to index mapping\n",
    "track_id_to_index = {track_id: index for index, track_id in enumerate(unique_track_ids)}\n",
    "\n",
    "#print(track_id_to_index)\n",
    "\n",
    "# Get unique playlist IDs\n",
    "unique_playlist_ids = list(playlist_dict.keys())\n",
    "\n",
    "# Create a playlist ID to index mapping\n",
    "playlist_id_to_index = {playlist_id: index for index, playlist_id in enumerate(unique_playlist_ids)}\n",
    "\n",
    "#print(playlist_id_to_index)\n",
    "\n",
    "# Create adjacency matrices for each relationship\n",
    "n_tracks = len(unique_track_ids)\n",
    "shared_album_adj = lil_matrix((n_tracks, n_tracks), dtype=np.float32)\n",
    "shared_artist_adj = lil_matrix((n_tracks, n_tracks), dtype=np.float32)\n",
    "shared_genre_adj = lil_matrix((n_tracks, n_tracks), dtype=np.float32)\n",
    "cosine_similarity_adj = lil_matrix((n_tracks, n_tracks), dtype=np.float32)\n",
    "\n",
    "# Fill in the shared_album_adj matrix\n",
    "for track_id, connected_track_ids in shared_album_edges.items():\n",
    "    track_index = track_id_to_index[track_id]\n",
    "    for connected_track_id in connected_track_ids:\n",
    "        connected_track_index = track_id_to_index[connected_track_id]\n",
    "        shared_album_adj[track_index, connected_track_index] = .25\n",
    "\n",
    "# Fill in the shared_artist_adj matrix\n",
    "for track_id, connected_track_ids in shared_artist_edges.items():\n",
    "    track_index = track_id_to_index[track_id]\n",
    "    for connected_track_id in connected_track_ids:\n",
    "        connected_track_index = track_id_to_index[connected_track_id]\n",
    "        shared_artist_adj[track_index, connected_track_index] = .25\n",
    "\n",
    "# Fill in the shared_genre_adj matrix\n",
    "for track_id, connected_track_ids in shared_genre_edges.items():\n",
    "    track_index = track_id_to_index[track_id]\n",
    "    for connected_track_id in connected_track_ids:\n",
    "        connected_track_index = track_id_to_index[connected_track_id]\n",
    "        shared_genre_adj[track_index, connected_track_index] = .5\n",
    "\n",
    "# Fill in the cosine_similarity_adj matrix\n",
    "for track_id, connected_track_tuples in cosine_similarity_edges.items():\n",
    "    track_index = track_id_to_index[track_id]\n",
    "    for connected_track_id in connected_track_tuples:\n",
    "        connected_track_index = track_id_to_index[connected_track_id]\n",
    "        cosine_similarity_adj[track_index, connected_track_index] = .95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade80f53-a695-40fc-ae74-3a199740ddf3",
   "metadata": {},
   "source": [
    "# KGAT Model Implementation: PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe7ef27-4ed3-45d7-945a-9bb5654a3cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "class KGATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(KGATLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        #self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features) * 0.1)  # multiply by 0.1 to increase values\n",
    "        self.reset_parameters()\n",
    "\n",
    "#    def reset_parameters(self):\n",
    "#        gain = nn.init.calculate_gain('relu') * math.sqrt(3)\n",
    "#        nn.init.uniform_(self.weight, -10, 10)\n",
    "#        self.weight.data.mul_(gain)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        #print(self.weight)\n",
    "        #nn.Parameter(torch.randn(11, out_features) * 0.1)  # multiply by 0.1 to increase values\n",
    "        nn.init.kaiming_uniform_(self.weight, mode='fan_in', nonlinearity='relu')\n",
    "        #print(self.weight)\n",
    "\n",
    "    def forward(self, adjacency_matrix, input_features):\n",
    "        output_features = torch.mm(input_features, self.weight)\n",
    "        return torch.mm(adjacency_matrix, output_features)\n",
    "\n",
    "class KGAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_layers):\n",
    "        super(KGAT, self).__init__()\n",
    "        self.input_bn = nn.BatchNorm1d(hidden_features)\n",
    "        self.hidden_bns = nn.ModuleList([nn.BatchNorm1d(hidden_features) for _ in range(num_layers - 1)])\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the input layer\n",
    "        self.input_layer = KGATLayer(in_features, hidden_features)\n",
    "\n",
    "        # Define the hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.hidden_layers.append(KGATLayer(hidden_features, hidden_features))\n",
    "\n",
    "        # Define the output layer\n",
    "        self.output_layer = KGATLayer(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, adjacency_matrix, input_features):\n",
    "        x = self.input_layer(adjacency_matrix, input_features)\n",
    "        x = x.unsqueeze(2)  # Add an extra dimension for Batch Normalization\n",
    "        x = F.relu(self.input_bn(x))\n",
    "        x = x.squeeze(2)  # Remove the extra dimension\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            x = layer(adjacency_matrix, x)\n",
    "            x = x.unsqueeze(2)  # Add an extra dimension for Batch Normalization\n",
    "            x = F.relu(self.hidden_bns[i](x))\n",
    "            x = x.squeeze(2)  # Remove the extra dimension\n",
    "\n",
    "        # Pass through the output layer\n",
    "        x = self.output_layer(adjacency_matrix, x)\n",
    "\n",
    "        return x        \n",
    "\n",
    "hidden_features = 64  # Number of hidden features in the KGAT model\n",
    "out_features = 1  # Number of output features in the KGAT model\n",
    "num_layers = 2  # Number of layers in the KGAT model\n",
    "\n",
    "numeric_keys = [\n",
    "    'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    "    'liveness', 'loudness', 'popularity', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "\n",
    "model = KGAT(num_layers=num_layers, in_features=len(numeric_keys), hidden_features=hidden_features, out_features=out_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98fa381-2149-41cd-88cb-e649cec5e601",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53d43fe4-0cb8-43a0-812e-d5a21b1193dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "contains_edges_flat = [(playlist_id, track_id) for playlist_id, track_ids in contains_edges.items() for track_id in track_ids]\n",
    "train_edges, val_edges = train_test_split(contains_edges_flat, test_size=0.2, random_state=42)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, edges, playlist_id_to_index, track_id_to_index):\n",
    "        self.edges = edges\n",
    "        self.playlist_id_to_index = playlist_id_to_index\n",
    "        self.track_id_to_index = track_id_to_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edges)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        playlist_id, track_id = self.edges[idx]\n",
    "        playlist_index = self.playlist_id_to_index[playlist_id]\n",
    "        track_index = self.track_id_to_index[track_id]\n",
    "        return playlist_index, track_index\n",
    "\n",
    "train_dataset = MusicDataset(train_edges, playlist_id_to_index, track_id_to_index)\n",
    "val_dataset = MusicDataset(val_edges, playlist_id_to_index, track_id_to_index)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss with logits for link prediction\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Adam optimizer with a learning rate of 'lr'\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0002, momentum=0.90)\n",
    "num_epochs = 50\n",
    "\n",
    "# Convert adjacency matrices to PyTorch tensors\n",
    "shared_album_adj_tensor = torch.FloatTensor(shared_album_adj.toarray())\n",
    "shared_artist_adj_tensor = torch.FloatTensor(shared_artist_adj.toarray())\n",
    "shared_genre_adj_tensor = torch.FloatTensor(shared_genre_adj.toarray())\n",
    "cosine_similarity_adj_tensor = torch.FloatTensor(cosine_similarity_adj.toarray())\n",
    "\n",
    "# Function to handle tensor conversion for either array or string values\n",
    "def process_feature(feature):\n",
    "    if isinstance(feature, (list, tuple, np.ndarray)):\n",
    "        return np.array(feature, dtype=np.float32)\n",
    "    else:\n",
    "        return np.float32(feature)\n",
    "\n",
    "# Convert track features to PyTorch tensor\n",
    "track_features = torch.FloatTensor([[process_feature(track_dict[track_id][key]) for key in numeric_keys] for track_id in unique_track_ids])\n",
    "\n",
    "# Set device to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model and data to the selected device\n",
    "model = model.to(device)\n",
    "shared_album_adj_tensor = shared_album_adj_tensor.to(device)\n",
    "shared_artist_adj_tensor = shared_artist_adj_tensor.to(device)\n",
    "shared_genre_adj_tensor = shared_genre_adj_tensor.to(device)\n",
    "cosine_similarity_adj_tensor = cosine_similarity_adj_tensor.to(device)\n",
    "track_features = track_features.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f722cdc-99ad-40bb-8a3f-43dfd1541702",
   "metadata": {},
   "source": [
    "# Train KGAT Model\n",
    "\n",
    "vanishing gradient problem in training this model.\n",
    "\n",
    "Weights are initialized, but after passing each batch through the training loop the weights are equal to zero for the input layer, hidden layer, and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaf7301-56cc-44b4-aef3-528a445ed900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Batch [1/184], Gradient of input_bn.weight: -3.808236215263605e-08\n",
      "Epoch [1/50], Batch [1/184], Gradient of input_bn.bias: -0.000841515779029578\n",
      "Epoch [1/50], Batch [1/184], Gradient of hidden_bns.0.weight: 0.00025379256112501025\n",
      "Epoch [1/50], Batch [1/184], Gradient of hidden_bns.0.bias: 0.0005878241499885917\n",
      "Epoch [1/50], Batch [1/184], Gradient of input_layer.weight: 8.912380508263595e-06\n",
      "Epoch [1/50], Batch [1/184], Gradient of hidden_layers.0.weight: -0.0007725466275587678\n",
      "Epoch [1/50], Batch [1/184], Gradient of output_layer.weight: 0.0027055959217250347\n",
      "Epoch [1/50], Batch [2/184], Gradient of input_bn.weight: -1.4295801520347595e-07\n",
      "Epoch [1/50], Batch [2/184], Gradient of input_bn.bias: -0.00036191369872540236\n",
      "Epoch [1/50], Batch [2/184], Gradient of hidden_bns.0.weight: 0.0002734675072133541\n",
      "Epoch [1/50], Batch [2/184], Gradient of hidden_bns.0.bias: 0.0007899461779743433\n",
      "Epoch [1/50], Batch [2/184], Gradient of input_layer.weight: -1.3507545190805104e-05\n",
      "Epoch [1/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.00036411365726962686\n",
      "Epoch [1/50], Batch [2/184], Gradient of output_layer.weight: 0.012581822462379932\n",
      "Epoch [1/50], Batch [3/184], Gradient of input_bn.weight: -1.5133991837501526e-09\n",
      "Epoch [1/50], Batch [3/184], Gradient of input_bn.bias: -0.00025390752125531435\n",
      "Epoch [1/50], Batch [3/184], Gradient of hidden_bns.0.weight: 0.00035794050199911\n",
      "Epoch [1/50], Batch [3/184], Gradient of hidden_bns.0.bias: 0.0016133780591189861\n",
      "Epoch [1/50], Batch [3/184], Gradient of input_layer.weight: -7.632388587808236e-06\n",
      "Epoch [1/50], Batch [3/184], Gradient of hidden_layers.0.weight: 0.0006765285506844521\n",
      "Epoch [1/50], Batch [3/184], Gradient of output_layer.weight: 0.004203770775347948\n",
      "Epoch [1/50], Batch [101/184], Gradient of input_bn.weight: 7.270245987456292e-07\n",
      "Epoch [1/50], Batch [101/184], Gradient of input_bn.bias: -9.359575051348656e-05\n",
      "Epoch [1/50], Batch [101/184], Gradient of hidden_bns.0.weight: 5.959700501989573e-05\n",
      "Epoch [1/50], Batch [101/184], Gradient of hidden_bns.0.bias: 0.0004287094925530255\n",
      "Epoch [1/50], Batch [101/184], Gradient of input_layer.weight: -7.02898219628878e-08\n",
      "Epoch [1/50], Batch [101/184], Gradient of hidden_layers.0.weight: -3.124036084045656e-05\n",
      "Epoch [1/50], Batch [101/184], Gradient of output_layer.weight: 0.0013966968981549144\n",
      "Epoch [1/50], Batch [102/184], Gradient of input_bn.weight: 9.837112884270027e-07\n",
      "Epoch [1/50], Batch [102/184], Gradient of input_bn.bias: -7.520031795138493e-05\n",
      "Epoch [1/50], Batch [102/184], Gradient of hidden_bns.0.weight: 3.955892316298559e-05\n",
      "Epoch [1/50], Batch [102/184], Gradient of hidden_bns.0.bias: 0.00011352379806339741\n",
      "Epoch [1/50], Batch [102/184], Gradient of input_layer.weight: -1.6796622759329694e-08\n",
      "Epoch [1/50], Batch [102/184], Gradient of hidden_layers.0.weight: -4.769630322698504e-05\n",
      "Epoch [1/50], Batch [102/184], Gradient of output_layer.weight: 0.001309688319452107\n",
      "Epoch [1/50], Batch [103/184], Gradient of input_bn.weight: 7.750682016194332e-07\n",
      "Epoch [1/50], Batch [103/184], Gradient of input_bn.bias: 1.0850133548956364e-05\n",
      "Epoch [1/50], Batch [103/184], Gradient of hidden_bns.0.weight: 3.507452493067831e-05\n",
      "Epoch [1/50], Batch [103/184], Gradient of hidden_bns.0.bias: -0.00035994802601635456\n",
      "Epoch [1/50], Batch [103/184], Gradient of input_layer.weight: 4.0785417354527453e-07\n",
      "Epoch [1/50], Batch [103/184], Gradient of hidden_layers.0.weight: -3.6071432987228036e-05\n",
      "Epoch [1/50], Batch [103/184], Gradient of output_layer.weight: 0.0008946848683990538\n",
      "Epoch [1/50], Loss: 0.3641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                        | 1/50 [09:24<7:41:05, 564.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3339\n",
      "Epoch [2/50], Batch [1/184], Gradient of input_bn.weight: 1.3348221727937926e-06\n",
      "Epoch [2/50], Batch [1/184], Gradient of input_bn.bias: -1.364789204671979e-05\n",
      "Epoch [2/50], Batch [1/184], Gradient of hidden_bns.0.weight: 4.159519448876381e-05\n",
      "Epoch [2/50], Batch [1/184], Gradient of hidden_bns.0.bias: -0.00016994297038763762\n",
      "Epoch [2/50], Batch [1/184], Gradient of input_layer.weight: 4.793313337358995e-07\n",
      "Epoch [2/50], Batch [1/184], Gradient of hidden_layers.0.weight: -3.384886804269627e-05\n",
      "Epoch [2/50], Batch [1/184], Gradient of output_layer.weight: 0.0012177529279142618\n",
      "Epoch [2/50], Batch [2/184], Gradient of input_bn.weight: 7.86027612775797e-07\n",
      "Epoch [2/50], Batch [2/184], Gradient of input_bn.bias: -5.620004958473146e-05\n",
      "Epoch [2/50], Batch [2/184], Gradient of hidden_bns.0.weight: 3.4782078728312626e-05\n",
      "Epoch [2/50], Batch [2/184], Gradient of hidden_bns.0.bias: 0.00019568981952033937\n",
      "Epoch [2/50], Batch [2/184], Gradient of input_layer.weight: -1.852865239015955e-07\n",
      "Epoch [2/50], Batch [2/184], Gradient of hidden_layers.0.weight: -3.561084668035619e-05\n",
      "Epoch [2/50], Batch [2/184], Gradient of output_layer.weight: 0.0009302361868321896\n",
      "Epoch [2/50], Batch [3/184], Gradient of input_bn.weight: 5.249085006653331e-07\n",
      "Epoch [2/50], Batch [3/184], Gradient of input_bn.bias: -2.9411847208393738e-05\n",
      "Epoch [2/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.465010715648532e-05\n",
      "Epoch [2/50], Batch [3/184], Gradient of hidden_bns.0.bias: 0.0002613633987493813\n",
      "Epoch [2/50], Batch [3/184], Gradient of input_layer.weight: 1.8292498182859163e-08\n",
      "Epoch [2/50], Batch [3/184], Gradient of hidden_layers.0.weight: -2.916902485594619e-05\n",
      "Epoch [2/50], Batch [3/184], Gradient of output_layer.weight: 0.0009959827875718474\n",
      "Epoch [2/50], Batch [101/184], Gradient of input_bn.weight: 1.1524516594363376e-06\n",
      "Epoch [2/50], Batch [101/184], Gradient of input_bn.bias: 8.060887921601534e-07\n",
      "Epoch [2/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.9578859792090952e-05\n",
      "Epoch [2/50], Batch [101/184], Gradient of hidden_bns.0.bias: -0.00031739368569105864\n",
      "Epoch [2/50], Batch [101/184], Gradient of input_layer.weight: 5.941452627666877e-07\n",
      "Epoch [2/50], Batch [101/184], Gradient of hidden_layers.0.weight: -2.0970757759641856e-05\n",
      "Epoch [2/50], Batch [101/184], Gradient of output_layer.weight: 0.0007021885830909014\n",
      "Epoch [2/50], Batch [102/184], Gradient of input_bn.weight: 3.6439087125472724e-07\n",
      "Epoch [2/50], Batch [102/184], Gradient of input_bn.bias: -4.406880907481536e-05\n",
      "Epoch [2/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.7849899450084195e-05\n",
      "Epoch [2/50], Batch [102/184], Gradient of hidden_bns.0.bias: 0.00018130570242647082\n",
      "Epoch [2/50], Batch [102/184], Gradient of input_layer.weight: 1.1895139806483712e-07\n",
      "Epoch [2/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.9249926481279545e-05\n",
      "Epoch [2/50], Batch [102/184], Gradient of output_layer.weight: 0.0006128823151811957\n",
      "Epoch [2/50], Batch [103/184], Gradient of input_bn.weight: 1.2590135156642646e-07\n",
      "Epoch [2/50], Batch [103/184], Gradient of input_bn.bias: -9.87220300885383e-06\n",
      "Epoch [2/50], Batch [103/184], Gradient of hidden_bns.0.weight: 8.915684702515136e-06\n",
      "Epoch [2/50], Batch [103/184], Gradient of hidden_bns.0.bias: 7.580136298201978e-05\n",
      "Epoch [2/50], Batch [103/184], Gradient of input_layer.weight: -2.2408165989418194e-08\n",
      "Epoch [2/50], Batch [103/184], Gradient of hidden_layers.0.weight: -1.219420119014103e-05\n",
      "Epoch [2/50], Batch [103/184], Gradient of output_layer.weight: 0.00025349308270961046\n",
      "Epoch [2/50], Loss: 0.3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▋                                       | 2/50 [18:47<7:30:41, 563.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3324\n",
      "Epoch [3/50], Batch [1/184], Gradient of input_bn.weight: 9.706027412903495e-07\n",
      "Epoch [3/50], Batch [1/184], Gradient of input_bn.bias: -4.602269473252818e-05\n",
      "Epoch [3/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.1219471818767488e-05\n",
      "Epoch [3/50], Batch [1/184], Gradient of hidden_bns.0.bias: 0.00011594851093832403\n",
      "Epoch [3/50], Batch [1/184], Gradient of input_layer.weight: 5.5219800287886756e-08\n",
      "Epoch [3/50], Batch [1/184], Gradient of hidden_layers.0.weight: -3.638220005086623e-05\n",
      "Epoch [3/50], Batch [1/184], Gradient of output_layer.weight: 0.0007321105804294348\n",
      "Epoch [3/50], Batch [2/184], Gradient of input_bn.weight: 7.354992703767493e-07\n",
      "Epoch [3/50], Batch [2/184], Gradient of input_bn.bias: -3.553083661245182e-05\n",
      "Epoch [3/50], Batch [2/184], Gradient of hidden_bns.0.weight: 3.1379819120047614e-05\n",
      "Epoch [3/50], Batch [2/184], Gradient of hidden_bns.0.bias: 0.00023245456395670772\n",
      "Epoch [3/50], Batch [2/184], Gradient of input_layer.weight: 1.2472403909669083e-07\n",
      "Epoch [3/50], Batch [2/184], Gradient of hidden_layers.0.weight: -3.0297072953544557e-05\n",
      "Epoch [3/50], Batch [2/184], Gradient of output_layer.weight: 0.0009060632437467575\n",
      "Epoch [3/50], Batch [3/184], Gradient of input_bn.weight: 1.2283207979635336e-06\n",
      "Epoch [3/50], Batch [3/184], Gradient of input_bn.bias: -4.17616538470611e-05\n",
      "Epoch [3/50], Batch [3/184], Gradient of hidden_bns.0.weight: 3.60260164598003e-05\n",
      "Epoch [3/50], Batch [3/184], Gradient of hidden_bns.0.bias: 9.678432252258062e-05\n",
      "Epoch [3/50], Batch [3/184], Gradient of input_layer.weight: -4.520673257957242e-08\n",
      "Epoch [3/50], Batch [3/184], Gradient of hidden_layers.0.weight: -3.59528639819473e-05\n",
      "Epoch [3/50], Batch [3/184], Gradient of output_layer.weight: 0.0010943396482616663\n",
      "Epoch [3/50], Batch [101/184], Gradient of input_bn.weight: 3.767463567783125e-07\n",
      "Epoch [3/50], Batch [101/184], Gradient of input_bn.bias: -3.839564305962995e-05\n",
      "Epoch [3/50], Batch [101/184], Gradient of hidden_bns.0.weight: 4.435904884303454e-06\n",
      "Epoch [3/50], Batch [101/184], Gradient of hidden_bns.0.bias: 7.930261926958337e-05\n",
      "Epoch [3/50], Batch [101/184], Gradient of input_layer.weight: -8.318473909696422e-09\n",
      "Epoch [3/50], Batch [101/184], Gradient of hidden_layers.0.weight: -4.5831213355995715e-05\n",
      "Epoch [3/50], Batch [101/184], Gradient of output_layer.weight: 0.00032865171669982374\n",
      "Epoch [3/50], Batch [102/184], Gradient of input_bn.weight: 1.1013817129423842e-06\n",
      "Epoch [3/50], Batch [102/184], Gradient of input_bn.bias: -7.212147465907037e-07\n",
      "Epoch [3/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.1248439477640204e-06\n",
      "Epoch [3/50], Batch [102/184], Gradient of hidden_bns.0.bias: -0.00017880764789879322\n",
      "Epoch [3/50], Batch [102/184], Gradient of input_layer.weight: 1.547890065012325e-07\n",
      "Epoch [3/50], Batch [102/184], Gradient of hidden_layers.0.weight: -5.000579039915465e-05\n",
      "Epoch [3/50], Batch [102/184], Gradient of output_layer.weight: 0.00045205437345430255\n",
      "Epoch [3/50], Batch [103/184], Gradient of input_bn.weight: 4.950597940478474e-07\n",
      "Epoch [3/50], Batch [103/184], Gradient of input_bn.bias: -4.772565444000065e-05\n",
      "Epoch [3/50], Batch [103/184], Gradient of hidden_bns.0.weight: 3.677240965771489e-05\n",
      "Epoch [3/50], Batch [103/184], Gradient of hidden_bns.0.bias: 0.00019385592895559967\n",
      "Epoch [3/50], Batch [103/184], Gradient of input_layer.weight: 2.686795852469004e-08\n",
      "Epoch [3/50], Batch [103/184], Gradient of hidden_layers.0.weight: -6.629194103879854e-05\n",
      "Epoch [3/50], Batch [103/184], Gradient of output_layer.weight: 0.0008213306427933276\n",
      "Epoch [3/50], Loss: 0.3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                      | 3/50 [28:10<7:21:26, 563.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3314\n",
      "Epoch [4/50], Batch [1/184], Gradient of input_bn.weight: 4.712364898296073e-07\n",
      "Epoch [4/50], Batch [1/184], Gradient of input_bn.bias: -5.8763248489412945e-06\n",
      "Epoch [4/50], Batch [1/184], Gradient of hidden_bns.0.weight: 5.682967639586423e-06\n",
      "Epoch [4/50], Batch [1/184], Gradient of hidden_bns.0.bias: 2.104491795762442e-05\n",
      "Epoch [4/50], Batch [1/184], Gradient of input_layer.weight: -4.1117484528285786e-08\n",
      "Epoch [4/50], Batch [1/184], Gradient of hidden_layers.0.weight: -0.00011322428326820955\n",
      "Epoch [4/50], Batch [1/184], Gradient of output_layer.weight: 0.00018000754062086344\n",
      "Epoch [4/50], Batch [2/184], Gradient of input_bn.weight: 6.750451575499028e-07\n",
      "Epoch [4/50], Batch [2/184], Gradient of input_bn.bias: -8.80432162375655e-06\n",
      "Epoch [4/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.944655923580285e-05\n",
      "Epoch [4/50], Batch [2/184], Gradient of hidden_bns.0.bias: 0.00015291596355382353\n",
      "Epoch [4/50], Batch [2/184], Gradient of input_layer.weight: 1.827675220056335e-07\n",
      "Epoch [4/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.00022934548906050622\n",
      "Epoch [4/50], Batch [2/184], Gradient of output_layer.weight: 0.00044876447645947337\n",
      "Epoch [4/50], Batch [3/184], Gradient of input_bn.weight: 1.8495484255254269e-07\n",
      "Epoch [4/50], Batch [3/184], Gradient of input_bn.bias: -4.270667432137998e-06\n",
      "Epoch [4/50], Batch [3/184], Gradient of hidden_bns.0.weight: 9.715870419313433e-07\n",
      "Epoch [4/50], Batch [3/184], Gradient of hidden_bns.0.bias: 5.405903721111827e-06\n",
      "Epoch [4/50], Batch [3/184], Gradient of input_layer.weight: -2.3512971836225915e-07\n",
      "Epoch [4/50], Batch [3/184], Gradient of hidden_layers.0.weight: -7.36733854864724e-05\n",
      "Epoch [4/50], Batch [3/184], Gradient of output_layer.weight: 6.406736065400764e-05\n",
      "Epoch [4/50], Batch [101/184], Gradient of input_bn.weight: -8.613496902398765e-07\n",
      "Epoch [4/50], Batch [101/184], Gradient of input_bn.bias: 1.1402438758523203e-05\n",
      "Epoch [4/50], Batch [101/184], Gradient of hidden_bns.0.weight: 4.777472895511892e-06\n",
      "Epoch [4/50], Batch [101/184], Gradient of hidden_bns.0.bias: 6.320222018985078e-05\n",
      "Epoch [4/50], Batch [101/184], Gradient of input_layer.weight: -1.3854918279321282e-07\n",
      "Epoch [4/50], Batch [101/184], Gradient of hidden_layers.0.weight: 0.0003571983252186328\n",
      "Epoch [4/50], Batch [101/184], Gradient of output_layer.weight: 0.0001851895940490067\n",
      "Epoch [4/50], Batch [102/184], Gradient of input_bn.weight: -1.0033181752078235e-06\n",
      "Epoch [4/50], Batch [102/184], Gradient of input_bn.bias: 2.6194295060122386e-05\n",
      "Epoch [4/50], Batch [102/184], Gradient of hidden_bns.0.weight: -1.2285927368793637e-06\n",
      "Epoch [4/50], Batch [102/184], Gradient of hidden_bns.0.bias: 9.342651901533827e-05\n",
      "Epoch [4/50], Batch [102/184], Gradient of input_layer.weight: -2.908078613472753e-07\n",
      "Epoch [4/50], Batch [102/184], Gradient of hidden_layers.0.weight: 0.00046282628318294883\n",
      "Epoch [4/50], Batch [102/184], Gradient of output_layer.weight: 0.00037133734440431\n",
      "Epoch [4/50], Batch [103/184], Gradient of input_bn.weight: -2.645756467245519e-07\n",
      "Epoch [4/50], Batch [103/184], Gradient of input_bn.bias: 2.88235314656049e-05\n",
      "Epoch [4/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.9365425032447092e-06\n",
      "Epoch [4/50], Batch [103/184], Gradient of hidden_bns.0.bias: 9.649750427342951e-05\n",
      "Epoch [4/50], Batch [103/184], Gradient of input_layer.weight: -9.285273883108403e-09\n",
      "Epoch [4/50], Batch [103/184], Gradient of hidden_layers.0.weight: 0.0001749444054439664\n",
      "Epoch [4/50], Batch [103/184], Gradient of output_layer.weight: 0.0003168202529195696\n",
      "Epoch [4/50], Loss: 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                     | 4/50 [37:34<7:12:08, 563.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3308\n",
      "Epoch [5/50], Batch [1/184], Gradient of input_bn.weight: 5.742112989537418e-07\n",
      "Epoch [5/50], Batch [1/184], Gradient of input_bn.bias: 1.4839635696262121e-05\n",
      "Epoch [5/50], Batch [1/184], Gradient of hidden_bns.0.weight: -3.905783160007559e-06\n",
      "Epoch [5/50], Batch [1/184], Gradient of hidden_bns.0.bias: -1.4182267477735877e-05\n",
      "Epoch [5/50], Batch [1/184], Gradient of input_layer.weight: 6.927241003040763e-08\n",
      "Epoch [5/50], Batch [1/184], Gradient of hidden_layers.0.weight: -0.00012684731336776167\n",
      "Epoch [5/50], Batch [1/184], Gradient of output_layer.weight: 0.00016547575069125742\n",
      "Epoch [5/50], Batch [2/184], Gradient of input_bn.weight: 6.10751158092171e-07\n",
      "Epoch [5/50], Batch [2/184], Gradient of input_bn.bias: 2.978740303660743e-05\n",
      "Epoch [5/50], Batch [2/184], Gradient of hidden_bns.0.weight: -5.093953404866625e-06\n",
      "Epoch [5/50], Batch [2/184], Gradient of hidden_bns.0.bias: -0.00023410373250953853\n",
      "Epoch [5/50], Batch [2/184], Gradient of input_layer.weight: -2.2072918000048958e-06\n",
      "Epoch [5/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.0002882495755329728\n",
      "Epoch [5/50], Batch [2/184], Gradient of output_layer.weight: 0.00021944474428892136\n",
      "Epoch [5/50], Batch [3/184], Gradient of input_bn.weight: 3.7282734410837293e-07\n",
      "Epoch [5/50], Batch [3/184], Gradient of input_bn.bias: 1.28284982565674e-05\n",
      "Epoch [5/50], Batch [3/184], Gradient of hidden_bns.0.weight: 9.137713277596049e-06\n",
      "Epoch [5/50], Batch [3/184], Gradient of hidden_bns.0.bias: 9.815771772991866e-05\n",
      "Epoch [5/50], Batch [3/184], Gradient of input_layer.weight: 1.7676615016171127e-07\n",
      "Epoch [5/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00011101913696620613\n",
      "Epoch [5/50], Batch [3/184], Gradient of output_layer.weight: 0.00029468414140865207\n",
      "Epoch [5/50], Batch [101/184], Gradient of input_bn.weight: 4.037428880110383e-07\n",
      "Epoch [5/50], Batch [101/184], Gradient of input_bn.bias: 1.594135756022297e-05\n",
      "Epoch [5/50], Batch [101/184], Gradient of hidden_bns.0.weight: 9.28962072066497e-06\n",
      "Epoch [5/50], Batch [101/184], Gradient of hidden_bns.0.bias: 0.00010304615716449916\n",
      "Epoch [5/50], Batch [101/184], Gradient of input_layer.weight: 6.104380645410856e-08\n",
      "Epoch [5/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00015528422954957932\n",
      "Epoch [5/50], Batch [101/184], Gradient of output_layer.weight: 0.0002926558372564614\n",
      "Epoch [5/50], Batch [102/184], Gradient of input_bn.weight: -3.7136487662792206e-08\n",
      "Epoch [5/50], Batch [102/184], Gradient of input_bn.bias: 2.9000453650951385e-05\n",
      "Epoch [5/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.98917018173961e-06\n",
      "Epoch [5/50], Batch [102/184], Gradient of hidden_bns.0.bias: 3.9467355236411095e-05\n",
      "Epoch [5/50], Batch [102/184], Gradient of input_layer.weight: -2.8977302335420063e-08\n",
      "Epoch [5/50], Batch [102/184], Gradient of hidden_layers.0.weight: 0.00012333926861174405\n",
      "Epoch [5/50], Batch [102/184], Gradient of output_layer.weight: 0.0002910297771450132\n",
      "Epoch [5/50], Batch [103/184], Gradient of input_bn.weight: 7.919652489363216e-08\n",
      "Epoch [5/50], Batch [103/184], Gradient of input_bn.bias: 1.1697802619892173e-05\n",
      "Epoch [5/50], Batch [103/184], Gradient of hidden_bns.0.weight: 3.3873284337460063e-06\n",
      "Epoch [5/50], Batch [103/184], Gradient of hidden_bns.0.bias: 4.2631560063455254e-05\n",
      "Epoch [5/50], Batch [103/184], Gradient of input_layer.weight: 5.8369735711494286e-08\n",
      "Epoch [5/50], Batch [103/184], Gradient of hidden_layers.0.weight: -9.672289706941228e-06\n",
      "Epoch [5/50], Batch [103/184], Gradient of output_layer.weight: 0.0001315306144533679\n",
      "Epoch [5/50], Loss: 0.3311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 5/50 [46:58<7:02:42, 563.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3306\n",
      "Epoch [6/50], Batch [1/184], Gradient of input_bn.weight: 4.995090421289206e-07\n",
      "Epoch [6/50], Batch [1/184], Gradient of input_bn.bias: 2.9018956411164254e-06\n",
      "Epoch [6/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.035294528468512e-07\n",
      "Epoch [6/50], Batch [1/184], Gradient of hidden_bns.0.bias: -3.0357077775988728e-06\n",
      "Epoch [6/50], Batch [1/184], Gradient of input_layer.weight: -5.36750803803443e-07\n",
      "Epoch [6/50], Batch [1/184], Gradient of hidden_layers.0.weight: -0.0002927831083070487\n",
      "Epoch [6/50], Batch [1/184], Gradient of output_layer.weight: 0.00016322790179401636\n",
      "Epoch [6/50], Batch [2/184], Gradient of input_bn.weight: 4.3645741243381053e-07\n",
      "Epoch [6/50], Batch [2/184], Gradient of input_bn.bias: 1.9440822143224068e-05\n",
      "Epoch [6/50], Batch [2/184], Gradient of hidden_bns.0.weight: 4.5044548642181326e-06\n",
      "Epoch [6/50], Batch [2/184], Gradient of hidden_bns.0.bias: 6.98606891091913e-06\n",
      "Epoch [6/50], Batch [2/184], Gradient of input_layer.weight: 5.8448641482300445e-08\n",
      "Epoch [6/50], Batch [2/184], Gradient of hidden_layers.0.weight: -8.739426993997768e-05\n",
      "Epoch [6/50], Batch [2/184], Gradient of output_layer.weight: 0.00013870008115191013\n",
      "Epoch [6/50], Batch [3/184], Gradient of input_bn.weight: 4.0416125557385385e-07\n",
      "Epoch [6/50], Batch [3/184], Gradient of input_bn.bias: 2.8173960799904307e-06\n",
      "Epoch [6/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.415792318468448e-06\n",
      "Epoch [6/50], Batch [3/184], Gradient of hidden_bns.0.bias: 6.844053859822452e-05\n",
      "Epoch [6/50], Batch [3/184], Gradient of input_layer.weight: 7.805208923628015e-08\n",
      "Epoch [6/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00013945414684712887\n",
      "Epoch [6/50], Batch [3/184], Gradient of output_layer.weight: 0.00022975887986831367\n",
      "Epoch [6/50], Batch [101/184], Gradient of input_bn.weight: 1.8455739336786792e-07\n",
      "Epoch [6/50], Batch [101/184], Gradient of input_bn.bias: 9.23528477869695e-06\n",
      "Epoch [6/50], Batch [101/184], Gradient of hidden_bns.0.weight: 7.829731657693628e-06\n",
      "Epoch [6/50], Batch [101/184], Gradient of hidden_bns.0.bias: 5.886102735530585e-05\n",
      "Epoch [6/50], Batch [101/184], Gradient of input_layer.weight: -9.235148468178522e-08\n",
      "Epoch [6/50], Batch [101/184], Gradient of hidden_layers.0.weight: 3.250735244364478e-05\n",
      "Epoch [6/50], Batch [101/184], Gradient of output_layer.weight: 0.00028876971919089556\n",
      "Epoch [6/50], Batch [102/184], Gradient of input_bn.weight: 2.5341068976558745e-07\n",
      "Epoch [6/50], Batch [102/184], Gradient of input_bn.bias: 3.2741772884037346e-05\n",
      "Epoch [6/50], Batch [102/184], Gradient of hidden_bns.0.weight: -8.314611477544531e-06\n",
      "Epoch [6/50], Batch [102/184], Gradient of hidden_bns.0.bias: 3.2041280064731836e-06\n",
      "Epoch [6/50], Batch [102/184], Gradient of input_layer.weight: -4.07652862577379e-08\n",
      "Epoch [6/50], Batch [102/184], Gradient of hidden_layers.0.weight: 8.517444075550884e-05\n",
      "Epoch [6/50], Batch [102/184], Gradient of output_layer.weight: 0.00024137398577295244\n",
      "Epoch [6/50], Batch [103/184], Gradient of input_bn.weight: 1.3852377378498204e-07\n",
      "Epoch [6/50], Batch [103/184], Gradient of input_bn.bias: 2.031657004408771e-06\n",
      "Epoch [6/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.5190216799965128e-06\n",
      "Epoch [6/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.6986919692717493e-05\n",
      "Epoch [6/50], Batch [103/184], Gradient of input_layer.weight: -3.127275549630326e-09\n",
      "Epoch [6/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.2952042854740284e-05\n",
      "Epoch [6/50], Batch [103/184], Gradient of output_layer.weight: 0.00010091417789226398\n",
      "Epoch [6/50], Loss: 0.3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▉                                    | 6/50 [56:21<6:53:20, 563.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3304\n",
      "Epoch [7/50], Batch [1/184], Gradient of input_bn.weight: 2.633037183841225e-07\n",
      "Epoch [7/50], Batch [1/184], Gradient of input_bn.bias: 2.1415569790406153e-05\n",
      "Epoch [7/50], Batch [1/184], Gradient of hidden_bns.0.weight: 1.4121360436547548e-07\n",
      "Epoch [7/50], Batch [1/184], Gradient of hidden_bns.0.bias: 5.383425741456449e-05\n",
      "Epoch [7/50], Batch [1/184], Gradient of input_layer.weight: 5.565748395497394e-08\n",
      "Epoch [7/50], Batch [1/184], Gradient of hidden_layers.0.weight: -2.5462755729677156e-05\n",
      "Epoch [7/50], Batch [1/184], Gradient of output_layer.weight: 0.00021921374718658626\n",
      "Epoch [7/50], Batch [2/184], Gradient of input_bn.weight: 2.534998202463612e-07\n",
      "Epoch [7/50], Batch [2/184], Gradient of input_bn.bias: 4.8592992243357e-06\n",
      "Epoch [7/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.2151454029663e-06\n",
      "Epoch [7/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.770736707840115e-05\n",
      "Epoch [7/50], Batch [2/184], Gradient of input_layer.weight: 3.830796657666724e-08\n",
      "Epoch [7/50], Batch [2/184], Gradient of hidden_layers.0.weight: -9.990439866669476e-05\n",
      "Epoch [7/50], Batch [2/184], Gradient of output_layer.weight: 8.151478687068447e-05\n",
      "Epoch [7/50], Batch [3/184], Gradient of input_bn.weight: 6.061309250071645e-07\n",
      "Epoch [7/50], Batch [3/184], Gradient of input_bn.bias: -3.42206476489082e-08\n",
      "Epoch [7/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.109353317791829e-06\n",
      "Epoch [7/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.0302453776821494e-05\n",
      "Epoch [7/50], Batch [3/184], Gradient of input_layer.weight: -1.4899307565485742e-08\n",
      "Epoch [7/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00016463820065837353\n",
      "Epoch [7/50], Batch [3/184], Gradient of output_layer.weight: 0.00012515518756117672\n",
      "Epoch [7/50], Batch [101/184], Gradient of input_bn.weight: 3.7846803024876863e-07\n",
      "Epoch [7/50], Batch [101/184], Gradient of input_bn.bias: 1.9679484466905706e-05\n",
      "Epoch [7/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.5808636817382649e-06\n",
      "Epoch [7/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.6404672098578885e-05\n",
      "Epoch [7/50], Batch [101/184], Gradient of input_layer.weight: 4.619430615804276e-09\n",
      "Epoch [7/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00010813312110258266\n",
      "Epoch [7/50], Batch [101/184], Gradient of output_layer.weight: 0.0001750414230627939\n",
      "Epoch [7/50], Batch [102/184], Gradient of input_bn.weight: 4.1990460886154324e-07\n",
      "Epoch [7/50], Batch [102/184], Gradient of input_bn.bias: 2.8703325369860977e-06\n",
      "Epoch [7/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.5495040719979443e-06\n",
      "Epoch [7/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.6883582904702052e-05\n",
      "Epoch [7/50], Batch [102/184], Gradient of input_layer.weight: 1.056389578479866e-06\n",
      "Epoch [7/50], Batch [102/184], Gradient of hidden_layers.0.weight: -5.943918222328648e-05\n",
      "Epoch [7/50], Batch [102/184], Gradient of output_layer.weight: 0.00021105140331201255\n",
      "Epoch [7/50], Batch [103/184], Gradient of input_bn.weight: -1.2714735930785537e-08\n",
      "Epoch [7/50], Batch [103/184], Gradient of input_bn.bias: 2.3340067855315283e-05\n",
      "Epoch [7/50], Batch [103/184], Gradient of hidden_bns.0.weight: -2.797318302327767e-06\n",
      "Epoch [7/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.6571957278065383e-05\n",
      "Epoch [7/50], Batch [103/184], Gradient of input_layer.weight: -1.8315958527637122e-07\n",
      "Epoch [7/50], Batch [103/184], Gradient of hidden_layers.0.weight: 0.0001829901011660695\n",
      "Epoch [7/50], Batch [103/184], Gradient of output_layer.weight: 0.00019404685008339584\n",
      "Epoch [7/50], Loss: 0.3309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▍                                 | 7/50 [1:05:44<6:43:46, 563.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3303\n",
      "Epoch [8/50], Batch [1/184], Gradient of input_bn.weight: 3.5825905797537416e-07\n",
      "Epoch [8/50], Batch [1/184], Gradient of input_bn.bias: 2.5694658688735217e-05\n",
      "Epoch [8/50], Batch [1/184], Gradient of hidden_bns.0.weight: -6.993291208345909e-06\n",
      "Epoch [8/50], Batch [1/184], Gradient of hidden_bns.0.bias: 5.323992809280753e-05\n",
      "Epoch [8/50], Batch [1/184], Gradient of input_layer.weight: -9.338127426872234e-08\n",
      "Epoch [8/50], Batch [1/184], Gradient of hidden_layers.0.weight: 7.054176967358217e-05\n",
      "Epoch [8/50], Batch [1/184], Gradient of output_layer.weight: 0.00024572928668931127\n",
      "Epoch [8/50], Batch [2/184], Gradient of input_bn.weight: 1.4151737559586763e-09\n",
      "Epoch [8/50], Batch [2/184], Gradient of input_bn.bias: 7.94402149040252e-06\n",
      "Epoch [8/50], Batch [2/184], Gradient of hidden_bns.0.weight: -6.380903869285248e-06\n",
      "Epoch [8/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.365713615086861e-05\n",
      "Epoch [8/50], Batch [2/184], Gradient of input_layer.weight: -6.47701881462126e-07\n",
      "Epoch [8/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.00022548067499883473\n",
      "Epoch [8/50], Batch [2/184], Gradient of output_layer.weight: 0.00018950123921968043\n",
      "Epoch [8/50], Batch [3/184], Gradient of input_bn.weight: 2.0050538296345621e-07\n",
      "Epoch [8/50], Batch [3/184], Gradient of input_bn.bias: 1.6162803149200045e-05\n",
      "Epoch [8/50], Batch [3/184], Gradient of hidden_bns.0.weight: -1.4372872101375833e-06\n",
      "Epoch [8/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.09778590942733e-06\n",
      "Epoch [8/50], Batch [3/184], Gradient of input_layer.weight: -5.2397059135955715e-08\n",
      "Epoch [8/50], Batch [3/184], Gradient of hidden_layers.0.weight: 4.811044709640555e-05\n",
      "Epoch [8/50], Batch [3/184], Gradient of output_layer.weight: 0.00019459148461464792\n",
      "Epoch [8/50], Batch [101/184], Gradient of input_bn.weight: 2.2642848307441454e-07\n",
      "Epoch [8/50], Batch [101/184], Gradient of input_bn.bias: 7.180865850386908e-06\n",
      "Epoch [8/50], Batch [101/184], Gradient of hidden_bns.0.weight: 3.957335138693452e-06\n",
      "Epoch [8/50], Batch [101/184], Gradient of hidden_bns.0.bias: 4.622077540261671e-05\n",
      "Epoch [8/50], Batch [101/184], Gradient of input_layer.weight: 8.557790032170942e-09\n",
      "Epoch [8/50], Batch [101/184], Gradient of hidden_layers.0.weight: -8.102588253677823e-06\n",
      "Epoch [8/50], Batch [101/184], Gradient of output_layer.weight: 0.00014605687465518713\n",
      "Epoch [8/50], Batch [102/184], Gradient of input_bn.weight: -4.948960850015283e-07\n",
      "Epoch [8/50], Batch [102/184], Gradient of input_bn.bias: -8.45612430566689e-06\n",
      "Epoch [8/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.1488070817431435e-08\n",
      "Epoch [8/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.6178713596891612e-05\n",
      "Epoch [8/50], Batch [102/184], Gradient of input_layer.weight: -2.3860168312239693e-06\n",
      "Epoch [8/50], Batch [102/184], Gradient of hidden_layers.0.weight: -0.0001870122505351901\n",
      "Epoch [8/50], Batch [102/184], Gradient of output_layer.weight: 0.00012581903138197958\n",
      "Epoch [8/50], Batch [103/184], Gradient of input_bn.weight: 3.6206984077580273e-07\n",
      "Epoch [8/50], Batch [103/184], Gradient of input_bn.bias: 1.651993443374522e-05\n",
      "Epoch [8/50], Batch [103/184], Gradient of hidden_bns.0.weight: -4.671542228606995e-07\n",
      "Epoch [8/50], Batch [103/184], Gradient of hidden_bns.0.bias: 3.3455762604717165e-05\n",
      "Epoch [8/50], Batch [103/184], Gradient of input_layer.weight: 1.4971776352012967e-07\n",
      "Epoch [8/50], Batch [103/184], Gradient of hidden_layers.0.weight: -0.00013299401325639337\n",
      "Epoch [8/50], Batch [103/184], Gradient of output_layer.weight: 0.00020291680993977934\n",
      "Epoch [8/50], Loss: 0.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▏                                | 8/50 [1:15:08<6:34:26, 563.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3302\n",
      "Epoch [9/50], Batch [1/184], Gradient of input_bn.weight: -2.117303665727377e-09\n",
      "Epoch [9/50], Batch [1/184], Gradient of input_bn.bias: 1.5258105122484267e-05\n",
      "Epoch [9/50], Batch [1/184], Gradient of hidden_bns.0.weight: -9.598570613889024e-07\n",
      "Epoch [9/50], Batch [1/184], Gradient of hidden_bns.0.bias: 4.21161312260665e-05\n",
      "Epoch [9/50], Batch [1/184], Gradient of input_layer.weight: -2.4802136522339424e-07\n",
      "Epoch [9/50], Batch [1/184], Gradient of hidden_layers.0.weight: 0.00012793665518984199\n",
      "Epoch [9/50], Batch [1/184], Gradient of output_layer.weight: 0.00019976455951109529\n",
      "Epoch [9/50], Batch [2/184], Gradient of input_bn.weight: 6.78028300171718e-08\n",
      "Epoch [9/50], Batch [2/184], Gradient of input_bn.bias: 1.0252535503241234e-05\n",
      "Epoch [9/50], Batch [2/184], Gradient of hidden_bns.0.weight: 3.3480200727353804e-06\n",
      "Epoch [9/50], Batch [2/184], Gradient of hidden_bns.0.bias: 5.013913687434979e-05\n",
      "Epoch [9/50], Batch [2/184], Gradient of input_layer.weight: 3.318128847240587e-07\n",
      "Epoch [9/50], Batch [2/184], Gradient of hidden_layers.0.weight: 6.962785118957981e-05\n",
      "Epoch [9/50], Batch [2/184], Gradient of output_layer.weight: 0.00017623468011152\n",
      "Epoch [9/50], Batch [3/184], Gradient of input_bn.weight: 4.4689841161016375e-07\n",
      "Epoch [9/50], Batch [3/184], Gradient of input_bn.bias: 2.235679312434513e-05\n",
      "Epoch [9/50], Batch [3/184], Gradient of hidden_bns.0.weight: 5.667488949256949e-06\n",
      "Epoch [9/50], Batch [3/184], Gradient of hidden_bns.0.bias: 5.278521712170914e-05\n",
      "Epoch [9/50], Batch [3/184], Gradient of input_layer.weight: -4.94456875443916e-09\n",
      "Epoch [9/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00011071476910728961\n",
      "Epoch [9/50], Batch [3/184], Gradient of output_layer.weight: 0.00025241076946258545\n",
      "Epoch [9/50], Batch [101/184], Gradient of input_bn.weight: 8.38413143355865e-08\n",
      "Epoch [9/50], Batch [101/184], Gradient of input_bn.bias: 5.3518360800808296e-06\n",
      "Epoch [9/50], Batch [101/184], Gradient of hidden_bns.0.weight: 3.7653694562322926e-06\n",
      "Epoch [9/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.391702921362594e-05\n",
      "Epoch [9/50], Batch [101/184], Gradient of input_layer.weight: 8.708126664203064e-09\n",
      "Epoch [9/50], Batch [101/184], Gradient of hidden_layers.0.weight: 9.801330634218175e-06\n",
      "Epoch [9/50], Batch [101/184], Gradient of output_layer.weight: 0.00010191352339461446\n",
      "Epoch [9/50], Batch [102/184], Gradient of input_bn.weight: 2.3818574845790863e-07\n",
      "Epoch [9/50], Batch [102/184], Gradient of input_bn.bias: 8.278726454591379e-06\n",
      "Epoch [9/50], Batch [102/184], Gradient of hidden_bns.0.weight: 6.939800186955836e-06\n",
      "Epoch [9/50], Batch [102/184], Gradient of hidden_bns.0.bias: 8.09565099189058e-05\n",
      "Epoch [9/50], Batch [102/184], Gradient of input_layer.weight: 8.154226804890641e-08\n",
      "Epoch [9/50], Batch [102/184], Gradient of hidden_layers.0.weight: -8.921730477595702e-05\n",
      "Epoch [9/50], Batch [102/184], Gradient of output_layer.weight: 0.00021165843645576388\n",
      "Epoch [9/50], Batch [103/184], Gradient of input_bn.weight: 6.712580216117203e-07\n",
      "Epoch [9/50], Batch [103/184], Gradient of input_bn.bias: 2.0740220861625858e-05\n",
      "Epoch [9/50], Batch [103/184], Gradient of hidden_bns.0.weight: -3.7056061046314426e-06\n",
      "Epoch [9/50], Batch [103/184], Gradient of hidden_bns.0.bias: 7.373517291853204e-05\n",
      "Epoch [9/50], Batch [103/184], Gradient of input_layer.weight: -6.753108294788035e-08\n",
      "Epoch [9/50], Batch [103/184], Gradient of hidden_layers.0.weight: -0.00011690540122799575\n",
      "Epoch [9/50], Batch [103/184], Gradient of output_layer.weight: 0.0003018969146069139\n",
      "Epoch [9/50], Loss: 0.3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████                                | 9/50 [1:24:31<6:24:55, 563.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3301\n",
      "Epoch [10/50], Batch [1/184], Gradient of input_bn.weight: -1.935950422193855e-08\n",
      "Epoch [10/50], Batch [1/184], Gradient of input_bn.bias: 8.752641406317707e-06\n",
      "Epoch [10/50], Batch [1/184], Gradient of hidden_bns.0.weight: 3.1177394248516066e-06\n",
      "Epoch [10/50], Batch [1/184], Gradient of hidden_bns.0.bias: 2.008497904171236e-05\n",
      "Epoch [10/50], Batch [1/184], Gradient of input_layer.weight: -1.5065877434494723e-08\n",
      "Epoch [10/50], Batch [1/184], Gradient of hidden_layers.0.weight: 6.107502849772573e-05\n",
      "Epoch [10/50], Batch [1/184], Gradient of output_layer.weight: 5.9377020079409704e-05\n",
      "Epoch [10/50], Batch [2/184], Gradient of input_bn.weight: 3.4781805879902095e-07\n",
      "Epoch [10/50], Batch [2/184], Gradient of input_bn.bias: 1.4870195627736393e-05\n",
      "Epoch [10/50], Batch [2/184], Gradient of hidden_bns.0.weight: 4.081247880094452e-06\n",
      "Epoch [10/50], Batch [2/184], Gradient of hidden_bns.0.bias: 3.90399873140268e-06\n",
      "Epoch [10/50], Batch [2/184], Gradient of input_layer.weight: -7.764167087032092e-09\n",
      "Epoch [10/50], Batch [2/184], Gradient of hidden_layers.0.weight: -6.244484393391758e-05\n",
      "Epoch [10/50], Batch [2/184], Gradient of output_layer.weight: 0.00011786531104007736\n",
      "Epoch [10/50], Batch [3/184], Gradient of input_bn.weight: 3.5992525226902217e-07\n",
      "Epoch [10/50], Batch [3/184], Gradient of input_bn.bias: 1.7493899576948024e-05\n",
      "Epoch [10/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.928901944367681e-06\n",
      "Epoch [10/50], Batch [3/184], Gradient of hidden_bns.0.bias: 7.056257163640112e-05\n",
      "Epoch [10/50], Batch [3/184], Gradient of input_layer.weight: 5.1526310329563785e-08\n",
      "Epoch [10/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00011874865595018491\n",
      "Epoch [10/50], Batch [3/184], Gradient of output_layer.weight: 0.0002211772371083498\n",
      "Epoch [10/50], Batch [101/184], Gradient of input_bn.weight: 2.3623942979611456e-07\n",
      "Epoch [10/50], Batch [101/184], Gradient of input_bn.bias: 3.380170892341994e-05\n",
      "Epoch [10/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.1272913980064914e-06\n",
      "Epoch [10/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.871156513923779e-05\n",
      "Epoch [10/50], Batch [101/184], Gradient of input_layer.weight: -9.69924656146759e-08\n",
      "Epoch [10/50], Batch [101/184], Gradient of hidden_layers.0.weight: 8.993673691293225e-05\n",
      "Epoch [10/50], Batch [101/184], Gradient of output_layer.weight: 0.0002597392303869128\n",
      "Epoch [10/50], Batch [102/184], Gradient of input_bn.weight: 5.605961632682011e-07\n",
      "Epoch [10/50], Batch [102/184], Gradient of input_bn.bias: 1.1545669622137211e-05\n",
      "Epoch [10/50], Batch [102/184], Gradient of hidden_bns.0.weight: 2.7305231924401596e-06\n",
      "Epoch [10/50], Batch [102/184], Gradient of hidden_bns.0.bias: 0.00011123903095722198\n",
      "Epoch [10/50], Batch [102/184], Gradient of input_layer.weight: -4.5518763869267787e-08\n",
      "Epoch [10/50], Batch [102/184], Gradient of hidden_layers.0.weight: 3.130608092760667e-05\n",
      "Epoch [10/50], Batch [102/184], Gradient of output_layer.weight: 0.00038358583697117865\n",
      "Epoch [10/50], Batch [103/184], Gradient of input_bn.weight: 2.808997123793233e-07\n",
      "Epoch [10/50], Batch [103/184], Gradient of input_bn.bias: 2.1217201719991863e-05\n",
      "Epoch [10/50], Batch [103/184], Gradient of hidden_bns.0.weight: -8.930783224059269e-07\n",
      "Epoch [10/50], Batch [103/184], Gradient of hidden_bns.0.bias: 4.426918530953117e-05\n",
      "Epoch [10/50], Batch [103/184], Gradient of input_layer.weight: -1.6036382888273693e-08\n",
      "Epoch [10/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.5988132620113902e-05\n",
      "Epoch [10/50], Batch [103/184], Gradient of output_layer.weight: 0.00017472379840910435\n",
      "Epoch [10/50], Loss: 0.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▌                              | 10/50 [1:33:54<6:15:32, 563.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3300\n",
      "Epoch [11/50], Batch [1/184], Gradient of input_bn.weight: -4.986142130292137e-07\n",
      "Epoch [11/50], Batch [1/184], Gradient of input_bn.bias: -5.171541488380171e-07\n",
      "Epoch [11/50], Batch [1/184], Gradient of hidden_bns.0.weight: -6.353145181492437e-06\n",
      "Epoch [11/50], Batch [1/184], Gradient of hidden_bns.0.bias: 4.061673462274484e-05\n",
      "Epoch [11/50], Batch [1/184], Gradient of input_layer.weight: -1.5084635833773063e-06\n",
      "Epoch [11/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.008653543976834e-05\n",
      "Epoch [11/50], Batch [1/184], Gradient of output_layer.weight: 0.00019026042718905956\n",
      "Epoch [11/50], Batch [2/184], Gradient of input_bn.weight: 5.041874828748405e-08\n",
      "Epoch [11/50], Batch [2/184], Gradient of input_bn.bias: 1.3271036550577264e-05\n",
      "Epoch [11/50], Batch [2/184], Gradient of hidden_bns.0.weight: 5.845718078489881e-06\n",
      "Epoch [11/50], Batch [2/184], Gradient of hidden_bns.0.bias: 5.540752681554295e-05\n",
      "Epoch [11/50], Batch [2/184], Gradient of input_layer.weight: -5.470445785249467e-08\n",
      "Epoch [11/50], Batch [2/184], Gradient of hidden_layers.0.weight: 6.094008858781308e-05\n",
      "Epoch [11/50], Batch [2/184], Gradient of output_layer.weight: 0.0001560313830850646\n",
      "Epoch [11/50], Batch [3/184], Gradient of input_bn.weight: 1.7752063286025077e-07\n",
      "Epoch [11/50], Batch [3/184], Gradient of input_bn.bias: 9.113968189922161e-06\n",
      "Epoch [11/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.2280115697649308e-06\n",
      "Epoch [11/50], Batch [3/184], Gradient of hidden_bns.0.bias: 3.2747790100984275e-05\n",
      "Epoch [11/50], Batch [3/184], Gradient of input_layer.weight: -7.66741479196753e-08\n",
      "Epoch [11/50], Batch [3/184], Gradient of hidden_layers.0.weight: -0.00011261895997449756\n",
      "Epoch [11/50], Batch [3/184], Gradient of output_layer.weight: 9.649094863561913e-05\n",
      "Epoch [11/50], Batch [101/184], Gradient of input_bn.weight: 2.0455263438634574e-07\n",
      "Epoch [11/50], Batch [101/184], Gradient of input_bn.bias: 5.414880433818325e-06\n",
      "Epoch [11/50], Batch [101/184], Gradient of hidden_bns.0.weight: -5.9105104810441844e-08\n",
      "Epoch [11/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.2182895918376744e-05\n",
      "Epoch [11/50], Batch [101/184], Gradient of input_layer.weight: 1.9565728592851883e-08\n",
      "Epoch [11/50], Batch [101/184], Gradient of hidden_layers.0.weight: -9.953401604434475e-05\n",
      "Epoch [11/50], Batch [101/184], Gradient of output_layer.weight: 7.60463226470165e-05\n",
      "Epoch [11/50], Batch [102/184], Gradient of input_bn.weight: 3.7509016692638397e-07\n",
      "Epoch [11/50], Batch [102/184], Gradient of input_bn.bias: 4.076073309988715e-06\n",
      "Epoch [11/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.1717493180185556e-06\n",
      "Epoch [11/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.6579051336739212e-05\n",
      "Epoch [11/50], Batch [102/184], Gradient of input_layer.weight: 9.541986401018221e-08\n",
      "Epoch [11/50], Batch [102/184], Gradient of hidden_layers.0.weight: -0.00010341704182792455\n",
      "Epoch [11/50], Batch [102/184], Gradient of output_layer.weight: 0.00011924418504349887\n",
      "Epoch [11/50], Batch [103/184], Gradient of input_bn.weight: 1.4372653822647408e-07\n",
      "Epoch [11/50], Batch [103/184], Gradient of input_bn.bias: 5.641963980451692e-06\n",
      "Epoch [11/50], Batch [103/184], Gradient of hidden_bns.0.weight: 7.14705038262764e-07\n",
      "Epoch [11/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.6358113498426974e-05\n",
      "Epoch [11/50], Batch [103/184], Gradient of input_layer.weight: 1.6271005875978517e-08\n",
      "Epoch [11/50], Batch [103/184], Gradient of hidden_layers.0.weight: -3.36673365382012e-05\n",
      "Epoch [11/50], Batch [103/184], Gradient of output_layer.weight: 5.669295569532551e-05\n",
      "Epoch [11/50], Loss: 0.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▎                             | 11/50 [1:43:18<6:06:09, 563.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3300\n",
      "Epoch [12/50], Batch [1/184], Gradient of input_bn.weight: 4.093410552741261e-07\n",
      "Epoch [12/50], Batch [1/184], Gradient of input_bn.bias: 9.36205469770357e-06\n",
      "Epoch [12/50], Batch [1/184], Gradient of hidden_bns.0.weight: 1.7085994841181673e-07\n",
      "Epoch [12/50], Batch [1/184], Gradient of hidden_bns.0.bias: -1.0985291737597436e-05\n",
      "Epoch [12/50], Batch [1/184], Gradient of input_layer.weight: 3.533287795676188e-08\n",
      "Epoch [12/50], Batch [1/184], Gradient of hidden_layers.0.weight: -9.64964692684589e-06\n",
      "Epoch [12/50], Batch [1/184], Gradient of output_layer.weight: 0.00013395554560702294\n",
      "Epoch [12/50], Batch [2/184], Gradient of input_bn.weight: 9.136274456977844e-07\n",
      "Epoch [12/50], Batch [2/184], Gradient of input_bn.bias: 8.504845027346164e-06\n",
      "Epoch [12/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.0749612303916365e-06\n",
      "Epoch [12/50], Batch [2/184], Gradient of hidden_bns.0.bias: -0.00022173258184920996\n",
      "Epoch [12/50], Batch [2/184], Gradient of input_layer.weight: -3.291692109996802e-07\n",
      "Epoch [12/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.00016981335647869855\n",
      "Epoch [12/50], Batch [2/184], Gradient of output_layer.weight: 0.00030729291029274464\n",
      "Epoch [12/50], Batch [3/184], Gradient of input_bn.weight: 1.450698619009927e-07\n",
      "Epoch [12/50], Batch [3/184], Gradient of input_bn.bias: 1.3833509001415223e-05\n",
      "Epoch [12/50], Batch [3/184], Gradient of hidden_bns.0.weight: 3.2081579774967395e-06\n",
      "Epoch [12/50], Batch [3/184], Gradient of hidden_bns.0.bias: 4.420592085807584e-05\n",
      "Epoch [12/50], Batch [3/184], Gradient of input_layer.weight: -1.1575587599566006e-08\n",
      "Epoch [12/50], Batch [3/184], Gradient of hidden_layers.0.weight: 6.419263081625104e-05\n",
      "Epoch [12/50], Batch [3/184], Gradient of output_layer.weight: 0.0001422872592229396\n",
      "Epoch [12/50], Batch [101/184], Gradient of input_bn.weight: 1.4634679246228188e-07\n",
      "Epoch [12/50], Batch [101/184], Gradient of input_bn.bias: 1.2093103578081354e-05\n",
      "Epoch [12/50], Batch [101/184], Gradient of hidden_bns.0.weight: -5.027615316066658e-06\n",
      "Epoch [12/50], Batch [101/184], Gradient of hidden_bns.0.bias: -1.1469819582998753e-06\n",
      "Epoch [12/50], Batch [101/184], Gradient of input_layer.weight: -8.917388782947455e-08\n",
      "Epoch [12/50], Batch [101/184], Gradient of hidden_layers.0.weight: 6.904625479364768e-05\n",
      "Epoch [12/50], Batch [101/184], Gradient of output_layer.weight: 9.447435149922967e-05\n",
      "Epoch [12/50], Batch [102/184], Gradient of input_bn.weight: -4.426692612469196e-08\n",
      "Epoch [12/50], Batch [102/184], Gradient of input_bn.bias: 1.2510375199781265e-05\n",
      "Epoch [12/50], Batch [102/184], Gradient of hidden_bns.0.weight: 4.636255653167609e-06\n",
      "Epoch [12/50], Batch [102/184], Gradient of hidden_bns.0.bias: 4.559976150630973e-05\n",
      "Epoch [12/50], Batch [102/184], Gradient of input_layer.weight: -1.1249409936908705e-07\n",
      "Epoch [12/50], Batch [102/184], Gradient of hidden_layers.0.weight: 0.00018864810408558697\n",
      "Epoch [12/50], Batch [102/184], Gradient of output_layer.weight: 0.00016805734776426107\n",
      "Epoch [12/50], Batch [103/184], Gradient of input_bn.weight: -3.4739059628918767e-07\n",
      "Epoch [12/50], Batch [103/184], Gradient of input_bn.bias: 1.3030223271925934e-05\n",
      "Epoch [12/50], Batch [103/184], Gradient of hidden_bns.0.weight: 7.337589522649068e-06\n",
      "Epoch [12/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.397286779247224e-05\n",
      "Epoch [12/50], Batch [103/184], Gradient of input_layer.weight: -6.052168259884638e-07\n",
      "Epoch [12/50], Batch [103/184], Gradient of hidden_layers.0.weight: 0.00028885583742521703\n",
      "Epoch [12/50], Batch [103/184], Gradient of output_layer.weight: 0.0001881426724139601\n",
      "Epoch [12/50], Loss: 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████                             | 12/50 [1:52:40<5:56:37, 563.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3299\n",
      "Epoch [13/50], Batch [1/184], Gradient of input_bn.weight: 2.906399458879605e-07\n",
      "Epoch [13/50], Batch [1/184], Gradient of input_bn.bias: 1.0701709470595233e-05\n",
      "Epoch [13/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.5283879949711263e-06\n",
      "Epoch [13/50], Batch [1/184], Gradient of hidden_bns.0.bias: -7.990040467120707e-05\n",
      "Epoch [13/50], Batch [1/184], Gradient of input_layer.weight: 5.047905915489537e-08\n",
      "Epoch [13/50], Batch [1/184], Gradient of hidden_layers.0.weight: -7.73692227085121e-05\n",
      "Epoch [13/50], Batch [1/184], Gradient of output_layer.weight: 6.557972665177658e-05\n",
      "Epoch [13/50], Batch [2/184], Gradient of input_bn.weight: 1.432490535080433e-07\n",
      "Epoch [13/50], Batch [2/184], Gradient of input_bn.bias: 6.580229637620505e-06\n",
      "Epoch [13/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.4891797945892904e-06\n",
      "Epoch [13/50], Batch [2/184], Gradient of hidden_bns.0.bias: 3.1558760383632034e-05\n",
      "Epoch [13/50], Batch [2/184], Gradient of input_layer.weight: -3.4458732756093013e-08\n",
      "Epoch [13/50], Batch [2/184], Gradient of hidden_layers.0.weight: 5.389652869780548e-05\n",
      "Epoch [13/50], Batch [2/184], Gradient of output_layer.weight: 0.0001230533089255914\n",
      "Epoch [13/50], Batch [3/184], Gradient of input_bn.weight: 1.9010076357517391e-07\n",
      "Epoch [13/50], Batch [3/184], Gradient of input_bn.bias: 1.722052547847852e-05\n",
      "Epoch [13/50], Batch [3/184], Gradient of hidden_bns.0.weight: 9.317735930380877e-06\n",
      "Epoch [13/50], Batch [3/184], Gradient of hidden_bns.0.bias: 6.491171370726079e-05\n",
      "Epoch [13/50], Batch [3/184], Gradient of input_layer.weight: 4.049208257583814e-08\n",
      "Epoch [13/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.1877875294885598e-05\n",
      "Epoch [13/50], Batch [3/184], Gradient of output_layer.weight: 0.00017635422409512103\n",
      "Epoch [13/50], Batch [101/184], Gradient of input_bn.weight: 3.3055039239116013e-07\n",
      "Epoch [13/50], Batch [101/184], Gradient of input_bn.bias: 1.1147942132083699e-05\n",
      "Epoch [13/50], Batch [101/184], Gradient of hidden_bns.0.weight: 4.064992026542313e-06\n",
      "Epoch [13/50], Batch [101/184], Gradient of hidden_bns.0.bias: 5.6490527640562505e-05\n",
      "Epoch [13/50], Batch [101/184], Gradient of input_layer.weight: 4.015369370335975e-08\n",
      "Epoch [13/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00019984865502920002\n",
      "Epoch [13/50], Batch [101/184], Gradient of output_layer.weight: 0.00016444965149275959\n",
      "Epoch [13/50], Batch [102/184], Gradient of input_bn.weight: 1.9986237020930275e-07\n",
      "Epoch [13/50], Batch [102/184], Gradient of input_bn.bias: 7.183070920291357e-06\n",
      "Epoch [13/50], Batch [102/184], Gradient of hidden_bns.0.weight: -5.172162218514131e-07\n",
      "Epoch [13/50], Batch [102/184], Gradient of hidden_bns.0.bias: -4.187906961305998e-05\n",
      "Epoch [13/50], Batch [102/184], Gradient of input_layer.weight: 6.648377404161465e-09\n",
      "Epoch [13/50], Batch [102/184], Gradient of hidden_layers.0.weight: -3.2410862331744283e-05\n",
      "Epoch [13/50], Batch [102/184], Gradient of output_layer.weight: 5.0479698984418064e-05\n",
      "Epoch [13/50], Batch [103/184], Gradient of input_bn.weight: 6.767568265786394e-07\n",
      "Epoch [13/50], Batch [103/184], Gradient of input_bn.bias: 4.516700209933333e-05\n",
      "Epoch [13/50], Batch [103/184], Gradient of hidden_bns.0.weight: 9.059494914254174e-06\n",
      "Epoch [13/50], Batch [103/184], Gradient of hidden_bns.0.bias: -0.00017511346959508955\n",
      "Epoch [13/50], Batch [103/184], Gradient of input_layer.weight: 1.5969551236949542e-09\n",
      "Epoch [13/50], Batch [103/184], Gradient of hidden_layers.0.weight: 7.859762263251469e-05\n",
      "Epoch [13/50], Batch [103/184], Gradient of output_layer.weight: 0.00021632720017805696\n",
      "Epoch [13/50], Loss: 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|█████████▉                            | 13/50 [2:02:04<5:47:26, 563.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3299\n",
      "Epoch [14/50], Batch [1/184], Gradient of input_bn.weight: 5.605306796496734e-07\n",
      "Epoch [14/50], Batch [1/184], Gradient of input_bn.bias: 1.1135524800920393e-05\n",
      "Epoch [14/50], Batch [1/184], Gradient of hidden_bns.0.weight: 3.108847522526048e-06\n",
      "Epoch [14/50], Batch [1/184], Gradient of hidden_bns.0.bias: 4.9143734941026196e-05\n",
      "Epoch [14/50], Batch [1/184], Gradient of input_layer.weight: -1.5226584437755264e-08\n",
      "Epoch [14/50], Batch [1/184], Gradient of hidden_layers.0.weight: -5.0072329031536356e-05\n",
      "Epoch [14/50], Batch [1/184], Gradient of output_layer.weight: 0.00021510380611289293\n",
      "Epoch [14/50], Batch [2/184], Gradient of input_bn.weight: 4.965295374859124e-07\n",
      "Epoch [14/50], Batch [2/184], Gradient of input_bn.bias: -3.34552169078961e-07\n",
      "Epoch [14/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.392164449498523e-06\n",
      "Epoch [14/50], Batch [2/184], Gradient of hidden_bns.0.bias: 4.5780740038026124e-05\n",
      "Epoch [14/50], Batch [2/184], Gradient of input_layer.weight: 4.937390585268986e-08\n",
      "Epoch [14/50], Batch [2/184], Gradient of hidden_layers.0.weight: -6.433339876821265e-05\n",
      "Epoch [14/50], Batch [2/184], Gradient of output_layer.weight: 0.00021270185243338346\n",
      "Epoch [14/50], Batch [3/184], Gradient of input_bn.weight: 1.4947636373108253e-07\n",
      "Epoch [14/50], Batch [3/184], Gradient of input_bn.bias: 4.8014812819019426e-06\n",
      "Epoch [14/50], Batch [3/184], Gradient of hidden_bns.0.weight: 2.830000994435977e-06\n",
      "Epoch [14/50], Batch [3/184], Gradient of hidden_bns.0.bias: 4.582027031574398e-06\n",
      "Epoch [14/50], Batch [3/184], Gradient of input_layer.weight: -6.537682839535819e-09\n",
      "Epoch [14/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.128890941501595e-05\n",
      "Epoch [14/50], Batch [3/184], Gradient of output_layer.weight: 8.756162424106151e-05\n",
      "Epoch [14/50], Batch [101/184], Gradient of input_bn.weight: 7.28403392713517e-07\n",
      "Epoch [14/50], Batch [101/184], Gradient of input_bn.bias: 4.511690349318087e-05\n",
      "Epoch [14/50], Batch [101/184], Gradient of hidden_bns.0.weight: 6.571489393536467e-06\n",
      "Epoch [14/50], Batch [101/184], Gradient of hidden_bns.0.bias: -0.00017473466868977994\n",
      "Epoch [14/50], Batch [101/184], Gradient of input_layer.weight: -3.966682626810325e-08\n",
      "Epoch [14/50], Batch [101/184], Gradient of hidden_layers.0.weight: 0.0002537737600505352\n",
      "Epoch [14/50], Batch [101/184], Gradient of output_layer.weight: 0.00025093957083299756\n",
      "Epoch [14/50], Batch [102/184], Gradient of input_bn.weight: 1.895568857435137e-07\n",
      "Epoch [14/50], Batch [102/184], Gradient of input_bn.bias: 1.2695072655333206e-05\n",
      "Epoch [14/50], Batch [102/184], Gradient of hidden_bns.0.weight: 2.35174684348749e-06\n",
      "Epoch [14/50], Batch [102/184], Gradient of hidden_bns.0.bias: 4.523023380897939e-05\n",
      "Epoch [14/50], Batch [102/184], Gradient of input_layer.weight: 8.406530582760752e-07\n",
      "Epoch [14/50], Batch [102/184], Gradient of hidden_layers.0.weight: 9.869031055131927e-05\n",
      "Epoch [14/50], Batch [102/184], Gradient of output_layer.weight: 0.0002271851699333638\n",
      "Epoch [14/50], Batch [103/184], Gradient of input_bn.weight: 5.229230737313628e-08\n",
      "Epoch [14/50], Batch [103/184], Gradient of input_bn.bias: 1.029213126457762e-05\n",
      "Epoch [14/50], Batch [103/184], Gradient of hidden_bns.0.weight: 4.313601039029891e-06\n",
      "Epoch [14/50], Batch [103/184], Gradient of hidden_bns.0.bias: 3.9790713344700634e-05\n",
      "Epoch [14/50], Batch [103/184], Gradient of input_layer.weight: -9.99017188973994e-08\n",
      "Epoch [14/50], Batch [103/184], Gradient of hidden_layers.0.weight: 0.00010758198914118111\n",
      "Epoch [14/50], Batch [103/184], Gradient of output_layer.weight: 0.00012056854029651731\n",
      "Epoch [14/50], Loss: 0.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████▋                           | 14/50 [2:11:28<5:38:00, 563.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3298\n",
      "Epoch [15/50], Batch [1/184], Gradient of input_bn.weight: 1.9514118321239948e-07\n",
      "Epoch [15/50], Batch [1/184], Gradient of input_bn.bias: 1.3385997590376064e-05\n",
      "Epoch [15/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.9490784072550014e-06\n",
      "Epoch [15/50], Batch [1/184], Gradient of hidden_bns.0.bias: 5.794630487798713e-05\n",
      "Epoch [15/50], Batch [1/184], Gradient of input_layer.weight: -1.660568038630572e-08\n",
      "Epoch [15/50], Batch [1/184], Gradient of hidden_layers.0.weight: 2.3540853362646885e-05\n",
      "Epoch [15/50], Batch [1/184], Gradient of output_layer.weight: 0.00018321526295039803\n",
      "Epoch [15/50], Batch [2/184], Gradient of input_bn.weight: 2.745837264228612e-07\n",
      "Epoch [15/50], Batch [2/184], Gradient of input_bn.bias: 7.959901267895475e-06\n",
      "Epoch [15/50], Batch [2/184], Gradient of hidden_bns.0.weight: -3.3363448892487213e-07\n",
      "Epoch [15/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.2611606254940853e-05\n",
      "Epoch [15/50], Batch [2/184], Gradient of input_layer.weight: -4.272665776738904e-08\n",
      "Epoch [15/50], Batch [2/184], Gradient of hidden_layers.0.weight: -3.366442979313433e-05\n",
      "Epoch [15/50], Batch [2/184], Gradient of output_layer.weight: 0.00011595073738135397\n",
      "Epoch [15/50], Batch [3/184], Gradient of input_bn.weight: 2.516480890335515e-07\n",
      "Epoch [15/50], Batch [3/184], Gradient of input_bn.bias: 9.902619240165222e-06\n",
      "Epoch [15/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.2918612810608465e-06\n",
      "Epoch [15/50], Batch [3/184], Gradient of hidden_bns.0.bias: 3.41360064339824e-05\n",
      "Epoch [15/50], Batch [3/184], Gradient of input_layer.weight: -3.403369586152394e-09\n",
      "Epoch [15/50], Batch [3/184], Gradient of hidden_layers.0.weight: 6.657681660726666e-05\n",
      "Epoch [15/50], Batch [3/184], Gradient of output_layer.weight: 0.00011994347005384043\n",
      "Epoch [15/50], Batch [101/184], Gradient of input_bn.weight: 1.4804754755459726e-07\n",
      "Epoch [15/50], Batch [101/184], Gradient of input_bn.bias: 5.633352884615306e-06\n",
      "Epoch [15/50], Batch [101/184], Gradient of hidden_bns.0.weight: 9.052982932189479e-07\n",
      "Epoch [15/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.9406577848712914e-05\n",
      "Epoch [15/50], Batch [101/184], Gradient of input_layer.weight: 3.508395352014304e-08\n",
      "Epoch [15/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00012996949953958392\n",
      "Epoch [15/50], Batch [101/184], Gradient of output_layer.weight: 5.876845170860179e-05\n",
      "Epoch [15/50], Batch [102/184], Gradient of input_bn.weight: 7.005610314081423e-09\n",
      "Epoch [15/50], Batch [102/184], Gradient of input_bn.bias: 8.489290621582768e-07\n",
      "Epoch [15/50], Batch [102/184], Gradient of hidden_bns.0.weight: 5.648905698762974e-08\n",
      "Epoch [15/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.151220658357488e-06\n",
      "Epoch [15/50], Batch [102/184], Gradient of input_layer.weight: 6.786070594344551e-10\n",
      "Epoch [15/50], Batch [102/184], Gradient of hidden_layers.0.weight: -9.847821274888702e-06\n",
      "Epoch [15/50], Batch [102/184], Gradient of output_layer.weight: 1.217750377691118e-05\n",
      "Epoch [15/50], Batch [103/184], Gradient of input_bn.weight: 4.646149136533495e-07\n",
      "Epoch [15/50], Batch [103/184], Gradient of input_bn.bias: 2.0479743398027495e-05\n",
      "Epoch [15/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.866934210032923e-06\n",
      "Epoch [15/50], Batch [103/184], Gradient of hidden_bns.0.bias: -4.523686584434472e-05\n",
      "Epoch [15/50], Batch [103/184], Gradient of input_layer.weight: -4.681358234392974e-08\n",
      "Epoch [15/50], Batch [103/184], Gradient of hidden_layers.0.weight: -1.5877354599069804e-05\n",
      "Epoch [15/50], Batch [103/184], Gradient of output_layer.weight: 9.029681677930057e-05\n",
      "Epoch [15/50], Loss: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▍                          | 15/50 [2:20:51<5:28:35, 563.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3298\n",
      "Epoch [16/50], Batch [1/184], Gradient of input_bn.weight: 1.8689024727791548e-07\n",
      "Epoch [16/50], Batch [1/184], Gradient of input_bn.bias: 4.771240128320642e-06\n",
      "Epoch [16/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.028746621363098e-06\n",
      "Epoch [16/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.3767948985332623e-05\n",
      "Epoch [16/50], Batch [1/184], Gradient of input_layer.weight: -2.4059174208446166e-08\n",
      "Epoch [16/50], Batch [1/184], Gradient of hidden_layers.0.weight: 7.368755905190483e-05\n",
      "Epoch [16/50], Batch [1/184], Gradient of output_layer.weight: 7.148238364607096e-05\n",
      "Epoch [16/50], Batch [2/184], Gradient of input_bn.weight: 9.347422746941447e-08\n",
      "Epoch [16/50], Batch [2/184], Gradient of input_bn.bias: -1.0037797437689733e-06\n",
      "Epoch [16/50], Batch [2/184], Gradient of hidden_bns.0.weight: 6.607126579183387e-07\n",
      "Epoch [16/50], Batch [2/184], Gradient of hidden_bns.0.bias: 9.144989235210232e-06\n",
      "Epoch [16/50], Batch [2/184], Gradient of input_layer.weight: -1.001709293291242e-08\n",
      "Epoch [16/50], Batch [2/184], Gradient of hidden_layers.0.weight: -3.8219342968659475e-05\n",
      "Epoch [16/50], Batch [2/184], Gradient of output_layer.weight: 4.087040724698454e-05\n",
      "Epoch [16/50], Batch [3/184], Gradient of input_bn.weight: 9.22022707072756e-07\n",
      "Epoch [16/50], Batch [3/184], Gradient of input_bn.bias: 5.076818342786282e-05\n",
      "Epoch [16/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.107057323679328e-05\n",
      "Epoch [16/50], Batch [3/184], Gradient of hidden_bns.0.bias: -1.1610776709858328e-05\n",
      "Epoch [16/50], Batch [3/184], Gradient of input_layer.weight: -7.450913130924164e-08\n",
      "Epoch [16/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.6907722510950407e-07\n",
      "Epoch [16/50], Batch [3/184], Gradient of output_layer.weight: 0.0003105933719780296\n",
      "Epoch [16/50], Batch [101/184], Gradient of input_bn.weight: 1.9393701222725213e-07\n",
      "Epoch [16/50], Batch [101/184], Gradient of input_bn.bias: 2.0984653019695543e-06\n",
      "Epoch [16/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.7215643310919404e-07\n",
      "Epoch [16/50], Batch [101/184], Gradient of hidden_bns.0.bias: -1.0862195267691277e-06\n",
      "Epoch [16/50], Batch [101/184], Gradient of input_layer.weight: -4.096852634916104e-08\n",
      "Epoch [16/50], Batch [101/184], Gradient of hidden_layers.0.weight: -2.832582322298549e-05\n",
      "Epoch [16/50], Batch [101/184], Gradient of output_layer.weight: 4.599940439220518e-05\n",
      "Epoch [16/50], Batch [102/184], Gradient of input_bn.weight: 3.1721265258966014e-07\n",
      "Epoch [16/50], Batch [102/184], Gradient of input_bn.bias: 1.7135422240244225e-05\n",
      "Epoch [16/50], Batch [102/184], Gradient of hidden_bns.0.weight: -4.731048647954594e-06\n",
      "Epoch [16/50], Batch [102/184], Gradient of hidden_bns.0.bias: -2.9465662009897642e-05\n",
      "Epoch [16/50], Batch [102/184], Gradient of input_layer.weight: -8.79706050227469e-08\n",
      "Epoch [16/50], Batch [102/184], Gradient of hidden_layers.0.weight: -2.8204378395457752e-05\n",
      "Epoch [16/50], Batch [102/184], Gradient of output_layer.weight: 8.29521959531121e-05\n",
      "Epoch [16/50], Batch [103/184], Gradient of input_bn.weight: 1.3495537132257596e-07\n",
      "Epoch [16/50], Batch [103/184], Gradient of input_bn.bias: 1.8503842511563562e-06\n",
      "Epoch [16/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.9646149667096324e-06\n",
      "Epoch [16/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.6250032786047086e-05\n",
      "Epoch [16/50], Batch [103/184], Gradient of input_layer.weight: 5.838329641960627e-08\n",
      "Epoch [16/50], Batch [103/184], Gradient of hidden_layers.0.weight: -7.803681000950746e-06\n",
      "Epoch [16/50], Batch [103/184], Gradient of output_layer.weight: 8.12214202596806e-05\n",
      "Epoch [16/50], Loss: 0.3304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▏                         | 16/50 [2:30:14<5:19:17, 563.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3298\n",
      "Epoch [17/50], Batch [1/184], Gradient of input_bn.weight: 3.467721398919821e-07\n",
      "Epoch [17/50], Batch [1/184], Gradient of input_bn.bias: 6.983500497881323e-06\n",
      "Epoch [17/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.972919562831521e-06\n",
      "Epoch [17/50], Batch [1/184], Gradient of hidden_bns.0.bias: 6.311391189228743e-06\n",
      "Epoch [17/50], Batch [1/184], Gradient of input_layer.weight: -1.0659809390745068e-07\n",
      "Epoch [17/50], Batch [1/184], Gradient of hidden_layers.0.weight: 6.113076960900798e-05\n",
      "Epoch [17/50], Batch [1/184], Gradient of output_layer.weight: 0.00012269265425857157\n",
      "Epoch [17/50], Batch [2/184], Gradient of input_bn.weight: -1.0262738214805722e-07\n",
      "Epoch [17/50], Batch [2/184], Gradient of input_bn.bias: 7.467942850780673e-06\n",
      "Epoch [17/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.8523064682085533e-06\n",
      "Epoch [17/50], Batch [2/184], Gradient of hidden_bns.0.bias: -2.5294972147094086e-05\n",
      "Epoch [17/50], Batch [2/184], Gradient of input_layer.weight: -2.801513971917302e-07\n",
      "Epoch [17/50], Batch [2/184], Gradient of hidden_layers.0.weight: 0.0001004065852612257\n",
      "Epoch [17/50], Batch [2/184], Gradient of output_layer.weight: 0.00012539183080662042\n",
      "Epoch [17/50], Batch [3/184], Gradient of input_bn.weight: 6.806203600717708e-08\n",
      "Epoch [17/50], Batch [3/184], Gradient of input_bn.bias: 6.898534593346994e-06\n",
      "Epoch [17/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.814986262616003e-06\n",
      "Epoch [17/50], Batch [3/184], Gradient of hidden_bns.0.bias: 3.727473085746169e-07\n",
      "Epoch [17/50], Batch [3/184], Gradient of input_layer.weight: 8.500536807787284e-08\n",
      "Epoch [17/50], Batch [3/184], Gradient of hidden_layers.0.weight: 3.590823689592071e-05\n",
      "Epoch [17/50], Batch [3/184], Gradient of output_layer.weight: 9.123542986344546e-05\n",
      "Epoch [17/50], Batch [101/184], Gradient of input_bn.weight: 3.078480403928552e-07\n",
      "Epoch [17/50], Batch [101/184], Gradient of input_bn.bias: 8.405317203141749e-06\n",
      "Epoch [17/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.1282749003148638e-06\n",
      "Epoch [17/50], Batch [101/184], Gradient of hidden_bns.0.bias: 8.932598575484008e-06\n",
      "Epoch [17/50], Batch [101/184], Gradient of input_layer.weight: -1.4645285872916247e-08\n",
      "Epoch [17/50], Batch [101/184], Gradient of hidden_layers.0.weight: -2.4298351490870118e-05\n",
      "Epoch [17/50], Batch [101/184], Gradient of output_layer.weight: 9.07004505279474e-05\n",
      "Epoch [17/50], Batch [102/184], Gradient of input_bn.weight: 3.166824171785265e-07\n",
      "Epoch [17/50], Batch [102/184], Gradient of input_bn.bias: 4.572388206725009e-06\n",
      "Epoch [17/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.783636202570051e-06\n",
      "Epoch [17/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.1508509234990925e-05\n",
      "Epoch [17/50], Batch [102/184], Gradient of input_layer.weight: 1.2136699467646395e-07\n",
      "Epoch [17/50], Batch [102/184], Gradient of hidden_layers.0.weight: -0.00016191182658076286\n",
      "Epoch [17/50], Batch [102/184], Gradient of output_layer.weight: 0.00011506016016937792\n",
      "Epoch [17/50], Batch [103/184], Gradient of input_bn.weight: 2.0142761059105396e-07\n",
      "Epoch [17/50], Batch [103/184], Gradient of input_bn.bias: 1.1560783605091274e-05\n",
      "Epoch [17/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.7956017472897656e-06\n",
      "Epoch [17/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.0080790161737241e-05\n",
      "Epoch [17/50], Batch [103/184], Gradient of input_layer.weight: 2.2677305366869405e-08\n",
      "Epoch [17/50], Batch [103/184], Gradient of hidden_layers.0.weight: -8.701700426172465e-05\n",
      "Epoch [17/50], Batch [103/184], Gradient of output_layer.weight: 8.886634896043688e-05\n",
      "Epoch [17/50], Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████▉                         | 17/50 [2:39:38<5:09:50, 563.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3297\n",
      "Epoch [18/50], Batch [1/184], Gradient of input_bn.weight: 1.879748197097797e-07\n",
      "Epoch [18/50], Batch [1/184], Gradient of input_bn.bias: 1.585221070854459e-06\n",
      "Epoch [18/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.7316743853589287e-06\n",
      "Epoch [18/50], Batch [1/184], Gradient of hidden_bns.0.bias: 7.072448170220014e-06\n",
      "Epoch [18/50], Batch [1/184], Gradient of input_layer.weight: 6.950268272021276e-08\n",
      "Epoch [18/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.8488412024453282e-05\n",
      "Epoch [18/50], Batch [1/184], Gradient of output_layer.weight: 6.985709478612989e-05\n",
      "Epoch [18/50], Batch [2/184], Gradient of input_bn.weight: 5.23546987096779e-07\n",
      "Epoch [18/50], Batch [2/184], Gradient of input_bn.bias: 2.8899066819576547e-05\n",
      "Epoch [18/50], Batch [2/184], Gradient of hidden_bns.0.weight: -2.206837962148711e-06\n",
      "Epoch [18/50], Batch [2/184], Gradient of hidden_bns.0.bias: 3.7116624298505485e-06\n",
      "Epoch [18/50], Batch [2/184], Gradient of input_layer.weight: -1.4588739816190355e-07\n",
      "Epoch [18/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.033103126246715e-05\n",
      "Epoch [18/50], Batch [2/184], Gradient of output_layer.weight: 0.00019740559218917042\n",
      "Epoch [18/50], Batch [3/184], Gradient of input_bn.weight: 8.327560863108374e-08\n",
      "Epoch [18/50], Batch [3/184], Gradient of input_bn.bias: 2.8734225452353712e-06\n",
      "Epoch [18/50], Batch [3/184], Gradient of hidden_bns.0.weight: 2.1484315766429063e-06\n",
      "Epoch [18/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.6496795069542713e-05\n",
      "Epoch [18/50], Batch [3/184], Gradient of input_layer.weight: 1.1241197306333106e-08\n",
      "Epoch [18/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.353152583760675e-05\n",
      "Epoch [18/50], Batch [3/184], Gradient of output_layer.weight: 6.327258597593755e-05\n",
      "Epoch [18/50], Batch [101/184], Gradient of input_bn.weight: 1.703801899566315e-07\n",
      "Epoch [18/50], Batch [101/184], Gradient of input_bn.bias: 1.0543635653448291e-05\n",
      "Epoch [18/50], Batch [101/184], Gradient of hidden_bns.0.weight: -5.561109446716728e-06\n",
      "Epoch [18/50], Batch [101/184], Gradient of hidden_bns.0.bias: -7.83183077146532e-06\n",
      "Epoch [18/50], Batch [101/184], Gradient of input_layer.weight: -7.319718520193419e-08\n",
      "Epoch [18/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.4999706763774157e-05\n",
      "Epoch [18/50], Batch [101/184], Gradient of output_layer.weight: 6.455520633608103e-05\n",
      "Epoch [18/50], Batch [102/184], Gradient of input_bn.weight: 3.567583917174488e-08\n",
      "Epoch [18/50], Batch [102/184], Gradient of input_bn.bias: 4.759586772706825e-06\n",
      "Epoch [18/50], Batch [102/184], Gradient of hidden_bns.0.weight: -8.365318535652477e-07\n",
      "Epoch [18/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.5195554624369834e-05\n",
      "Epoch [18/50], Batch [102/184], Gradient of input_layer.weight: -2.464984305561302e-08\n",
      "Epoch [18/50], Batch [102/184], Gradient of hidden_layers.0.weight: -3.2957304938463494e-05\n",
      "Epoch [18/50], Batch [102/184], Gradient of output_layer.weight: 4.68936086690519e-05\n",
      "Epoch [18/50], Batch [103/184], Gradient of input_bn.weight: 1.3126737030688673e-07\n",
      "Epoch [18/50], Batch [103/184], Gradient of input_bn.bias: 5.197321115701925e-06\n",
      "Epoch [18/50], Batch [103/184], Gradient of hidden_bns.0.weight: -8.258621164713986e-08\n",
      "Epoch [18/50], Batch [103/184], Gradient of hidden_bns.0.bias: 8.37936022435315e-06\n",
      "Epoch [18/50], Batch [103/184], Gradient of input_layer.weight: -1.4935102399249445e-07\n",
      "Epoch [18/50], Batch [103/184], Gradient of hidden_layers.0.weight: 4.471174179343507e-05\n",
      "Epoch [18/50], Batch [103/184], Gradient of output_layer.weight: 8.511276973877102e-05\n",
      "Epoch [18/50], Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████▋                        | 18/50 [2:49:01<5:00:25, 563.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3297\n",
      "Epoch [19/50], Batch [1/184], Gradient of input_bn.weight: 2.5410645321244374e-07\n",
      "Epoch [19/50], Batch [1/184], Gradient of input_bn.bias: 6.735758688591886e-06\n",
      "Epoch [19/50], Batch [1/184], Gradient of hidden_bns.0.weight: -4.352547875896562e-06\n",
      "Epoch [19/50], Batch [1/184], Gradient of hidden_bns.0.bias: -2.2760204956284724e-05\n",
      "Epoch [19/50], Batch [1/184], Gradient of input_layer.weight: -3.731013009655726e-08\n",
      "Epoch [19/50], Batch [1/184], Gradient of hidden_layers.0.weight: -3.2826246751938015e-05\n",
      "Epoch [19/50], Batch [1/184], Gradient of output_layer.weight: 7.938381895655766e-05\n",
      "Epoch [19/50], Batch [2/184], Gradient of input_bn.weight: 1.5938894648570567e-07\n",
      "Epoch [19/50], Batch [2/184], Gradient of input_bn.bias: 7.05244474374922e-07\n",
      "Epoch [19/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.3630588000523858e-06\n",
      "Epoch [19/50], Batch [2/184], Gradient of hidden_bns.0.bias: 8.296373380289879e-06\n",
      "Epoch [19/50], Batch [2/184], Gradient of input_layer.weight: 4.325617641853796e-09\n",
      "Epoch [19/50], Batch [2/184], Gradient of hidden_layers.0.weight: -7.657661626581103e-05\n",
      "Epoch [19/50], Batch [2/184], Gradient of output_layer.weight: 4.2867304728133604e-05\n",
      "Epoch [19/50], Batch [3/184], Gradient of input_bn.weight: 2.6628731575328857e-07\n",
      "Epoch [19/50], Batch [3/184], Gradient of input_bn.bias: 6.631432370340917e-06\n",
      "Epoch [19/50], Batch [3/184], Gradient of hidden_bns.0.weight: -9.1037281890749e-07\n",
      "Epoch [19/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.800961010507308e-05\n",
      "Epoch [19/50], Batch [3/184], Gradient of input_layer.weight: -1.1034456015579508e-08\n",
      "Epoch [19/50], Batch [3/184], Gradient of hidden_layers.0.weight: -7.04914637026377e-05\n",
      "Epoch [19/50], Batch [3/184], Gradient of output_layer.weight: 0.0001092346865334548\n",
      "Epoch [19/50], Batch [101/184], Gradient of input_bn.weight: 7.095877663232386e-08\n",
      "Epoch [19/50], Batch [101/184], Gradient of input_bn.bias: 1.3145534467184916e-05\n",
      "Epoch [19/50], Batch [101/184], Gradient of hidden_bns.0.weight: -4.146249921177514e-08\n",
      "Epoch [19/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.809933721437119e-05\n",
      "Epoch [19/50], Batch [101/184], Gradient of input_layer.weight: -1.6522864143553306e-07\n",
      "Epoch [19/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.0001354870037175715\n",
      "Epoch [19/50], Batch [101/184], Gradient of output_layer.weight: 9.084869816433638e-05\n",
      "Epoch [19/50], Batch [102/184], Gradient of input_bn.weight: 3.557488525984809e-09\n",
      "Epoch [19/50], Batch [102/184], Gradient of input_bn.bias: 6.039129516466346e-07\n",
      "Epoch [19/50], Batch [102/184], Gradient of hidden_bns.0.weight: -5.669817255693488e-07\n",
      "Epoch [19/50], Batch [102/184], Gradient of hidden_bns.0.bias: 3.1935326205712045e-07\n",
      "Epoch [19/50], Batch [102/184], Gradient of input_layer.weight: -2.026316003878037e-08\n",
      "Epoch [19/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.159187377197668e-06\n",
      "Epoch [19/50], Batch [102/184], Gradient of output_layer.weight: 4.652813913708087e-06\n",
      "Epoch [19/50], Batch [103/184], Gradient of input_bn.weight: 2.1495725377462804e-07\n",
      "Epoch [19/50], Batch [103/184], Gradient of input_bn.bias: 9.901914381771348e-06\n",
      "Epoch [19/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.9299886844237335e-07\n",
      "Epoch [19/50], Batch [103/184], Gradient of hidden_bns.0.bias: 4.293997335480526e-05\n",
      "Epoch [19/50], Batch [103/184], Gradient of input_layer.weight: -1.3059950276783638e-07\n",
      "Epoch [19/50], Batch [103/184], Gradient of hidden_layers.0.weight: 0.0001363682677038014\n",
      "Epoch [19/50], Batch [103/184], Gradient of output_layer.weight: 0.00014749440015293658\n",
      "Epoch [19/50], Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████▍                       | 19/50 [2:58:25<4:51:09, 563.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3297\n",
      "Epoch [20/50], Batch [1/184], Gradient of input_bn.weight: 7.309472493943758e-08\n",
      "Epoch [20/50], Batch [1/184], Gradient of input_bn.bias: 3.1860358831181657e-06\n",
      "Epoch [20/50], Batch [1/184], Gradient of hidden_bns.0.weight: 1.1410738807171583e-06\n",
      "Epoch [20/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.3237175153335556e-05\n",
      "Epoch [20/50], Batch [1/184], Gradient of input_layer.weight: -1.6094436006142132e-08\n",
      "Epoch [20/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.730658914311789e-05\n",
      "Epoch [20/50], Batch [1/184], Gradient of output_layer.weight: 5.497224992723204e-05\n",
      "Epoch [20/50], Batch [2/184], Gradient of input_bn.weight: -3.152963472530246e-07\n",
      "Epoch [20/50], Batch [2/184], Gradient of input_bn.bias: 3.7145382520975545e-06\n",
      "Epoch [20/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.7571483112988062e-06\n",
      "Epoch [20/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.511331538495142e-05\n",
      "Epoch [20/50], Batch [2/184], Gradient of input_layer.weight: -1.374907924400759e-06\n",
      "Epoch [20/50], Batch [2/184], Gradient of hidden_layers.0.weight: -0.00017564426525495946\n",
      "Epoch [20/50], Batch [2/184], Gradient of output_layer.weight: 0.00010623736307024956\n",
      "Epoch [20/50], Batch [3/184], Gradient of input_bn.weight: 8.820279617793858e-09\n",
      "Epoch [20/50], Batch [3/184], Gradient of input_bn.bias: 6.059432962501887e-06\n",
      "Epoch [20/50], Batch [3/184], Gradient of hidden_bns.0.weight: -5.322940523910802e-07\n",
      "Epoch [20/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.328352456970606e-05\n",
      "Epoch [20/50], Batch [3/184], Gradient of input_layer.weight: -2.507117642380763e-07\n",
      "Epoch [20/50], Batch [3/184], Gradient of hidden_layers.0.weight: -7.662540883757174e-05\n",
      "Epoch [20/50], Batch [3/184], Gradient of output_layer.weight: 8.231365791289136e-05\n",
      "Epoch [20/50], Batch [101/184], Gradient of input_bn.weight: 3.1738090910948813e-07\n",
      "Epoch [20/50], Batch [101/184], Gradient of input_bn.bias: 1.1944999641855247e-05\n",
      "Epoch [20/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.0896559362881817e-06\n",
      "Epoch [20/50], Batch [101/184], Gradient of hidden_bns.0.bias: 4.812392216990702e-05\n",
      "Epoch [20/50], Batch [101/184], Gradient of input_layer.weight: -4.2500605701434324e-08\n",
      "Epoch [20/50], Batch [101/184], Gradient of hidden_layers.0.weight: 8.911361510399729e-05\n",
      "Epoch [20/50], Batch [101/184], Gradient of output_layer.weight: 0.00015539352898485959\n",
      "Epoch [20/50], Batch [102/184], Gradient of input_bn.weight: 1.2698910722974688e-07\n",
      "Epoch [20/50], Batch [102/184], Gradient of input_bn.bias: 9.94499623629963e-06\n",
      "Epoch [20/50], Batch [102/184], Gradient of hidden_bns.0.weight: 8.511884516337886e-06\n",
      "Epoch [20/50], Batch [102/184], Gradient of hidden_bns.0.bias: -1.2418120604706928e-05\n",
      "Epoch [20/50], Batch [102/184], Gradient of input_layer.weight: -7.995281947614785e-08\n",
      "Epoch [20/50], Batch [102/184], Gradient of hidden_layers.0.weight: 8.445225830655545e-06\n",
      "Epoch [20/50], Batch [102/184], Gradient of output_layer.weight: 0.00013345491606742144\n",
      "Epoch [20/50], Batch [103/184], Gradient of input_bn.weight: 9.202904038829729e-08\n",
      "Epoch [20/50], Batch [103/184], Gradient of input_bn.bias: 3.886268132191617e-06\n",
      "Epoch [20/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.023242475639563e-06\n",
      "Epoch [20/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.295103629672667e-05\n",
      "Epoch [20/50], Batch [103/184], Gradient of input_layer.weight: -6.913529304597432e-09\n",
      "Epoch [20/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.0186159670411143e-05\n",
      "Epoch [20/50], Batch [103/184], Gradient of output_layer.weight: 4.716750845545903e-05\n",
      "Epoch [20/50], Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▏                      | 20/50 [3:07:48<4:41:43, 563.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3297\n",
      "Epoch [21/50], Batch [1/184], Gradient of input_bn.weight: 2.0041989046148956e-07\n",
      "Epoch [21/50], Batch [1/184], Gradient of input_bn.bias: 4.904994511889527e-06\n",
      "Epoch [21/50], Batch [1/184], Gradient of hidden_bns.0.weight: 1.321946911048144e-06\n",
      "Epoch [21/50], Batch [1/184], Gradient of hidden_bns.0.bias: 4.295600228942931e-05\n",
      "Epoch [21/50], Batch [1/184], Gradient of input_layer.weight: 9.117091082089246e-09\n",
      "Epoch [21/50], Batch [1/184], Gradient of hidden_layers.0.weight: 4.653566065826453e-05\n",
      "Epoch [21/50], Batch [1/184], Gradient of output_layer.weight: 0.00013104041863698512\n",
      "Epoch [21/50], Batch [2/184], Gradient of input_bn.weight: 1.570333552081138e-07\n",
      "Epoch [21/50], Batch [2/184], Gradient of input_bn.bias: 1.9884988432750106e-05\n",
      "Epoch [21/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.0570741980918683e-06\n",
      "Epoch [21/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.111992216669023e-05\n",
      "Epoch [21/50], Batch [2/184], Gradient of input_layer.weight: -2.388944686515515e-08\n",
      "Epoch [21/50], Batch [2/184], Gradient of hidden_layers.0.weight: 7.57362213335e-05\n",
      "Epoch [21/50], Batch [2/184], Gradient of output_layer.weight: 0.00015466351760551333\n",
      "Epoch [21/50], Batch [3/184], Gradient of input_bn.weight: -1.526555024611298e-07\n",
      "Epoch [21/50], Batch [3/184], Gradient of input_bn.bias: 9.370320185553282e-06\n",
      "Epoch [21/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.796649368974613e-06\n",
      "Epoch [21/50], Batch [3/184], Gradient of hidden_bns.0.bias: -6.219790520844981e-06\n",
      "Epoch [21/50], Batch [3/184], Gradient of input_layer.weight: -1.2398057833706844e-06\n",
      "Epoch [21/50], Batch [3/184], Gradient of hidden_layers.0.weight: 2.69521424343111e-05\n",
      "Epoch [21/50], Batch [3/184], Gradient of output_layer.weight: 0.00012150373368058354\n",
      "Epoch [21/50], Batch [101/184], Gradient of input_bn.weight: -9.367249731440097e-08\n",
      "Epoch [21/50], Batch [101/184], Gradient of input_bn.bias: 7.173252015491016e-06\n",
      "Epoch [21/50], Batch [101/184], Gradient of hidden_bns.0.weight: -1.941667733262875e-06\n",
      "Epoch [21/50], Batch [101/184], Gradient of hidden_bns.0.bias: -5.108133336761966e-06\n",
      "Epoch [21/50], Batch [101/184], Gradient of input_layer.weight: 8.727926825713439e-08\n",
      "Epoch [21/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.0001069739373633638\n",
      "Epoch [21/50], Batch [101/184], Gradient of output_layer.weight: 7.87302415119484e-05\n",
      "Epoch [21/50], Batch [102/184], Gradient of input_bn.weight: 1.962694113899488e-07\n",
      "Epoch [21/50], Batch [102/184], Gradient of input_bn.bias: 1.9528997654560953e-06\n",
      "Epoch [21/50], Batch [102/184], Gradient of hidden_bns.0.weight: -1.349309286524658e-07\n",
      "Epoch [21/50], Batch [102/184], Gradient of hidden_bns.0.bias: -1.173033524537459e-06\n",
      "Epoch [21/50], Batch [102/184], Gradient of input_layer.weight: -5.080242004851243e-08\n",
      "Epoch [21/50], Batch [102/184], Gradient of hidden_layers.0.weight: -2.131602741428651e-05\n",
      "Epoch [21/50], Batch [102/184], Gradient of output_layer.weight: 4.918032936984673e-05\n",
      "Epoch [21/50], Batch [103/184], Gradient of input_bn.weight: 2.9266311685205437e-07\n",
      "Epoch [21/50], Batch [103/184], Gradient of input_bn.bias: 6.908408977324143e-06\n",
      "Epoch [21/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.3969020074000582e-07\n",
      "Epoch [21/50], Batch [103/184], Gradient of hidden_bns.0.bias: 3.239116631448269e-05\n",
      "Epoch [21/50], Batch [103/184], Gradient of input_layer.weight: -2.8042625999091797e-08\n",
      "Epoch [21/50], Batch [103/184], Gradient of hidden_layers.0.weight: -1.528046777821146e-05\n",
      "Epoch [21/50], Batch [103/184], Gradient of output_layer.weight: 0.00011229453230043873\n",
      "Epoch [21/50], Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|███████████████▉                      | 21/50 [3:17:12<4:32:23, 563.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3296\n",
      "Epoch [22/50], Batch [1/184], Gradient of input_bn.weight: 3.4699496609391645e-08\n",
      "Epoch [22/50], Batch [1/184], Gradient of input_bn.bias: 7.237132422233117e-07\n",
      "Epoch [22/50], Batch [1/184], Gradient of hidden_bns.0.weight: 1.4879542504786514e-06\n",
      "Epoch [22/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.1723149327735882e-05\n",
      "Epoch [22/50], Batch [1/184], Gradient of input_layer.weight: -2.9845885762824764e-08\n",
      "Epoch [22/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.469076505600242e-05\n",
      "Epoch [22/50], Batch [1/184], Gradient of output_layer.weight: 4.0547984099248424e-05\n",
      "Epoch [22/50], Batch [2/184], Gradient of input_bn.weight: 6.334539648378268e-08\n",
      "Epoch [22/50], Batch [2/184], Gradient of input_bn.bias: 4.1435359889874235e-06\n",
      "Epoch [22/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.807247826945968e-07\n",
      "Epoch [22/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.918058842420578e-05\n",
      "Epoch [22/50], Batch [2/184], Gradient of input_layer.weight: -9.589623317651785e-08\n",
      "Epoch [22/50], Batch [2/184], Gradient of hidden_layers.0.weight: 3.9459435356548056e-05\n",
      "Epoch [22/50], Batch [2/184], Gradient of output_layer.weight: 7.919404015410691e-05\n",
      "Epoch [22/50], Batch [3/184], Gradient of input_bn.weight: 6.389518603100441e-08\n",
      "Epoch [22/50], Batch [3/184], Gradient of input_bn.bias: 1.557984091959952e-06\n",
      "Epoch [22/50], Batch [3/184], Gradient of hidden_bns.0.weight: 2.7297255655867048e-06\n",
      "Epoch [22/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.4634238798171282e-05\n",
      "Epoch [22/50], Batch [3/184], Gradient of input_layer.weight: -4.109774209837269e-08\n",
      "Epoch [22/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.587816768733319e-05\n",
      "Epoch [22/50], Batch [3/184], Gradient of output_layer.weight: 6.374476652126759e-05\n",
      "Epoch [22/50], Batch [101/184], Gradient of input_bn.weight: 1.104390321415849e-07\n",
      "Epoch [22/50], Batch [101/184], Gradient of input_bn.bias: 4.146674655203242e-06\n",
      "Epoch [22/50], Batch [101/184], Gradient of hidden_bns.0.weight: -1.057774397850153e-06\n",
      "Epoch [22/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.8700628061196767e-05\n",
      "Epoch [22/50], Batch [101/184], Gradient of input_layer.weight: 2.9018311309414457e-08\n",
      "Epoch [22/50], Batch [101/184], Gradient of hidden_layers.0.weight: -5.4341191571438685e-05\n",
      "Epoch [22/50], Batch [101/184], Gradient of output_layer.weight: 7.901629578555003e-05\n",
      "Epoch [22/50], Batch [102/184], Gradient of input_bn.weight: -3.912930424121441e-09\n",
      "Epoch [22/50], Batch [102/184], Gradient of input_bn.bias: 8.236996507093863e-08\n",
      "Epoch [22/50], Batch [102/184], Gradient of hidden_bns.0.weight: 3.6726390817420906e-08\n",
      "Epoch [22/50], Batch [102/184], Gradient of hidden_bns.0.bias: -1.1667168564599706e-07\n",
      "Epoch [22/50], Batch [102/184], Gradient of input_layer.weight: -3.4093154965830763e-09\n",
      "Epoch [22/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.520516320852039e-06\n",
      "Epoch [22/50], Batch [102/184], Gradient of output_layer.weight: 3.9121810004871804e-06\n",
      "Epoch [22/50], Batch [103/184], Gradient of input_bn.weight: 2.7689020498655736e-07\n",
      "Epoch [22/50], Batch [103/184], Gradient of input_bn.bias: 4.602079570759088e-06\n",
      "Epoch [22/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.9041599443880841e-06\n",
      "Epoch [22/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.8474434657255188e-05\n",
      "Epoch [22/50], Batch [103/184], Gradient of input_layer.weight: -3.2521549542252615e-07\n",
      "Epoch [22/50], Batch [103/184], Gradient of hidden_layers.0.weight: 6.50939327897504e-05\n",
      "Epoch [22/50], Batch [103/184], Gradient of output_layer.weight: 0.00015913812967482954\n",
      "Epoch [22/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████▋                     | 22/50 [3:26:36<4:23:00, 563.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3296\n",
      "Epoch [23/50], Batch [1/184], Gradient of input_bn.weight: 3.767149792111013e-08\n",
      "Epoch [23/50], Batch [1/184], Gradient of input_bn.bias: 4.620546860678587e-06\n",
      "Epoch [23/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.8998207451659255e-07\n",
      "Epoch [23/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.1746020391001366e-05\n",
      "Epoch [23/50], Batch [1/184], Gradient of input_layer.weight: -2.143772981355596e-08\n",
      "Epoch [23/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.1329760127409827e-05\n",
      "Epoch [23/50], Batch [1/184], Gradient of output_layer.weight: 4.970489317202009e-05\n",
      "Epoch [23/50], Batch [2/184], Gradient of input_bn.weight: 2.009392119362019e-07\n",
      "Epoch [23/50], Batch [2/184], Gradient of input_bn.bias: 4.90136926600826e-06\n",
      "Epoch [23/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.3606327229354065e-06\n",
      "Epoch [23/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.632029307074845e-05\n",
      "Epoch [23/50], Batch [2/184], Gradient of input_layer.weight: -2.7123395085482116e-08\n",
      "Epoch [23/50], Batch [2/184], Gradient of hidden_layers.0.weight: 4.634381184587255e-05\n",
      "Epoch [23/50], Batch [2/184], Gradient of output_layer.weight: 6.957871664781123e-05\n",
      "Epoch [23/50], Batch [3/184], Gradient of input_bn.weight: 4.343819455243647e-07\n",
      "Epoch [23/50], Batch [3/184], Gradient of input_bn.bias: 3.061365714529529e-05\n",
      "Epoch [23/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.188847015029751e-06\n",
      "Epoch [23/50], Batch [3/184], Gradient of hidden_bns.0.bias: -9.580861660651863e-05\n",
      "Epoch [23/50], Batch [3/184], Gradient of input_layer.weight: -8.645151261532646e-09\n",
      "Epoch [23/50], Batch [3/184], Gradient of hidden_layers.0.weight: 0.00010791977547341958\n",
      "Epoch [23/50], Batch [3/184], Gradient of output_layer.weight: 0.00014767181710340083\n",
      "Epoch [23/50], Batch [101/184], Gradient of input_bn.weight: 3.774748620344326e-07\n",
      "Epoch [23/50], Batch [101/184], Gradient of input_bn.bias: 1.557666837470606e-05\n",
      "Epoch [23/50], Batch [101/184], Gradient of hidden_bns.0.weight: -6.950804163352586e-07\n",
      "Epoch [23/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.910044324584305e-05\n",
      "Epoch [23/50], Batch [101/184], Gradient of input_layer.weight: -3.248139535116934e-08\n",
      "Epoch [23/50], Batch [101/184], Gradient of hidden_layers.0.weight: 0.00011100435949629173\n",
      "Epoch [23/50], Batch [101/184], Gradient of output_layer.weight: 0.00016933200822677463\n",
      "Epoch [23/50], Batch [102/184], Gradient of input_bn.weight: 1.4439723372561275e-07\n",
      "Epoch [23/50], Batch [102/184], Gradient of input_bn.bias: 4.726724000647664e-06\n",
      "Epoch [23/50], Batch [102/184], Gradient of hidden_bns.0.weight: -9.246728041034658e-07\n",
      "Epoch [23/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.3538252460421063e-05\n",
      "Epoch [23/50], Batch [102/184], Gradient of input_layer.weight: -4.844891776656368e-08\n",
      "Epoch [23/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.4740537608304294e-06\n",
      "Epoch [23/50], Batch [102/184], Gradient of output_layer.weight: 8.437426731688902e-05\n",
      "Epoch [23/50], Batch [103/184], Gradient of input_bn.weight: 3.1880199458100833e-07\n",
      "Epoch [23/50], Batch [103/184], Gradient of input_bn.bias: 1.7427753846277483e-05\n",
      "Epoch [23/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.719799795158906e-06\n",
      "Epoch [23/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.906153430463746e-06\n",
      "Epoch [23/50], Batch [103/184], Gradient of input_layer.weight: -6.979529132422613e-08\n",
      "Epoch [23/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.90930823009694e-05\n",
      "Epoch [23/50], Batch [103/184], Gradient of output_layer.weight: 0.00012461779988370836\n",
      "Epoch [23/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████▍                    | 23/50 [3:35:59<4:13:33, 563.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3296\n",
      "Epoch [24/50], Batch [1/184], Gradient of input_bn.weight: 2.5767667466425337e-07\n",
      "Epoch [24/50], Batch [1/184], Gradient of input_bn.bias: 1.272796725970693e-05\n",
      "Epoch [24/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.1976591142447433e-06\n",
      "Epoch [24/50], Batch [1/184], Gradient of hidden_bns.0.bias: -2.097174001391977e-05\n",
      "Epoch [24/50], Batch [1/184], Gradient of input_layer.weight: -5.150340953719024e-08\n",
      "Epoch [24/50], Batch [1/184], Gradient of hidden_layers.0.weight: -8.56227234180551e-06\n",
      "Epoch [24/50], Batch [1/184], Gradient of output_layer.weight: 6.629393465118483e-05\n",
      "Epoch [24/50], Batch [2/184], Gradient of input_bn.weight: 1.94378117157612e-07\n",
      "Epoch [24/50], Batch [2/184], Gradient of input_bn.bias: 8.182996680261567e-06\n",
      "Epoch [24/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.685410097707063e-06\n",
      "Epoch [24/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.6391715689678676e-05\n",
      "Epoch [24/50], Batch [2/184], Gradient of input_layer.weight: -6.194787260938028e-08\n",
      "Epoch [24/50], Batch [2/184], Gradient of hidden_layers.0.weight: 3.3945339964702725e-05\n",
      "Epoch [24/50], Batch [2/184], Gradient of output_layer.weight: 0.00010003638453781605\n",
      "Epoch [24/50], Batch [3/184], Gradient of input_bn.weight: 4.90194906888064e-08\n",
      "Epoch [24/50], Batch [3/184], Gradient of input_bn.bias: 2.918306563515216e-06\n",
      "Epoch [24/50], Batch [3/184], Gradient of hidden_bns.0.weight: 6.013008260197239e-07\n",
      "Epoch [24/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.2845563105656765e-05\n",
      "Epoch [24/50], Batch [3/184], Gradient of input_layer.weight: -1.1507447439385032e-08\n",
      "Epoch [24/50], Batch [3/184], Gradient of hidden_layers.0.weight: -2.9346480005187914e-05\n",
      "Epoch [24/50], Batch [3/184], Gradient of output_layer.weight: 3.871041189995594e-05\n",
      "Epoch [24/50], Batch [101/184], Gradient of input_bn.weight: 1.0930534699582495e-08\n",
      "Epoch [24/50], Batch [101/184], Gradient of input_bn.bias: 5.936466322964407e-07\n",
      "Epoch [24/50], Batch [101/184], Gradient of hidden_bns.0.weight: -1.6686783510522218e-07\n",
      "Epoch [24/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.7921670405485202e-06\n",
      "Epoch [24/50], Batch [101/184], Gradient of input_layer.weight: -3.311475760270355e-09\n",
      "Epoch [24/50], Batch [101/184], Gradient of hidden_layers.0.weight: -6.7139808379579335e-06\n",
      "Epoch [24/50], Batch [101/184], Gradient of output_layer.weight: 7.925088539195713e-06\n",
      "Epoch [24/50], Batch [102/184], Gradient of input_bn.weight: 2.1110372472321615e-07\n",
      "Epoch [24/50], Batch [102/184], Gradient of input_bn.bias: 9.401566785527393e-06\n",
      "Epoch [24/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.6412529880180955e-08\n",
      "Epoch [24/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.6480593078304082e-05\n",
      "Epoch [24/50], Batch [102/184], Gradient of input_layer.weight: -4.1579202303410057e-08\n",
      "Epoch [24/50], Batch [102/184], Gradient of hidden_layers.0.weight: 9.746685464051552e-06\n",
      "Epoch [24/50], Batch [102/184], Gradient of output_layer.weight: 0.00010982250387314707\n",
      "Epoch [24/50], Batch [103/184], Gradient of input_bn.weight: 2.7977603167528287e-07\n",
      "Epoch [24/50], Batch [103/184], Gradient of input_bn.bias: 7.355368325079326e-06\n",
      "Epoch [24/50], Batch [103/184], Gradient of hidden_bns.0.weight: -8.051147233345546e-07\n",
      "Epoch [24/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.559954737080261e-05\n",
      "Epoch [24/50], Batch [103/184], Gradient of input_layer.weight: -1.991869780226807e-08\n",
      "Epoch [24/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.5773017114261165e-05\n",
      "Epoch [24/50], Batch [103/184], Gradient of output_layer.weight: 9.939266601577401e-05\n",
      "Epoch [24/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████▏                   | 24/50 [3:45:22<4:04:11, 563.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3296\n",
      "Epoch [25/50], Batch [1/184], Gradient of input_bn.weight: 2.8074737201677635e-07\n",
      "Epoch [25/50], Batch [1/184], Gradient of input_bn.bias: 1.3536549886339344e-05\n",
      "Epoch [25/50], Batch [1/184], Gradient of hidden_bns.0.weight: 4.8002916628320236e-06\n",
      "Epoch [25/50], Batch [1/184], Gradient of hidden_bns.0.bias: -4.8763773520477116e-05\n",
      "Epoch [25/50], Batch [1/184], Gradient of input_layer.weight: 2.447138847117003e-08\n",
      "Epoch [25/50], Batch [1/184], Gradient of hidden_layers.0.weight: 5.585956751019694e-05\n",
      "Epoch [25/50], Batch [1/184], Gradient of output_layer.weight: 9.002200386021286e-05\n",
      "Epoch [25/50], Batch [2/184], Gradient of input_bn.weight: 4.2825649870792404e-07\n",
      "Epoch [25/50], Batch [2/184], Gradient of input_bn.bias: 1.6923229850362986e-05\n",
      "Epoch [25/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.7133406799985096e-06\n",
      "Epoch [25/50], Batch [2/184], Gradient of hidden_bns.0.bias: -4.910056304652244e-06\n",
      "Epoch [25/50], Batch [2/184], Gradient of input_layer.weight: -1.2553890371691523e-07\n",
      "Epoch [25/50], Batch [2/184], Gradient of hidden_layers.0.weight: -5.821304876008071e-05\n",
      "Epoch [25/50], Batch [2/184], Gradient of output_layer.weight: 0.00017196318367496133\n",
      "Epoch [25/50], Batch [3/184], Gradient of input_bn.weight: 3.834941253444413e-08\n",
      "Epoch [25/50], Batch [3/184], Gradient of input_bn.bias: 7.561797019661753e-07\n",
      "Epoch [25/50], Batch [3/184], Gradient of hidden_bns.0.weight: 3.7185236578807235e-07\n",
      "Epoch [25/50], Batch [3/184], Gradient of hidden_bns.0.bias: 8.82968379301019e-07\n",
      "Epoch [25/50], Batch [3/184], Gradient of input_layer.weight: -1.2216262668118816e-08\n",
      "Epoch [25/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.488046215556096e-06\n",
      "Epoch [25/50], Batch [3/184], Gradient of output_layer.weight: 1.4318697139970027e-05\n",
      "Epoch [25/50], Batch [101/184], Gradient of input_bn.weight: 9.664290701039135e-08\n",
      "Epoch [25/50], Batch [101/184], Gradient of input_bn.bias: 3.610077783378074e-06\n",
      "Epoch [25/50], Batch [101/184], Gradient of hidden_bns.0.weight: 3.7631116356351413e-07\n",
      "Epoch [25/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.4702498194528744e-05\n",
      "Epoch [25/50], Batch [101/184], Gradient of input_layer.weight: 1.0188720089843173e-08\n",
      "Epoch [25/50], Batch [101/184], Gradient of hidden_layers.0.weight: -8.1475249317009e-05\n",
      "Epoch [25/50], Batch [101/184], Gradient of output_layer.weight: 7.689942140132189e-05\n",
      "Epoch [25/50], Batch [102/184], Gradient of input_bn.weight: 2.871413471439155e-07\n",
      "Epoch [25/50], Batch [102/184], Gradient of input_bn.bias: -2.1261223537294427e-06\n",
      "Epoch [25/50], Batch [102/184], Gradient of hidden_bns.0.weight: -2.1441426270030206e-06\n",
      "Epoch [25/50], Batch [102/184], Gradient of hidden_bns.0.bias: 7.861832273192704e-06\n",
      "Epoch [25/50], Batch [102/184], Gradient of input_layer.weight: -1.8367609655456363e-08\n",
      "Epoch [25/50], Batch [102/184], Gradient of hidden_layers.0.weight: 5.887252427783096e-06\n",
      "Epoch [25/50], Batch [102/184], Gradient of output_layer.weight: 8.425171108683571e-05\n",
      "Epoch [25/50], Batch [103/184], Gradient of input_bn.weight: 7.907829058240168e-09\n",
      "Epoch [25/50], Batch [103/184], Gradient of input_bn.bias: 4.424488793119963e-07\n",
      "Epoch [25/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.071629410238529e-07\n",
      "Epoch [25/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.0354887055873405e-06\n",
      "Epoch [25/50], Batch [103/184], Gradient of input_layer.weight: -4.3783110470485553e-10\n",
      "Epoch [25/50], Batch [103/184], Gradient of hidden_layers.0.weight: 2.673369635886047e-06\n",
      "Epoch [25/50], Batch [103/184], Gradient of output_layer.weight: 6.287398264248623e-06\n",
      "Epoch [25/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████                   | 25/50 [3:54:46<3:54:48, 563.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3296\n",
      "Epoch [26/50], Batch [1/184], Gradient of input_bn.weight: 2.6584643819660414e-07\n",
      "Epoch [26/50], Batch [1/184], Gradient of input_bn.bias: 1.0631611985445488e-05\n",
      "Epoch [26/50], Batch [1/184], Gradient of hidden_bns.0.weight: 4.527333203441231e-06\n",
      "Epoch [26/50], Batch [1/184], Gradient of hidden_bns.0.bias: 2.5710782210808247e-05\n",
      "Epoch [26/50], Batch [1/184], Gradient of input_layer.weight: -8.026272979577698e-08\n",
      "Epoch [26/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.2261548363312613e-05\n",
      "Epoch [26/50], Batch [1/184], Gradient of output_layer.weight: 0.00012742448598146439\n",
      "Epoch [26/50], Batch [2/184], Gradient of input_bn.weight: 5.62963577976916e-08\n",
      "Epoch [26/50], Batch [2/184], Gradient of input_bn.bias: 6.024185950082028e-07\n",
      "Epoch [26/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.1758007733296836e-06\n",
      "Epoch [26/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.7777076209313236e-05\n",
      "Epoch [26/50], Batch [2/184], Gradient of input_layer.weight: -9.51547551863996e-09\n",
      "Epoch [26/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.1786878530983813e-05\n",
      "Epoch [26/50], Batch [2/184], Gradient of output_layer.weight: 4.743872705148533e-05\n",
      "Epoch [26/50], Batch [3/184], Gradient of input_bn.weight: 3.0046066967770457e-07\n",
      "Epoch [26/50], Batch [3/184], Gradient of input_bn.bias: 1.3713904991163872e-05\n",
      "Epoch [26/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.1320456653484143e-06\n",
      "Epoch [26/50], Batch [3/184], Gradient of hidden_bns.0.bias: -3.536065196385607e-05\n",
      "Epoch [26/50], Batch [3/184], Gradient of input_layer.weight: -7.103023591525925e-08\n",
      "Epoch [26/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.336863275966607e-05\n",
      "Epoch [26/50], Batch [3/184], Gradient of output_layer.weight: 9.500658779870719e-05\n",
      "Epoch [26/50], Batch [101/184], Gradient of input_bn.weight: 8.189817890524864e-08\n",
      "Epoch [26/50], Batch [101/184], Gradient of input_bn.bias: 9.996176231652498e-06\n",
      "Epoch [26/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.874301117117284e-06\n",
      "Epoch [26/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.123444548691623e-05\n",
      "Epoch [26/50], Batch [101/184], Gradient of input_layer.weight: -2.033748387475498e-07\n",
      "Epoch [26/50], Batch [101/184], Gradient of hidden_layers.0.weight: 0.00011945667210966349\n",
      "Epoch [26/50], Batch [101/184], Gradient of output_layer.weight: 0.0001025188248604536\n",
      "Epoch [26/50], Batch [102/184], Gradient of input_bn.weight: 2.60077285929583e-07\n",
      "Epoch [26/50], Batch [102/184], Gradient of input_bn.bias: 6.286021744017489e-06\n",
      "Epoch [26/50], Batch [102/184], Gradient of hidden_bns.0.weight: -2.027443315455457e-06\n",
      "Epoch [26/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.1154321327921934e-05\n",
      "Epoch [26/50], Batch [102/184], Gradient of input_layer.weight: -2.8016291508947688e-08\n",
      "Epoch [26/50], Batch [102/184], Gradient of hidden_layers.0.weight: 8.502767013851553e-05\n",
      "Epoch [26/50], Batch [102/184], Gradient of output_layer.weight: 8.928594616008922e-05\n",
      "Epoch [26/50], Batch [103/184], Gradient of input_bn.weight: 1.066428012563847e-08\n",
      "Epoch [26/50], Batch [103/184], Gradient of input_bn.bias: 4.135472408961505e-06\n",
      "Epoch [26/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.0873821995337494e-06\n",
      "Epoch [26/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.7167590815224685e-05\n",
      "Epoch [26/50], Batch [103/184], Gradient of input_layer.weight: -3.063652442847342e-08\n",
      "Epoch [26/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.6724385204724967e-05\n",
      "Epoch [26/50], Batch [103/184], Gradient of output_layer.weight: 7.169252057792619e-05\n",
      "Epoch [26/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|███████████████████▊                  | 26/50 [4:04:09<3:45:21, 563.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [27/50], Batch [1/184], Gradient of input_bn.weight: 3.210002432751935e-07\n",
      "Epoch [27/50], Batch [1/184], Gradient of input_bn.bias: 9.04152329894714e-06\n",
      "Epoch [27/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.5283443392254412e-06\n",
      "Epoch [27/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.0203961210208945e-05\n",
      "Epoch [27/50], Batch [1/184], Gradient of input_layer.weight: -4.776862638777857e-08\n",
      "Epoch [27/50], Batch [1/184], Gradient of hidden_layers.0.weight: -2.6237948986818083e-05\n",
      "Epoch [27/50], Batch [1/184], Gradient of output_layer.weight: 9.304793638875708e-05\n",
      "Epoch [27/50], Batch [2/184], Gradient of input_bn.weight: 3.649961399787571e-08\n",
      "Epoch [27/50], Batch [2/184], Gradient of input_bn.bias: 3.328320644868654e-06\n",
      "Epoch [27/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.355042397539364e-06\n",
      "Epoch [27/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.3452341338270344e-05\n",
      "Epoch [27/50], Batch [2/184], Gradient of input_layer.weight: -1.1655268750132564e-08\n",
      "Epoch [27/50], Batch [2/184], Gradient of hidden_layers.0.weight: -1.049579896061914e-05\n",
      "Epoch [27/50], Batch [2/184], Gradient of output_layer.weight: 5.9298712585587054e-05\n",
      "Epoch [27/50], Batch [3/184], Gradient of input_bn.weight: 2.5885583454510197e-08\n",
      "Epoch [27/50], Batch [3/184], Gradient of input_bn.bias: -3.694060524139786e-08\n",
      "Epoch [27/50], Batch [3/184], Gradient of hidden_bns.0.weight: -4.937592166243121e-07\n",
      "Epoch [27/50], Batch [3/184], Gradient of hidden_bns.0.bias: 6.801802783229505e-07\n",
      "Epoch [27/50], Batch [3/184], Gradient of input_layer.weight: -5.01556440823947e-09\n",
      "Epoch [27/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.9471586862637196e-06\n",
      "Epoch [27/50], Batch [3/184], Gradient of output_layer.weight: 7.2514303610660136e-06\n",
      "Epoch [27/50], Batch [101/184], Gradient of input_bn.weight: 6.42717168375384e-08\n",
      "Epoch [27/50], Batch [101/184], Gradient of input_bn.bias: 2.0926172510371543e-06\n",
      "Epoch [27/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.2607188182300888e-07\n",
      "Epoch [27/50], Batch [101/184], Gradient of hidden_bns.0.bias: 5.360806426324416e-06\n",
      "Epoch [27/50], Batch [101/184], Gradient of input_layer.weight: -8.32635915770652e-09\n",
      "Epoch [27/50], Batch [101/184], Gradient of hidden_layers.0.weight: -8.624931979284156e-06\n",
      "Epoch [27/50], Batch [101/184], Gradient of output_layer.weight: 3.588126492104493e-05\n",
      "Epoch [27/50], Batch [102/184], Gradient of input_bn.weight: 1.0567691788310185e-07\n",
      "Epoch [27/50], Batch [102/184], Gradient of input_bn.bias: 5.927014626649907e-06\n",
      "Epoch [27/50], Batch [102/184], Gradient of hidden_bns.0.weight: 2.6297666408936493e-06\n",
      "Epoch [27/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.1302399545675144e-05\n",
      "Epoch [27/50], Batch [102/184], Gradient of input_layer.weight: 2.3181014441320258e-08\n",
      "Epoch [27/50], Batch [102/184], Gradient of hidden_layers.0.weight: 2.9324290153454058e-05\n",
      "Epoch [27/50], Batch [102/184], Gradient of output_layer.weight: 6.867548654554412e-05\n",
      "Epoch [27/50], Batch [103/184], Gradient of input_bn.weight: 3.437671693973243e-07\n",
      "Epoch [27/50], Batch [103/184], Gradient of input_bn.bias: 1.269975837203674e-05\n",
      "Epoch [27/50], Batch [103/184], Gradient of hidden_bns.0.weight: 3.76797925127903e-06\n",
      "Epoch [27/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.367380410665646e-05\n",
      "Epoch [27/50], Batch [103/184], Gradient of input_layer.weight: -7.897291709468846e-09\n",
      "Epoch [27/50], Batch [103/184], Gradient of hidden_layers.0.weight: -7.801249012118205e-05\n",
      "Epoch [27/50], Batch [103/184], Gradient of output_layer.weight: 0.00019312943913973868\n",
      "Epoch [27/50], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████▌                 | 27/50 [4:13:33<3:35:59, 563.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [28/50], Batch [1/184], Gradient of input_bn.weight: 3.5845050661009736e-07\n",
      "Epoch [28/50], Batch [1/184], Gradient of input_bn.bias: 1.1012662980647292e-05\n",
      "Epoch [28/50], Batch [1/184], Gradient of hidden_bns.0.weight: -5.8832379181694705e-06\n",
      "Epoch [28/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.8807550077326596e-05\n",
      "Epoch [28/50], Batch [1/184], Gradient of input_layer.weight: -8.183002364603453e-08\n",
      "Epoch [28/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.9194494598195888e-05\n",
      "Epoch [28/50], Batch [1/184], Gradient of output_layer.weight: 0.00011670928506646305\n",
      "Epoch [28/50], Batch [2/184], Gradient of input_bn.weight: 2.692195266718045e-07\n",
      "Epoch [28/50], Batch [2/184], Gradient of input_bn.bias: 6.037171260686591e-06\n",
      "Epoch [28/50], Batch [2/184], Gradient of hidden_bns.0.weight: 4.208936843497213e-07\n",
      "Epoch [28/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.650740134413354e-05\n",
      "Epoch [28/50], Batch [2/184], Gradient of input_layer.weight: 1.158353080121799e-09\n",
      "Epoch [28/50], Batch [2/184], Gradient of hidden_layers.0.weight: -9.547754598315805e-05\n",
      "Epoch [28/50], Batch [2/184], Gradient of output_layer.weight: 0.0001226505555678159\n",
      "Epoch [28/50], Batch [3/184], Gradient of input_bn.weight: 2.5598774300306104e-07\n",
      "Epoch [28/50], Batch [3/184], Gradient of input_bn.bias: 1.2527596481959336e-05\n",
      "Epoch [28/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.671259269642178e-06\n",
      "Epoch [28/50], Batch [3/184], Gradient of hidden_bns.0.bias: -3.148443647660315e-05\n",
      "Epoch [28/50], Batch [3/184], Gradient of input_layer.weight: -2.164911627744459e-08\n",
      "Epoch [28/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.3535582183976658e-05\n",
      "Epoch [28/50], Batch [3/184], Gradient of output_layer.weight: 6.817263783887029e-05\n",
      "Epoch [28/50], Batch [101/184], Gradient of input_bn.weight: 2.098895492963493e-07\n",
      "Epoch [28/50], Batch [101/184], Gradient of input_bn.bias: 1.837400850490667e-05\n",
      "Epoch [28/50], Batch [101/184], Gradient of hidden_bns.0.weight: 3.114582796115428e-06\n",
      "Epoch [28/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.263652615714818e-05\n",
      "Epoch [28/50], Batch [101/184], Gradient of input_layer.weight: -2.5613253740175423e-08\n",
      "Epoch [28/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00013426072837319225\n",
      "Epoch [28/50], Batch [101/184], Gradient of output_layer.weight: 0.0001387715310556814\n",
      "Epoch [28/50], Batch [102/184], Gradient of input_bn.weight: 9.023312941280892e-08\n",
      "Epoch [28/50], Batch [102/184], Gradient of input_bn.bias: 5.7430597735219635e-06\n",
      "Epoch [28/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.6901451494486537e-06\n",
      "Epoch [28/50], Batch [102/184], Gradient of hidden_bns.0.bias: -3.701642981468467e-06\n",
      "Epoch [28/50], Batch [102/184], Gradient of input_layer.weight: -4.035225842358159e-08\n",
      "Epoch [28/50], Batch [102/184], Gradient of hidden_layers.0.weight: 2.6990367132384563e-06\n",
      "Epoch [28/50], Batch [102/184], Gradient of output_layer.weight: 3.487771755317226e-05\n",
      "Epoch [28/50], Batch [103/184], Gradient of input_bn.weight: 5.969559424556792e-08\n",
      "Epoch [28/50], Batch [103/184], Gradient of input_bn.bias: 4.5045071601634845e-06\n",
      "Epoch [28/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.5281383386754896e-06\n",
      "Epoch [28/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.6665586372255348e-05\n",
      "Epoch [28/50], Batch [103/184], Gradient of input_layer.weight: -5.266829194994216e-09\n",
      "Epoch [28/50], Batch [103/184], Gradient of hidden_layers.0.weight: 5.003005935577676e-05\n",
      "Epoch [28/50], Batch [103/184], Gradient of output_layer.weight: 4.243903822498396e-05\n",
      "Epoch [28/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████▎                | 28/50 [4:22:56<3:26:37, 563.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [29/50], Batch [1/184], Gradient of input_bn.weight: 2.0245977339072851e-07\n",
      "Epoch [29/50], Batch [1/184], Gradient of input_bn.bias: 1.1470768185972702e-05\n",
      "Epoch [29/50], Batch [1/184], Gradient of hidden_bns.0.weight: 3.918770289601525e-06\n",
      "Epoch [29/50], Batch [1/184], Gradient of hidden_bns.0.bias: -3.215148899471387e-05\n",
      "Epoch [29/50], Batch [1/184], Gradient of input_layer.weight: 2.9111879573662236e-09\n",
      "Epoch [29/50], Batch [1/184], Gradient of hidden_layers.0.weight: 4.035429810755886e-06\n",
      "Epoch [29/50], Batch [1/184], Gradient of output_layer.weight: 7.575067138532177e-05\n",
      "Epoch [29/50], Batch [2/184], Gradient of input_bn.weight: 9.157565727946348e-08\n",
      "Epoch [29/50], Batch [2/184], Gradient of input_bn.bias: 5.200608029554132e-06\n",
      "Epoch [29/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.955830839506234e-06\n",
      "Epoch [29/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.27810705837328e-05\n",
      "Epoch [29/50], Batch [2/184], Gradient of input_layer.weight: -2.670594234643886e-08\n",
      "Epoch [29/50], Batch [2/184], Gradient of hidden_layers.0.weight: -2.2427084331866354e-05\n",
      "Epoch [29/50], Batch [2/184], Gradient of output_layer.weight: 6.593289435841143e-05\n",
      "Epoch [29/50], Batch [3/184], Gradient of input_bn.weight: 3.633167580119334e-07\n",
      "Epoch [29/50], Batch [3/184], Gradient of input_bn.bias: 1.0844044481927995e-05\n",
      "Epoch [29/50], Batch [3/184], Gradient of hidden_bns.0.weight: -3.2909197216213215e-06\n",
      "Epoch [29/50], Batch [3/184], Gradient of hidden_bns.0.bias: -1.6580555893597193e-05\n",
      "Epoch [29/50], Batch [3/184], Gradient of input_layer.weight: -1.566957053000806e-08\n",
      "Epoch [29/50], Batch [3/184], Gradient of hidden_layers.0.weight: 3.811566421063617e-05\n",
      "Epoch [29/50], Batch [3/184], Gradient of output_layer.weight: 9.208584378939122e-05\n",
      "Epoch [29/50], Batch [101/184], Gradient of input_bn.weight: 3.471541276667267e-08\n",
      "Epoch [29/50], Batch [101/184], Gradient of input_bn.bias: 4.099045781913446e-06\n",
      "Epoch [29/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.5373082078440348e-06\n",
      "Epoch [29/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.7982580175157636e-05\n",
      "Epoch [29/50], Batch [101/184], Gradient of input_layer.weight: -1.8482513297612968e-08\n",
      "Epoch [29/50], Batch [101/184], Gradient of hidden_layers.0.weight: -2.602397944428958e-05\n",
      "Epoch [29/50], Batch [101/184], Gradient of output_layer.weight: 4.9901282181963325e-05\n",
      "Epoch [29/50], Batch [102/184], Gradient of input_bn.weight: 5.717229214496911e-07\n",
      "Epoch [29/50], Batch [102/184], Gradient of input_bn.bias: 1.7269634554395452e-05\n",
      "Epoch [29/50], Batch [102/184], Gradient of hidden_bns.0.weight: 6.900791049702093e-07\n",
      "Epoch [29/50], Batch [102/184], Gradient of hidden_bns.0.bias: 4.8694160796003416e-05\n",
      "Epoch [29/50], Batch [102/184], Gradient of input_layer.weight: -3.713031659913213e-08\n",
      "Epoch [29/50], Batch [102/184], Gradient of hidden_layers.0.weight: 0.0001314054970862344\n",
      "Epoch [29/50], Batch [102/184], Gradient of output_layer.weight: 0.00018412593635730445\n",
      "Epoch [29/50], Batch [103/184], Gradient of input_bn.weight: 6.320697139017284e-07\n",
      "Epoch [29/50], Batch [103/184], Gradient of input_bn.bias: 1.3101582226227038e-05\n",
      "Epoch [29/50], Batch [103/184], Gradient of hidden_bns.0.weight: -7.06332548361388e-06\n",
      "Epoch [29/50], Batch [103/184], Gradient of hidden_bns.0.bias: -3.502268737065606e-05\n",
      "Epoch [29/50], Batch [103/184], Gradient of input_layer.weight: -1.0119702409383535e-07\n",
      "Epoch [29/50], Batch [103/184], Gradient of hidden_layers.0.weight: 5.1428545702947304e-05\n",
      "Epoch [29/50], Batch [103/184], Gradient of output_layer.weight: 0.00014773066504858434\n",
      "Epoch [29/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████                | 29/50 [4:32:20<3:17:16, 563.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [30/50], Batch [1/184], Gradient of input_bn.weight: -1.5941623132675886e-07\n",
      "Epoch [30/50], Batch [1/184], Gradient of input_bn.bias: 2.8415679480531253e-06\n",
      "Epoch [30/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.34810215968173e-06\n",
      "Epoch [30/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.3001495972275734e-05\n",
      "Epoch [30/50], Batch [1/184], Gradient of input_layer.weight: -7.664335726076388e-07\n",
      "Epoch [30/50], Batch [1/184], Gradient of hidden_layers.0.weight: -3.915307024726644e-05\n",
      "Epoch [30/50], Batch [1/184], Gradient of output_layer.weight: 9.660443902248517e-05\n",
      "Epoch [30/50], Batch [2/184], Gradient of input_bn.weight: 9.124346433964092e-08\n",
      "Epoch [30/50], Batch [2/184], Gradient of input_bn.bias: 5.049309947935399e-06\n",
      "Epoch [30/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.8426371752866544e-06\n",
      "Epoch [30/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.2126923795440234e-05\n",
      "Epoch [30/50], Batch [2/184], Gradient of input_layer.weight: -2.954062594540119e-08\n",
      "Epoch [30/50], Batch [2/184], Gradient of hidden_layers.0.weight: 8.76817648531869e-06\n",
      "Epoch [30/50], Batch [2/184], Gradient of output_layer.weight: 6.98056974215433e-05\n",
      "Epoch [30/50], Batch [3/184], Gradient of input_bn.weight: 4.1095063352258876e-08\n",
      "Epoch [30/50], Batch [3/184], Gradient of input_bn.bias: 3.408975317142904e-06\n",
      "Epoch [30/50], Batch [3/184], Gradient of hidden_bns.0.weight: -7.657066589672468e-07\n",
      "Epoch [30/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.0131522685696837e-05\n",
      "Epoch [30/50], Batch [3/184], Gradient of input_layer.weight: -4.327054270447661e-08\n",
      "Epoch [30/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.0423957064631395e-05\n",
      "Epoch [30/50], Batch [3/184], Gradient of output_layer.weight: 3.971670594182797e-05\n",
      "Epoch [30/50], Batch [101/184], Gradient of input_bn.weight: 5.766267463513941e-10\n",
      "Epoch [30/50], Batch [101/184], Gradient of input_bn.bias: 7.442206850782895e-09\n",
      "Epoch [30/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.4184704017216063e-08\n",
      "Epoch [30/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.7292109077970963e-07\n",
      "Epoch [30/50], Batch [101/184], Gradient of input_layer.weight: -1.527346582541611e-10\n",
      "Epoch [30/50], Batch [101/184], Gradient of hidden_layers.0.weight: 4.231721959513379e-07\n",
      "Epoch [30/50], Batch [101/184], Gradient of output_layer.weight: 8.242209332820494e-07\n",
      "Epoch [30/50], Batch [102/184], Gradient of input_bn.weight: 1.7301863408647478e-07\n",
      "Epoch [30/50], Batch [102/184], Gradient of input_bn.bias: 7.766870112391189e-06\n",
      "Epoch [30/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.535851078595442e-07\n",
      "Epoch [30/50], Batch [102/184], Gradient of hidden_bns.0.bias: -5.338665141607635e-05\n",
      "Epoch [30/50], Batch [102/184], Gradient of input_layer.weight: 3.5977322454527894e-08\n",
      "Epoch [30/50], Batch [102/184], Gradient of hidden_layers.0.weight: 7.250321687024552e-06\n",
      "Epoch [30/50], Batch [102/184], Gradient of output_layer.weight: 3.5278349969303235e-05\n",
      "Epoch [30/50], Batch [103/184], Gradient of input_bn.weight: 2.3510438040830195e-07\n",
      "Epoch [30/50], Batch [103/184], Gradient of input_bn.bias: 1.1556340723473113e-05\n",
      "Epoch [30/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.525742274883669e-06\n",
      "Epoch [30/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.287646101554856e-07\n",
      "Epoch [30/50], Batch [103/184], Gradient of input_layer.weight: -7.450771022377012e-08\n",
      "Epoch [30/50], Batch [103/184], Gradient of hidden_layers.0.weight: 5.071060877526179e-05\n",
      "Epoch [30/50], Batch [103/184], Gradient of output_layer.weight: 7.998252840479836e-05\n",
      "Epoch [30/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 30/50 [4:41:44<3:07:50, 563.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [31/50], Batch [1/184], Gradient of input_bn.weight: -4.960111255059019e-08\n",
      "Epoch [31/50], Batch [1/184], Gradient of input_bn.bias: 2.1913747332291678e-06\n",
      "Epoch [31/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.597056663944386e-06\n",
      "Epoch [31/50], Batch [1/184], Gradient of hidden_bns.0.bias: -4.186911610304378e-06\n",
      "Epoch [31/50], Batch [1/184], Gradient of input_layer.weight: -6.97664518156671e-07\n",
      "Epoch [31/50], Batch [1/184], Gradient of hidden_layers.0.weight: -4.6753753849770874e-05\n",
      "Epoch [31/50], Batch [1/184], Gradient of output_layer.weight: 7.141631067497656e-05\n",
      "Epoch [31/50], Batch [2/184], Gradient of input_bn.weight: 3.336649569973815e-07\n",
      "Epoch [31/50], Batch [2/184], Gradient of input_bn.bias: 6.3716506701894104e-06\n",
      "Epoch [31/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.4822861632856075e-07\n",
      "Epoch [31/50], Batch [2/184], Gradient of hidden_bns.0.bias: -1.2873890227638185e-05\n",
      "Epoch [31/50], Batch [2/184], Gradient of input_layer.weight: -5.236753608528488e-08\n",
      "Epoch [31/50], Batch [2/184], Gradient of hidden_layers.0.weight: -1.8920556613011286e-05\n",
      "Epoch [31/50], Batch [2/184], Gradient of output_layer.weight: 5.724181391997263e-05\n",
      "Epoch [31/50], Batch [3/184], Gradient of input_bn.weight: 2.8220620151842013e-07\n",
      "Epoch [31/50], Batch [3/184], Gradient of input_bn.bias: 1.400788823957555e-05\n",
      "Epoch [31/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.8612804524309468e-06\n",
      "Epoch [31/50], Batch [3/184], Gradient of hidden_bns.0.bias: -9.901704470394179e-05\n",
      "Epoch [31/50], Batch [3/184], Gradient of input_layer.weight: 3.245873969603963e-08\n",
      "Epoch [31/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.744639591081068e-05\n",
      "Epoch [31/50], Batch [3/184], Gradient of output_layer.weight: 3.8388378015952185e-05\n",
      "Epoch [31/50], Batch [101/184], Gradient of input_bn.weight: -8.807583071757108e-07\n",
      "Epoch [31/50], Batch [101/184], Gradient of input_bn.bias: -3.232977178413421e-06\n",
      "Epoch [31/50], Batch [101/184], Gradient of hidden_bns.0.weight: -2.589767063909676e-06\n",
      "Epoch [31/50], Batch [101/184], Gradient of hidden_bns.0.bias: 8.856064596329816e-06\n",
      "Epoch [31/50], Batch [101/184], Gradient of input_layer.weight: -1.8737620166575653e-06\n",
      "Epoch [31/50], Batch [101/184], Gradient of hidden_layers.0.weight: -0.00010984928667312488\n",
      "Epoch [31/50], Batch [101/184], Gradient of output_layer.weight: 4.5633707486558706e-05\n",
      "Epoch [31/50], Batch [102/184], Gradient of input_bn.weight: 3.798879788519116e-08\n",
      "Epoch [31/50], Batch [102/184], Gradient of input_bn.bias: -3.7127119867363945e-07\n",
      "Epoch [31/50], Batch [102/184], Gradient of hidden_bns.0.weight: -4.79056723179383e-07\n",
      "Epoch [31/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.952112481580116e-06\n",
      "Epoch [31/50], Batch [102/184], Gradient of input_layer.weight: 1.2038793961721694e-08\n",
      "Epoch [31/50], Batch [102/184], Gradient of hidden_layers.0.weight: 6.859387212898582e-06\n",
      "Epoch [31/50], Batch [102/184], Gradient of output_layer.weight: 1.3599115845863707e-05\n",
      "Epoch [31/50], Batch [103/184], Gradient of input_bn.weight: 1.0457415555720218e-07\n",
      "Epoch [31/50], Batch [103/184], Gradient of input_bn.bias: 5.335539754014462e-06\n",
      "Epoch [31/50], Batch [103/184], Gradient of hidden_bns.0.weight: -2.9498355615942273e-06\n",
      "Epoch [31/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.646112524322234e-06\n",
      "Epoch [31/50], Batch [103/184], Gradient of input_layer.weight: -3.792627012444427e-08\n",
      "Epoch [31/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.6530730135855265e-05\n",
      "Epoch [31/50], Batch [103/184], Gradient of output_layer.weight: 4.296106635592878e-05\n",
      "Epoch [31/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████▌              | 31/50 [4:51:08<2:58:30, 563.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [32/50], Batch [1/184], Gradient of input_bn.weight: 7.099430376911187e-09\n",
      "Epoch [32/50], Batch [1/184], Gradient of input_bn.bias: -1.285547114093788e-06\n",
      "Epoch [32/50], Batch [1/184], Gradient of hidden_bns.0.weight: 9.513244094705442e-07\n",
      "Epoch [32/50], Batch [1/184], Gradient of hidden_bns.0.bias: 8.913717465475202e-06\n",
      "Epoch [32/50], Batch [1/184], Gradient of input_layer.weight: -9.048114257836914e-09\n",
      "Epoch [32/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.1128757932965527e-06\n",
      "Epoch [32/50], Batch [1/184], Gradient of output_layer.weight: 2.4464639864163473e-05\n",
      "Epoch [32/50], Batch [2/184], Gradient of input_bn.weight: 1.1879978956130799e-07\n",
      "Epoch [32/50], Batch [2/184], Gradient of input_bn.bias: 1.0979510079778265e-05\n",
      "Epoch [32/50], Batch [2/184], Gradient of hidden_bns.0.weight: -3.1591639526595827e-06\n",
      "Epoch [32/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.392439273535274e-05\n",
      "Epoch [32/50], Batch [2/184], Gradient of input_layer.weight: -9.362111796917816e-08\n",
      "Epoch [32/50], Batch [2/184], Gradient of hidden_layers.0.weight: 2.5881092824420193e-08\n",
      "Epoch [32/50], Batch [2/184], Gradient of output_layer.weight: 0.0001165070352726616\n",
      "Epoch [32/50], Batch [3/184], Gradient of input_bn.weight: 2.137694536941126e-07\n",
      "Epoch [32/50], Batch [3/184], Gradient of input_bn.bias: -8.262171832029708e-06\n",
      "Epoch [32/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.4563842089264654e-06\n",
      "Epoch [32/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.5223562261089683e-05\n",
      "Epoch [32/50], Batch [3/184], Gradient of input_layer.weight: -2.477561338309897e-07\n",
      "Epoch [32/50], Batch [3/184], Gradient of hidden_layers.0.weight: -2.929970833065454e-05\n",
      "Epoch [32/50], Batch [3/184], Gradient of output_layer.weight: 0.00014652502431999892\n",
      "Epoch [32/50], Batch [101/184], Gradient of input_bn.weight: 4.841717782255728e-08\n",
      "Epoch [32/50], Batch [101/184], Gradient of input_bn.bias: 2.2731678654963616e-06\n",
      "Epoch [32/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.3605313142761588e-06\n",
      "Epoch [32/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.012241409625858e-05\n",
      "Epoch [32/50], Batch [101/184], Gradient of input_layer.weight: 1.22239489641629e-08\n",
      "Epoch [32/50], Batch [101/184], Gradient of hidden_layers.0.weight: 9.609671906218864e-06\n",
      "Epoch [32/50], Batch [101/184], Gradient of output_layer.weight: 2.7574824343901128e-05\n",
      "Epoch [32/50], Batch [102/184], Gradient of input_bn.weight: 3.9721771827316843e-07\n",
      "Epoch [32/50], Batch [102/184], Gradient of input_bn.bias: 1.6419549865531735e-05\n",
      "Epoch [32/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.6667265754222171e-06\n",
      "Epoch [32/50], Batch [102/184], Gradient of hidden_bns.0.bias: -7.321709563257173e-05\n",
      "Epoch [32/50], Batch [102/184], Gradient of input_layer.weight: -6.583537714988097e-09\n",
      "Epoch [32/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.9355427866685204e-05\n",
      "Epoch [32/50], Batch [102/184], Gradient of output_layer.weight: 4.639746475731954e-05\n",
      "Epoch [32/50], Batch [103/184], Gradient of input_bn.weight: 1.501389306213241e-07\n",
      "Epoch [32/50], Batch [103/184], Gradient of input_bn.bias: 6.924210538272746e-06\n",
      "Epoch [32/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.794518539099954e-06\n",
      "Epoch [32/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.507525121269282e-05\n",
      "Epoch [32/50], Batch [103/184], Gradient of input_layer.weight: 3.83112963575627e-09\n",
      "Epoch [32/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.4477161787217483e-05\n",
      "Epoch [32/50], Batch [103/184], Gradient of output_layer.weight: 9.727895667310804e-05\n",
      "Epoch [32/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████▎             | 32/50 [5:00:31<2:49:06, 563.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [33/50], Batch [1/184], Gradient of input_bn.weight: 2.8639078664127737e-07\n",
      "Epoch [33/50], Batch [1/184], Gradient of input_bn.bias: 8.248505764640868e-06\n",
      "Epoch [33/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.7102569220005535e-06\n",
      "Epoch [33/50], Batch [1/184], Gradient of hidden_bns.0.bias: 3.9268736145459116e-05\n",
      "Epoch [33/50], Batch [1/184], Gradient of input_layer.weight: -6.326759205421695e-08\n",
      "Epoch [33/50], Batch [1/184], Gradient of hidden_layers.0.weight: 8.06960160844028e-05\n",
      "Epoch [33/50], Batch [1/184], Gradient of output_layer.weight: 0.00013937440235167742\n",
      "Epoch [33/50], Batch [2/184], Gradient of input_bn.weight: 5.188121576793492e-08\n",
      "Epoch [33/50], Batch [2/184], Gradient of input_bn.bias: 3.981836016464513e-06\n",
      "Epoch [33/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.068274286808446e-07\n",
      "Epoch [33/50], Batch [2/184], Gradient of hidden_bns.0.bias: 5.704357135982718e-06\n",
      "Epoch [33/50], Batch [2/184], Gradient of input_layer.weight: -1.9695681530151887e-08\n",
      "Epoch [33/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.1172715858265292e-05\n",
      "Epoch [33/50], Batch [2/184], Gradient of output_layer.weight: 3.4733333450276405e-05\n",
      "Epoch [33/50], Batch [3/184], Gradient of input_bn.weight: -4.405537765705958e-07\n",
      "Epoch [33/50], Batch [3/184], Gradient of input_bn.bias: -2.351494003960397e-06\n",
      "Epoch [33/50], Batch [3/184], Gradient of hidden_bns.0.weight: -5.111690825287951e-06\n",
      "Epoch [33/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.1929892934858799e-05\n",
      "Epoch [33/50], Batch [3/184], Gradient of input_layer.weight: -1.4455137034019572e-06\n",
      "Epoch [33/50], Batch [3/184], Gradient of hidden_layers.0.weight: -8.677687583258376e-05\n",
      "Epoch [33/50], Batch [3/184], Gradient of output_layer.weight: 0.00014013922191224992\n",
      "Epoch [33/50], Batch [101/184], Gradient of input_bn.weight: -1.209377842315007e-08\n",
      "Epoch [33/50], Batch [101/184], Gradient of input_bn.bias: 4.2365729768789606e-07\n",
      "Epoch [33/50], Batch [101/184], Gradient of hidden_bns.0.weight: -5.987668032503279e-07\n",
      "Epoch [33/50], Batch [101/184], Gradient of hidden_bns.0.bias: -8.275439995486522e-07\n",
      "Epoch [33/50], Batch [101/184], Gradient of input_layer.weight: -7.880264440984774e-09\n",
      "Epoch [33/50], Batch [101/184], Gradient of hidden_layers.0.weight: -5.785060693597188e-06\n",
      "Epoch [33/50], Batch [101/184], Gradient of output_layer.weight: 3.3884648473758716e-06\n",
      "Epoch [33/50], Batch [102/184], Gradient of input_bn.weight: 4.916849150049529e-10\n",
      "Epoch [33/50], Batch [102/184], Gradient of input_bn.bias: 1.2844409980061755e-09\n",
      "Epoch [33/50], Batch [102/184], Gradient of hidden_bns.0.weight: -5.258532276286587e-09\n",
      "Epoch [33/50], Batch [102/184], Gradient of hidden_bns.0.bias: 4.6728647618010655e-08\n",
      "Epoch [33/50], Batch [102/184], Gradient of input_layer.weight: -8.418304942026111e-11\n",
      "Epoch [33/50], Batch [102/184], Gradient of hidden_layers.0.weight: -5.4860734621797747e-08\n",
      "Epoch [33/50], Batch [102/184], Gradient of output_layer.weight: 2.0073801465514407e-07\n",
      "Epoch [33/50], Batch [103/184], Gradient of input_bn.weight: 1.9197977962903678e-07\n",
      "Epoch [33/50], Batch [103/184], Gradient of input_bn.bias: 1.6958533706201706e-06\n",
      "Epoch [33/50], Batch [103/184], Gradient of hidden_bns.0.weight: -9.123095878749155e-08\n",
      "Epoch [33/50], Batch [103/184], Gradient of hidden_bns.0.bias: -3.2602820283500478e-06\n",
      "Epoch [33/50], Batch [103/184], Gradient of input_layer.weight: -3.887207356001454e-08\n",
      "Epoch [33/50], Batch [103/184], Gradient of hidden_layers.0.weight: -3.666749398689717e-05\n",
      "Epoch [33/50], Batch [103/184], Gradient of output_layer.weight: 4.3724983697757125e-05\n",
      "Epoch [33/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████             | 33/50 [5:09:55<2:39:40, 563.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3295\n",
      "Epoch [34/50], Batch [1/184], Gradient of input_bn.weight: 9.52236405282747e-08\n",
      "Epoch [34/50], Batch [1/184], Gradient of input_bn.bias: 5.804243301099632e-06\n",
      "Epoch [34/50], Batch [1/184], Gradient of hidden_bns.0.weight: -7.986602668097476e-07\n",
      "Epoch [34/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.3398554074228741e-05\n",
      "Epoch [34/50], Batch [1/184], Gradient of input_layer.weight: 1.4460737496335696e-08\n",
      "Epoch [34/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.9589224393712357e-05\n",
      "Epoch [34/50], Batch [1/184], Gradient of output_layer.weight: 5.6672444770811126e-05\n",
      "Epoch [34/50], Batch [2/184], Gradient of input_bn.weight: 2.4600694814580493e-09\n",
      "Epoch [34/50], Batch [2/184], Gradient of input_bn.bias: -2.8513784400274744e-07\n",
      "Epoch [34/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.9931007955165114e-09\n",
      "Epoch [34/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.7412525039617321e-06\n",
      "Epoch [34/50], Batch [2/184], Gradient of input_layer.weight: -3.601420717203041e-09\n",
      "Epoch [34/50], Batch [2/184], Gradient of hidden_layers.0.weight: -5.17468015459599e-06\n",
      "Epoch [34/50], Batch [2/184], Gradient of output_layer.weight: 5.852452432009159e-06\n",
      "Epoch [34/50], Batch [3/184], Gradient of input_bn.weight: 1.8232799448014703e-07\n",
      "Epoch [34/50], Batch [3/184], Gradient of input_bn.bias: 1.0008031495090108e-05\n",
      "Epoch [34/50], Batch [3/184], Gradient of hidden_bns.0.weight: 1.431548753316747e-06\n",
      "Epoch [34/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.3858552594901994e-05\n",
      "Epoch [34/50], Batch [3/184], Gradient of input_layer.weight: -2.9385324396002943e-08\n",
      "Epoch [34/50], Batch [3/184], Gradient of hidden_layers.0.weight: -3.655440423244727e-06\n",
      "Epoch [34/50], Batch [3/184], Gradient of output_layer.weight: 0.00011020484089385718\n",
      "Epoch [34/50], Batch [101/184], Gradient of input_bn.weight: 4.11842847825028e-07\n",
      "Epoch [34/50], Batch [101/184], Gradient of input_bn.bias: 2.0148547264398076e-05\n",
      "Epoch [34/50], Batch [101/184], Gradient of hidden_bns.0.weight: 6.253895662666764e-06\n",
      "Epoch [34/50], Batch [101/184], Gradient of hidden_bns.0.bias: 4.983747203368694e-06\n",
      "Epoch [34/50], Batch [101/184], Gradient of input_layer.weight: -3.646233324161585e-07\n",
      "Epoch [34/50], Batch [101/184], Gradient of hidden_layers.0.weight: 8.107618486974388e-05\n",
      "Epoch [34/50], Batch [101/184], Gradient of output_layer.weight: 0.00018286894191987813\n",
      "Epoch [34/50], Batch [102/184], Gradient of input_bn.weight: 2.3556685846415348e-07\n",
      "Epoch [34/50], Batch [102/184], Gradient of input_bn.bias: 2.4600367396487854e-06\n",
      "Epoch [34/50], Batch [102/184], Gradient of hidden_bns.0.weight: -5.554158633458428e-06\n",
      "Epoch [34/50], Batch [102/184], Gradient of hidden_bns.0.bias: -1.1825676665466744e-05\n",
      "Epoch [34/50], Batch [102/184], Gradient of input_layer.weight: 1.044456467980126e-07\n",
      "Epoch [34/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.7075853975256905e-05\n",
      "Epoch [34/50], Batch [102/184], Gradient of output_layer.weight: 7.565391570096835e-05\n",
      "Epoch [34/50], Batch [103/184], Gradient of input_bn.weight: 2.695655894058291e-07\n",
      "Epoch [34/50], Batch [103/184], Gradient of input_bn.bias: 3.263573489675764e-06\n",
      "Epoch [34/50], Batch [103/184], Gradient of hidden_bns.0.weight: -6.036628974470659e-07\n",
      "Epoch [34/50], Batch [103/184], Gradient of hidden_bns.0.bias: -1.2822712960769422e-05\n",
      "Epoch [34/50], Batch [103/184], Gradient of input_layer.weight: -3.476173660033055e-08\n",
      "Epoch [34/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.039331229752861e-05\n",
      "Epoch [34/50], Batch [103/184], Gradient of output_layer.weight: 4.4450593122746795e-05\n",
      "Epoch [34/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████▊            | 34/50 [5:19:18<2:30:17, 563.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [35/50], Batch [1/184], Gradient of input_bn.weight: 2.5352528609801084e-07\n",
      "Epoch [35/50], Batch [1/184], Gradient of input_bn.bias: 6.205384579516249e-06\n",
      "Epoch [35/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.5663831618439872e-06\n",
      "Epoch [35/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.2108435839763843e-05\n",
      "Epoch [35/50], Batch [1/184], Gradient of input_layer.weight: -3.227951950179886e-08\n",
      "Epoch [35/50], Batch [1/184], Gradient of hidden_layers.0.weight: 6.545776705024764e-05\n",
      "Epoch [35/50], Batch [1/184], Gradient of output_layer.weight: 8.427750435657799e-05\n",
      "Epoch [35/50], Batch [2/184], Gradient of input_bn.weight: 1.434868863725569e-07\n",
      "Epoch [35/50], Batch [2/184], Gradient of input_bn.bias: 3.6351598282635678e-06\n",
      "Epoch [35/50], Batch [2/184], Gradient of hidden_bns.0.weight: -1.953229457285488e-06\n",
      "Epoch [35/50], Batch [2/184], Gradient of hidden_bns.0.bias: -1.1945786354772281e-05\n",
      "Epoch [35/50], Batch [2/184], Gradient of input_layer.weight: 2.073791094403532e-08\n",
      "Epoch [35/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.2875383617938496e-05\n",
      "Epoch [35/50], Batch [2/184], Gradient of output_layer.weight: 3.425596150918864e-05\n",
      "Epoch [35/50], Batch [3/184], Gradient of input_bn.weight: 2.0333027350716293e-07\n",
      "Epoch [35/50], Batch [3/184], Gradient of input_bn.bias: 1.1000882295775227e-05\n",
      "Epoch [35/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.661599177779863e-06\n",
      "Epoch [35/50], Batch [3/184], Gradient of hidden_bns.0.bias: 3.149330950691365e-05\n",
      "Epoch [35/50], Batch [3/184], Gradient of input_layer.weight: -2.3885574407245258e-08\n",
      "Epoch [35/50], Batch [3/184], Gradient of hidden_layers.0.weight: 0.00012358585081528872\n",
      "Epoch [35/50], Batch [3/184], Gradient of output_layer.weight: 8.534425433026627e-05\n",
      "Epoch [35/50], Batch [101/184], Gradient of input_bn.weight: 1.967669049918186e-08\n",
      "Epoch [35/50], Batch [101/184], Gradient of input_bn.bias: 2.6752570647659013e-07\n",
      "Epoch [35/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.2309944824883132e-07\n",
      "Epoch [35/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.632441692185239e-06\n",
      "Epoch [35/50], Batch [101/184], Gradient of input_layer.weight: -3.8712806293972335e-09\n",
      "Epoch [35/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.1111416824860498e-05\n",
      "Epoch [35/50], Batch [101/184], Gradient of output_layer.weight: 1.1004502994182985e-05\n",
      "Epoch [35/50], Batch [102/184], Gradient of input_bn.weight: 7.305607141461223e-08\n",
      "Epoch [35/50], Batch [102/184], Gradient of input_bn.bias: 4.339196948421886e-06\n",
      "Epoch [35/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.2657444585784106e-06\n",
      "Epoch [35/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.4946413102734368e-05\n",
      "Epoch [35/50], Batch [102/184], Gradient of input_layer.weight: -3.452664998349064e-08\n",
      "Epoch [35/50], Batch [102/184], Gradient of hidden_layers.0.weight: 3.720107997651212e-05\n",
      "Epoch [35/50], Batch [102/184], Gradient of output_layer.weight: 4.402798003866337e-05\n",
      "Epoch [35/50], Batch [103/184], Gradient of input_bn.weight: 2.626575223985128e-08\n",
      "Epoch [35/50], Batch [103/184], Gradient of input_bn.bias: 4.6522231968992855e-06\n",
      "Epoch [35/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.2035593499604147e-06\n",
      "Epoch [35/50], Batch [103/184], Gradient of hidden_bns.0.bias: -3.956799628213048e-05\n",
      "Epoch [35/50], Batch [103/184], Gradient of input_layer.weight: -9.089679053886357e-08\n",
      "Epoch [35/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.624810647626873e-05\n",
      "Epoch [35/50], Batch [103/184], Gradient of output_layer.weight: 4.9913178372662514e-05\n",
      "Epoch [35/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▌           | 35/50 [5:28:42<2:20:55, 563.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [36/50], Batch [1/184], Gradient of input_bn.weight: 3.6830442695645615e-08\n",
      "Epoch [36/50], Batch [1/184], Gradient of input_bn.bias: 3.5068779880020884e-07\n",
      "Epoch [36/50], Batch [1/184], Gradient of hidden_bns.0.weight: 7.646497124369489e-07\n",
      "Epoch [36/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.2527515536930878e-05\n",
      "Epoch [36/50], Batch [1/184], Gradient of input_layer.weight: -1.5959287225086882e-08\n",
      "Epoch [36/50], Batch [1/184], Gradient of hidden_layers.0.weight: 4.014471869595582e-06\n",
      "Epoch [36/50], Batch [1/184], Gradient of output_layer.weight: 3.8191748899407685e-05\n",
      "Epoch [36/50], Batch [2/184], Gradient of input_bn.weight: 1.2250438885530457e-08\n",
      "Epoch [36/50], Batch [2/184], Gradient of input_bn.bias: 1.9523272385413293e-06\n",
      "Epoch [36/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.0193267598879174e-06\n",
      "Epoch [36/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.020695981424069e-05\n",
      "Epoch [36/50], Batch [2/184], Gradient of input_layer.weight: -1.4598042774593978e-08\n",
      "Epoch [36/50], Batch [2/184], Gradient of hidden_layers.0.weight: -2.408077853033319e-05\n",
      "Epoch [36/50], Batch [2/184], Gradient of output_layer.weight: 2.991196197399404e-05\n",
      "Epoch [36/50], Batch [3/184], Gradient of input_bn.weight: 1.0110989023814909e-07\n",
      "Epoch [36/50], Batch [3/184], Gradient of input_bn.bias: 1.4851470950816292e-06\n",
      "Epoch [36/50], Batch [3/184], Gradient of hidden_bns.0.weight: 9.610298548068386e-07\n",
      "Epoch [36/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.558719486638438e-05\n",
      "Epoch [36/50], Batch [3/184], Gradient of input_layer.weight: -3.7960838028539e-08\n",
      "Epoch [36/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.646988675929606e-05\n",
      "Epoch [36/50], Batch [3/184], Gradient of output_layer.weight: 6.156185554573312e-05\n",
      "Epoch [36/50], Batch [101/184], Gradient of input_bn.weight: 5.8973000705009326e-08\n",
      "Epoch [36/50], Batch [101/184], Gradient of input_bn.bias: 5.873735972272698e-06\n",
      "Epoch [36/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.2609007171704434e-06\n",
      "Epoch [36/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.7619011487113312e-05\n",
      "Epoch [36/50], Batch [101/184], Gradient of input_layer.weight: -8.667801587591839e-09\n",
      "Epoch [36/50], Batch [101/184], Gradient of hidden_layers.0.weight: -2.2996366169536486e-05\n",
      "Epoch [36/50], Batch [101/184], Gradient of output_layer.weight: 5.90749696129933e-05\n",
      "Epoch [36/50], Batch [102/184], Gradient of input_bn.weight: 4.6936793296481483e-07\n",
      "Epoch [36/50], Batch [102/184], Gradient of input_bn.bias: 1.3583045983978081e-05\n",
      "Epoch [36/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.897463789646281e-06\n",
      "Epoch [36/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.8266214940231293e-05\n",
      "Epoch [36/50], Batch [102/184], Gradient of input_layer.weight: 3.204770004927582e-09\n",
      "Epoch [36/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.8633303625392728e-05\n",
      "Epoch [36/50], Batch [102/184], Gradient of output_layer.weight: 0.00015192580758593976\n",
      "Epoch [36/50], Batch [103/184], Gradient of input_bn.weight: 3.2414300221716985e-07\n",
      "Epoch [36/50], Batch [103/184], Gradient of input_bn.bias: 1.4666930837847758e-05\n",
      "Epoch [36/50], Batch [103/184], Gradient of hidden_bns.0.weight: -5.469142706715502e-06\n",
      "Epoch [36/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.727886774460785e-05\n",
      "Epoch [36/50], Batch [103/184], Gradient of input_layer.weight: -8.807720064396563e-08\n",
      "Epoch [36/50], Batch [103/184], Gradient of hidden_layers.0.weight: -4.1842213249765337e-05\n",
      "Epoch [36/50], Batch [103/184], Gradient of output_layer.weight: 0.0001451851858291775\n",
      "Epoch [36/50], Loss: 0.3301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████████████████████████▎          | 36/50 [5:38:06<2:11:31, 563.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [37/50], Batch [1/184], Gradient of input_bn.weight: -1.3451995073410217e-09\n",
      "Epoch [37/50], Batch [1/184], Gradient of input_bn.bias: -1.0191357091571263e-08\n",
      "Epoch [37/50], Batch [1/184], Gradient of hidden_bns.0.weight: -6.699501398088614e-09\n",
      "Epoch [37/50], Batch [1/184], Gradient of hidden_bns.0.bias: 3.758782440854702e-07\n",
      "Epoch [37/50], Batch [1/184], Gradient of input_layer.weight: -1.6305334860078347e-09\n",
      "Epoch [37/50], Batch [1/184], Gradient of hidden_layers.0.weight: -2.036362502622069e-06\n",
      "Epoch [37/50], Batch [1/184], Gradient of output_layer.weight: 1.7412024817531346e-06\n",
      "Epoch [37/50], Batch [2/184], Gradient of input_bn.weight: 4.2721467252704315e-08\n",
      "Epoch [37/50], Batch [2/184], Gradient of input_bn.bias: 2.7926575967285316e-06\n",
      "Epoch [37/50], Batch [2/184], Gradient of hidden_bns.0.weight: 7.723039061602321e-07\n",
      "Epoch [37/50], Batch [2/184], Gradient of hidden_bns.0.bias: 7.668481885048095e-06\n",
      "Epoch [37/50], Batch [2/184], Gradient of input_layer.weight: -3.1289721924565583e-09\n",
      "Epoch [37/50], Batch [2/184], Gradient of hidden_layers.0.weight: 9.83626796369208e-06\n",
      "Epoch [37/50], Batch [2/184], Gradient of output_layer.weight: 2.0254259652574547e-05\n",
      "Epoch [37/50], Batch [3/184], Gradient of input_bn.weight: 2.5112854018516373e-09\n",
      "Epoch [37/50], Batch [3/184], Gradient of input_bn.bias: -4.0902136788645294e-08\n",
      "Epoch [37/50], Batch [3/184], Gradient of hidden_bns.0.weight: -9.048407179079732e-08\n",
      "Epoch [37/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.4596869846172922e-07\n",
      "Epoch [37/50], Batch [3/184], Gradient of input_layer.weight: 7.93778764940356e-10\n",
      "Epoch [37/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.3759120065515162e-07\n",
      "Epoch [37/50], Batch [3/184], Gradient of output_layer.weight: 1.0924162552328198e-06\n",
      "Epoch [37/50], Batch [101/184], Gradient of input_bn.weight: 9.320046956418082e-10\n",
      "Epoch [37/50], Batch [101/184], Gradient of input_bn.bias: 1.518486669738195e-09\n",
      "Epoch [37/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.3378115681916825e-07\n",
      "Epoch [37/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.6904663172899745e-06\n",
      "Epoch [37/50], Batch [101/184], Gradient of input_layer.weight: -7.779551225439718e-09\n",
      "Epoch [37/50], Batch [101/184], Gradient of hidden_layers.0.weight: -7.664938493689988e-06\n",
      "Epoch [37/50], Batch [101/184], Gradient of output_layer.weight: 8.362527296412736e-06\n",
      "Epoch [37/50], Batch [102/184], Gradient of input_bn.weight: 1.6967078408924863e-08\n",
      "Epoch [37/50], Batch [102/184], Gradient of input_bn.bias: 1.4455122254730668e-06\n",
      "Epoch [37/50], Batch [102/184], Gradient of hidden_bns.0.weight: 7.406415534205735e-07\n",
      "Epoch [37/50], Batch [102/184], Gradient of hidden_bns.0.bias: 6.1442565311153885e-06\n",
      "Epoch [37/50], Batch [102/184], Gradient of input_layer.weight: -2.002180643501106e-09\n",
      "Epoch [37/50], Batch [102/184], Gradient of hidden_layers.0.weight: 7.444878519891063e-06\n",
      "Epoch [37/50], Batch [102/184], Gradient of output_layer.weight: 1.3832353943143971e-05\n",
      "Epoch [37/50], Batch [103/184], Gradient of input_bn.weight: -5.537640390684828e-07\n",
      "Epoch [37/50], Batch [103/184], Gradient of input_bn.bias: -5.973317911411868e-06\n",
      "Epoch [37/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.6826961655169725e-06\n",
      "Epoch [37/50], Batch [103/184], Gradient of hidden_bns.0.bias: -2.8359776479192078e-05\n",
      "Epoch [37/50], Batch [103/184], Gradient of input_layer.weight: -1.3438543646770995e-06\n",
      "Epoch [37/50], Batch [103/184], Gradient of hidden_layers.0.weight: -0.00010316776024410501\n",
      "Epoch [37/50], Batch [103/184], Gradient of output_layer.weight: 5.004446938983165e-05\n",
      "Epoch [37/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|████████████████████████████          | 37/50 [5:47:29<2:02:06, 563.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [38/50], Batch [1/184], Gradient of input_bn.weight: 1.0863641364267096e-07\n",
      "Epoch [38/50], Batch [1/184], Gradient of input_bn.bias: 6.235647560970392e-06\n",
      "Epoch [38/50], Batch [1/184], Gradient of hidden_bns.0.weight: 2.0530451365630142e-06\n",
      "Epoch [38/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.4447985449805856e-05\n",
      "Epoch [38/50], Batch [1/184], Gradient of input_layer.weight: -8.126834316612985e-09\n",
      "Epoch [38/50], Batch [1/184], Gradient of hidden_layers.0.weight: 5.14540406584274e-05\n",
      "Epoch [38/50], Batch [1/184], Gradient of output_layer.weight: 4.1109298763331026e-05\n",
      "Epoch [38/50], Batch [2/184], Gradient of input_bn.weight: 9.907307685352862e-08\n",
      "Epoch [38/50], Batch [2/184], Gradient of input_bn.bias: 6.291613317443989e-06\n",
      "Epoch [38/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.4587857296864968e-06\n",
      "Epoch [38/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.9023178538191132e-05\n",
      "Epoch [38/50], Batch [2/184], Gradient of input_layer.weight: -1.5931266972302183e-08\n",
      "Epoch [38/50], Batch [2/184], Gradient of hidden_layers.0.weight: 5.59488580620382e-05\n",
      "Epoch [38/50], Batch [2/184], Gradient of output_layer.weight: 6.658830534433946e-05\n",
      "Epoch [38/50], Batch [3/184], Gradient of input_bn.weight: 2.3285093675440294e-07\n",
      "Epoch [38/50], Batch [3/184], Gradient of input_bn.bias: 1.5512828213104513e-06\n",
      "Epoch [38/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.8749088869517436e-06\n",
      "Epoch [38/50], Batch [3/184], Gradient of hidden_bns.0.bias: -1.0861158443731256e-05\n",
      "Epoch [38/50], Batch [3/184], Gradient of input_layer.weight: 7.479295049961365e-08\n",
      "Epoch [38/50], Batch [3/184], Gradient of hidden_layers.0.weight: -4.4767608642359846e-07\n",
      "Epoch [38/50], Batch [3/184], Gradient of output_layer.weight: 4.6517045120708644e-05\n",
      "Epoch [38/50], Batch [101/184], Gradient of input_bn.weight: 2.1539540284720715e-07\n",
      "Epoch [38/50], Batch [101/184], Gradient of input_bn.bias: 1.0927348739642184e-05\n",
      "Epoch [38/50], Batch [101/184], Gradient of hidden_bns.0.weight: 3.4916215554403607e-06\n",
      "Epoch [38/50], Batch [101/184], Gradient of hidden_bns.0.bias: -1.4754536096006632e-05\n",
      "Epoch [38/50], Batch [101/184], Gradient of input_layer.weight: -4.998591762728211e-09\n",
      "Epoch [38/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.1464781891845632e-05\n",
      "Epoch [38/50], Batch [101/184], Gradient of output_layer.weight: 9.264830441679806e-05\n",
      "Epoch [38/50], Batch [102/184], Gradient of input_bn.weight: 3.5599805414676666e-07\n",
      "Epoch [38/50], Batch [102/184], Gradient of input_bn.bias: 8.757760951993987e-06\n",
      "Epoch [38/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.9419360291503835e-06\n",
      "Epoch [38/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.8958857253892347e-05\n",
      "Epoch [38/50], Batch [102/184], Gradient of input_layer.weight: -1.1234571672957827e-07\n",
      "Epoch [38/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.6105221220641397e-05\n",
      "Epoch [38/50], Batch [102/184], Gradient of output_layer.weight: 0.00015755242202430964\n",
      "Epoch [38/50], Batch [103/184], Gradient of input_bn.weight: 1.0332199451568158e-07\n",
      "Epoch [38/50], Batch [103/184], Gradient of input_bn.bias: 4.578035259328317e-06\n",
      "Epoch [38/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.2076882285327883e-06\n",
      "Epoch [38/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.0163028491660953e-05\n",
      "Epoch [38/50], Batch [103/184], Gradient of input_layer.weight: -1.1321574788780708e-08\n",
      "Epoch [38/50], Batch [103/184], Gradient of hidden_layers.0.weight: 9.182228382087487e-07\n",
      "Epoch [38/50], Batch [103/184], Gradient of output_layer.weight: 4.361563696875237e-05\n",
      "Epoch [38/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████▉         | 38/50 [5:56:53<1:52:44, 563.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [39/50], Batch [1/184], Gradient of input_bn.weight: -3.659442882053554e-08\n",
      "Epoch [39/50], Batch [1/184], Gradient of input_bn.bias: 2.3196016627480276e-06\n",
      "Epoch [39/50], Batch [1/184], Gradient of hidden_bns.0.weight: 3.6501523936749436e-07\n",
      "Epoch [39/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.812267510103993e-05\n",
      "Epoch [39/50], Batch [1/184], Gradient of input_layer.weight: -9.149530910690373e-08\n",
      "Epoch [39/50], Batch [1/184], Gradient of hidden_layers.0.weight: -5.5078660807339475e-05\n",
      "Epoch [39/50], Batch [1/184], Gradient of output_layer.weight: 8.182731835404411e-05\n",
      "Epoch [39/50], Batch [2/184], Gradient of input_bn.weight: 3.4366894396953285e-07\n",
      "Epoch [39/50], Batch [2/184], Gradient of input_bn.bias: 8.437080396106467e-06\n",
      "Epoch [39/50], Batch [2/184], Gradient of hidden_bns.0.weight: -7.153039405238815e-08\n",
      "Epoch [39/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.425233651592862e-05\n",
      "Epoch [39/50], Batch [2/184], Gradient of input_layer.weight: -2.2669011556786245e-08\n",
      "Epoch [39/50], Batch [2/184], Gradient of hidden_layers.0.weight: 8.520395931554958e-05\n",
      "Epoch [39/50], Batch [2/184], Gradient of output_layer.weight: 9.239919018000364e-05\n",
      "Epoch [39/50], Batch [3/184], Gradient of input_bn.weight: 3.0369028536370024e-07\n",
      "Epoch [39/50], Batch [3/184], Gradient of input_bn.bias: 4.637224265024997e-06\n",
      "Epoch [39/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.0830088942602742e-07\n",
      "Epoch [39/50], Batch [3/184], Gradient of hidden_bns.0.bias: -9.668354323366657e-06\n",
      "Epoch [39/50], Batch [3/184], Gradient of input_layer.weight: -4.853043478192376e-08\n",
      "Epoch [39/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.1913080015801825e-05\n",
      "Epoch [39/50], Batch [3/184], Gradient of output_layer.weight: 4.109419751330279e-05\n",
      "Epoch [39/50], Batch [101/184], Gradient of input_bn.weight: 2.4120936359395273e-08\n",
      "Epoch [39/50], Batch [101/184], Gradient of input_bn.bias: -1.101659449886938e-06\n",
      "Epoch [39/50], Batch [101/184], Gradient of hidden_bns.0.weight: -1.4805996215727646e-06\n",
      "Epoch [39/50], Batch [101/184], Gradient of hidden_bns.0.bias: -8.81462256074883e-07\n",
      "Epoch [39/50], Batch [101/184], Gradient of input_layer.weight: -1.9916999605129604e-08\n",
      "Epoch [39/50], Batch [101/184], Gradient of hidden_layers.0.weight: 8.302708920382429e-06\n",
      "Epoch [39/50], Batch [101/184], Gradient of output_layer.weight: 1.4751345588592812e-05\n",
      "Epoch [39/50], Batch [102/184], Gradient of input_bn.weight: 3.740751708392054e-09\n",
      "Epoch [39/50], Batch [102/184], Gradient of input_bn.bias: 2.7294390747556463e-08\n",
      "Epoch [39/50], Batch [102/184], Gradient of hidden_bns.0.weight: -2.9392246858606086e-08\n",
      "Epoch [39/50], Batch [102/184], Gradient of hidden_bns.0.bias: -6.669573622275493e-07\n",
      "Epoch [39/50], Batch [102/184], Gradient of input_layer.weight: 1.2459148157617506e-09\n",
      "Epoch [39/50], Batch [102/184], Gradient of hidden_layers.0.weight: -4.1807493289525155e-07\n",
      "Epoch [39/50], Batch [102/184], Gradient of output_layer.weight: 1.1405453506085905e-06\n",
      "Epoch [39/50], Batch [103/184], Gradient of input_bn.weight: 3.0532601158483885e-07\n",
      "Epoch [39/50], Batch [103/184], Gradient of input_bn.bias: 5.208918082644232e-06\n",
      "Epoch [39/50], Batch [103/184], Gradient of hidden_bns.0.weight: -5.339726612874074e-06\n",
      "Epoch [39/50], Batch [103/184], Gradient of hidden_bns.0.bias: 8.984185114968568e-06\n",
      "Epoch [39/50], Batch [103/184], Gradient of input_layer.weight: -1.3089447747915983e-07\n",
      "Epoch [39/50], Batch [103/184], Gradient of hidden_layers.0.weight: 4.4089119910495356e-06\n",
      "Epoch [39/50], Batch [103/184], Gradient of output_layer.weight: 0.00012530188541859388\n",
      "Epoch [39/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████▋        | 39/50 [6:06:18<1:43:22, 563.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [40/50], Batch [1/184], Gradient of input_bn.weight: 1.9113599591946695e-12\n",
      "Epoch [40/50], Batch [1/184], Gradient of input_bn.bias: -6.101805638536462e-08\n",
      "Epoch [40/50], Batch [1/184], Gradient of hidden_bns.0.weight: 6.441602806717128e-09\n",
      "Epoch [40/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.5423901800204476e-07\n",
      "Epoch [40/50], Batch [1/184], Gradient of input_layer.weight: -3.4204800103410093e-10\n",
      "Epoch [40/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.1879978956130799e-07\n",
      "Epoch [40/50], Batch [1/184], Gradient of output_layer.weight: 4.620363540652761e-07\n",
      "Epoch [40/50], Batch [2/184], Gradient of input_bn.weight: 4.184298063591996e-08\n",
      "Epoch [40/50], Batch [2/184], Gradient of input_bn.bias: 5.897740038562915e-07\n",
      "Epoch [40/50], Batch [2/184], Gradient of hidden_bns.0.weight: -8.559768502891529e-07\n",
      "Epoch [40/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.237931767012924e-06\n",
      "Epoch [40/50], Batch [2/184], Gradient of input_layer.weight: -7.472673146935449e-09\n",
      "Epoch [40/50], Batch [2/184], Gradient of hidden_layers.0.weight: 2.432056589896092e-06\n",
      "Epoch [40/50], Batch [2/184], Gradient of output_layer.weight: 1.4821109289187007e-05\n",
      "Epoch [40/50], Batch [3/184], Gradient of input_bn.weight: 3.6075516618438996e-07\n",
      "Epoch [40/50], Batch [3/184], Gradient of input_bn.bias: 2.6855313990381546e-06\n",
      "Epoch [40/50], Batch [3/184], Gradient of hidden_bns.0.weight: -1.8579595462142606e-06\n",
      "Epoch [40/50], Batch [3/184], Gradient of hidden_bns.0.bias: -1.1639498552540317e-05\n",
      "Epoch [40/50], Batch [3/184], Gradient of input_layer.weight: -2.6708006473086243e-08\n",
      "Epoch [40/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.7367416148772463e-05\n",
      "Epoch [40/50], Batch [3/184], Gradient of output_layer.weight: 6.142894562799484e-05\n",
      "Epoch [40/50], Batch [101/184], Gradient of input_bn.weight: 6.916164352332999e-08\n",
      "Epoch [40/50], Batch [101/184], Gradient of input_bn.bias: 4.22138055000687e-06\n",
      "Epoch [40/50], Batch [101/184], Gradient of hidden_bns.0.weight: -2.812308821376064e-06\n",
      "Epoch [40/50], Batch [101/184], Gradient of hidden_bns.0.bias: -2.605042936920654e-06\n",
      "Epoch [40/50], Batch [101/184], Gradient of input_layer.weight: -3.721477881413193e-08\n",
      "Epoch [40/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.4616821317758877e-06\n",
      "Epoch [40/50], Batch [101/184], Gradient of output_layer.weight: 2.8773240046575665e-05\n",
      "Epoch [40/50], Batch [102/184], Gradient of input_bn.weight: 2.832057361956686e-07\n",
      "Epoch [40/50], Batch [102/184], Gradient of input_bn.bias: 8.114016964100301e-06\n",
      "Epoch [40/50], Batch [102/184], Gradient of hidden_bns.0.weight: -4.534304025582969e-07\n",
      "Epoch [40/50], Batch [102/184], Gradient of hidden_bns.0.bias: 1.2949341908097267e-05\n",
      "Epoch [40/50], Batch [102/184], Gradient of input_layer.weight: -1.209446143235482e-08\n",
      "Epoch [40/50], Batch [102/184], Gradient of hidden_layers.0.weight: 6.755578942829743e-05\n",
      "Epoch [40/50], Batch [102/184], Gradient of output_layer.weight: 9.754084749147296e-05\n",
      "Epoch [40/50], Batch [103/184], Gradient of input_bn.weight: 8.97517793418956e-08\n",
      "Epoch [40/50], Batch [103/184], Gradient of input_bn.bias: 7.86279997555539e-06\n",
      "Epoch [40/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.1328220352879725e-06\n",
      "Epoch [40/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.7054531528847292e-05\n",
      "Epoch [40/50], Batch [103/184], Gradient of input_layer.weight: -3.2031774566121385e-08\n",
      "Epoch [40/50], Batch [103/184], Gradient of hidden_layers.0.weight: 6.943662356206914e-06\n",
      "Epoch [40/50], Batch [103/184], Gradient of output_layer.weight: 7.762406312394887e-05\n",
      "Epoch [40/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 40/50 [6:15:41<1:33:56, 563.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [41/50], Batch [1/184], Gradient of input_bn.weight: 6.416075848392211e-08\n",
      "Epoch [41/50], Batch [1/184], Gradient of input_bn.bias: 5.77413993596565e-06\n",
      "Epoch [41/50], Batch [1/184], Gradient of hidden_bns.0.weight: 5.743534075008938e-07\n",
      "Epoch [41/50], Batch [1/184], Gradient of hidden_bns.0.bias: -6.834672603872605e-06\n",
      "Epoch [41/50], Batch [1/184], Gradient of input_layer.weight: -2.5207175013974847e-08\n",
      "Epoch [41/50], Batch [1/184], Gradient of hidden_layers.0.weight: 1.4659474800282624e-05\n",
      "Epoch [41/50], Batch [1/184], Gradient of output_layer.weight: 3.42439379892312e-05\n",
      "Epoch [41/50], Batch [2/184], Gradient of input_bn.weight: 3.63270373782143e-07\n",
      "Epoch [41/50], Batch [2/184], Gradient of input_bn.bias: 3.51237667928217e-06\n",
      "Epoch [41/50], Batch [2/184], Gradient of hidden_bns.0.weight: -4.992702997697052e-06\n",
      "Epoch [41/50], Batch [2/184], Gradient of hidden_bns.0.bias: 9.95658410829492e-07\n",
      "Epoch [41/50], Batch [2/184], Gradient of input_layer.weight: -3.243554402843074e-08\n",
      "Epoch [41/50], Batch [2/184], Gradient of hidden_layers.0.weight: 4.431918205227703e-05\n",
      "Epoch [41/50], Batch [2/184], Gradient of output_layer.weight: 8.473680645693094e-05\n",
      "Epoch [41/50], Batch [3/184], Gradient of input_bn.weight: 1.492958290327806e-08\n",
      "Epoch [41/50], Batch [3/184], Gradient of input_bn.bias: 4.266227279003942e-06\n",
      "Epoch [41/50], Batch [3/184], Gradient of hidden_bns.0.weight: -4.034541234432254e-07\n",
      "Epoch [41/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.3162490176910069e-05\n",
      "Epoch [41/50], Batch [3/184], Gradient of input_layer.weight: -3.469118681209693e-08\n",
      "Epoch [41/50], Batch [3/184], Gradient of hidden_layers.0.weight: -7.641029696969781e-06\n",
      "Epoch [41/50], Batch [3/184], Gradient of output_layer.weight: 4.012184217572212e-05\n",
      "Epoch [41/50], Batch [101/184], Gradient of input_bn.weight: 4.788726073456928e-07\n",
      "Epoch [41/50], Batch [101/184], Gradient of input_bn.bias: 7.027487299637869e-06\n",
      "Epoch [41/50], Batch [101/184], Gradient of hidden_bns.0.weight: -1.4873346572130686e-06\n",
      "Epoch [41/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.921628038166091e-06\n",
      "Epoch [41/50], Batch [101/184], Gradient of input_layer.weight: -3.8920553890875453e-08\n",
      "Epoch [41/50], Batch [101/184], Gradient of hidden_layers.0.weight: 2.0638093701563776e-05\n",
      "Epoch [41/50], Batch [101/184], Gradient of output_layer.weight: 0.00010064600792247802\n",
      "Epoch [41/50], Batch [102/184], Gradient of input_bn.weight: 2.132355803041719e-08\n",
      "Epoch [41/50], Batch [102/184], Gradient of input_bn.bias: 7.381914883808349e-07\n",
      "Epoch [41/50], Batch [102/184], Gradient of hidden_bns.0.weight: 3.2113678116729716e-07\n",
      "Epoch [41/50], Batch [102/184], Gradient of hidden_bns.0.bias: 5.707079253625125e-06\n",
      "Epoch [41/50], Batch [102/184], Gradient of input_layer.weight: -1.0549336515452978e-08\n",
      "Epoch [41/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.0944792848022189e-05\n",
      "Epoch [41/50], Batch [102/184], Gradient of output_layer.weight: 1.776757198967971e-05\n",
      "Epoch [41/50], Batch [103/184], Gradient of input_bn.weight: 2.148198063878226e-09\n",
      "Epoch [41/50], Batch [103/184], Gradient of input_bn.bias: 1.677086913787207e-07\n",
      "Epoch [41/50], Batch [103/184], Gradient of hidden_bns.0.weight: 7.973810056682851e-08\n",
      "Epoch [41/50], Batch [103/184], Gradient of hidden_bns.0.bias: 6.692225156257336e-07\n",
      "Epoch [41/50], Batch [103/184], Gradient of input_layer.weight: -1.0828741237034478e-09\n",
      "Epoch [41/50], Batch [103/184], Gradient of hidden_layers.0.weight: -3.792919187617372e-07\n",
      "Epoch [41/50], Batch [103/184], Gradient of output_layer.weight: 1.9566330138331978e-06\n",
      "Epoch [41/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████▏      | 41/50 [6:25:05<1:24:34, 563.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [42/50], Batch [1/184], Gradient of input_bn.weight: 9.007408152683638e-09\n",
      "Epoch [42/50], Batch [1/184], Gradient of input_bn.bias: 4.7305985617640545e-07\n",
      "Epoch [42/50], Batch [1/184], Gradient of hidden_bns.0.weight: -7.651314604117943e-08\n",
      "Epoch [42/50], Batch [1/184], Gradient of hidden_bns.0.bias: -7.623548299307004e-07\n",
      "Epoch [42/50], Batch [1/184], Gradient of input_layer.weight: -5.141727044133404e-10\n",
      "Epoch [42/50], Batch [1/184], Gradient of hidden_layers.0.weight: 3.3715195968397893e-06\n",
      "Epoch [42/50], Batch [1/184], Gradient of output_layer.weight: 4.37453354606987e-06\n",
      "Epoch [42/50], Batch [2/184], Gradient of input_bn.weight: 1.9537765183486044e-07\n",
      "Epoch [42/50], Batch [2/184], Gradient of input_bn.bias: 7.647297024959698e-06\n",
      "Epoch [42/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.2383211469568778e-06\n",
      "Epoch [42/50], Batch [2/184], Gradient of hidden_bns.0.bias: -2.8605547413462773e-05\n",
      "Epoch [42/50], Batch [2/184], Gradient of input_layer.weight: -1.1314741499290903e-07\n",
      "Epoch [42/50], Batch [2/184], Gradient of hidden_layers.0.weight: 9.173200669465587e-05\n",
      "Epoch [42/50], Batch [2/184], Gradient of output_layer.weight: 8.233085827669129e-05\n",
      "Epoch [42/50], Batch [3/184], Gradient of input_bn.weight: 3.0219234758988023e-07\n",
      "Epoch [42/50], Batch [3/184], Gradient of input_bn.bias: -7.555263437097892e-07\n",
      "Epoch [42/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.1271994228300173e-06\n",
      "Epoch [42/50], Batch [3/184], Gradient of hidden_bns.0.bias: -4.526384600467281e-06\n",
      "Epoch [42/50], Batch [3/184], Gradient of input_layer.weight: -2.4208691939975324e-08\n",
      "Epoch [42/50], Batch [3/184], Gradient of hidden_layers.0.weight: 9.851309187070001e-06\n",
      "Epoch [42/50], Batch [3/184], Gradient of output_layer.weight: 3.592291250242852e-05\n",
      "Epoch [42/50], Batch [101/184], Gradient of input_bn.weight: 1.895205059554428e-08\n",
      "Epoch [42/50], Batch [101/184], Gradient of input_bn.bias: 1.3113417480781209e-06\n",
      "Epoch [42/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.5325304048019461e-07\n",
      "Epoch [42/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.588340091984719e-05\n",
      "Epoch [42/50], Batch [101/184], Gradient of input_layer.weight: -1.782263936433992e-08\n",
      "Epoch [42/50], Batch [101/184], Gradient of hidden_layers.0.weight: -1.9793294995906763e-05\n",
      "Epoch [42/50], Batch [101/184], Gradient of output_layer.weight: 4.5789121941197664e-05\n",
      "Epoch [42/50], Batch [102/184], Gradient of input_bn.weight: 1.455885012546787e-08\n",
      "Epoch [42/50], Batch [102/184], Gradient of input_bn.bias: 7.523173906065495e-08\n",
      "Epoch [42/50], Batch [102/184], Gradient of hidden_bns.0.weight: 3.30399757331179e-07\n",
      "Epoch [42/50], Batch [102/184], Gradient of hidden_bns.0.bias: 3.7221993807179388e-06\n",
      "Epoch [42/50], Batch [102/184], Gradient of input_layer.weight: -2.4930904007902654e-09\n",
      "Epoch [42/50], Batch [102/184], Gradient of hidden_layers.0.weight: -5.70661495657987e-06\n",
      "Epoch [42/50], Batch [102/184], Gradient of output_layer.weight: 1.1932652341783978e-05\n",
      "Epoch [42/50], Batch [103/184], Gradient of input_bn.weight: -3.1958506951923482e-09\n",
      "Epoch [42/50], Batch [103/184], Gradient of input_bn.bias: -5.502346311914152e-07\n",
      "Epoch [42/50], Batch [103/184], Gradient of hidden_bns.0.weight: -5.6086314259573555e-08\n",
      "Epoch [42/50], Batch [103/184], Gradient of hidden_bns.0.bias: -7.940222985780565e-07\n",
      "Epoch [42/50], Batch [103/184], Gradient of input_layer.weight: -6.2721854376945885e-09\n",
      "Epoch [42/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.71918884209299e-06\n",
      "Epoch [42/50], Batch [103/184], Gradient of output_layer.weight: 3.7580450680252397e-06\n",
      "Epoch [42/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|███████████████████████████████▉      | 42/50 [6:34:28<1:15:07, 563.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [43/50], Batch [1/184], Gradient of input_bn.weight: 3.0616865842603147e-07\n",
      "Epoch [43/50], Batch [1/184], Gradient of input_bn.bias: 7.091552106430754e-06\n",
      "Epoch [43/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.4179767024179455e-06\n",
      "Epoch [43/50], Batch [1/184], Gradient of hidden_bns.0.bias: 2.2944979718886316e-05\n",
      "Epoch [43/50], Batch [1/184], Gradient of input_layer.weight: -5.0104689286456505e-09\n",
      "Epoch [43/50], Batch [1/184], Gradient of hidden_layers.0.weight: 7.354082299571019e-06\n",
      "Epoch [43/50], Batch [1/184], Gradient of output_layer.weight: 9.90370026556775e-05\n",
      "Epoch [43/50], Batch [2/184], Gradient of input_bn.weight: 2.021920408878941e-10\n",
      "Epoch [43/50], Batch [2/184], Gradient of input_bn.bias: 2.5391997837687086e-08\n",
      "Epoch [43/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.0611179490638278e-08\n",
      "Epoch [43/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.1956407774960098e-07\n",
      "Epoch [43/50], Batch [2/184], Gradient of input_layer.weight: 1.4124290279027285e-11\n",
      "Epoch [43/50], Batch [2/184], Gradient of hidden_layers.0.weight: -5.04652405197703e-07\n",
      "Epoch [43/50], Batch [2/184], Gradient of output_layer.weight: 3.2645689884702733e-07\n",
      "Epoch [43/50], Batch [3/184], Gradient of input_bn.weight: 2.960518941108603e-09\n",
      "Epoch [43/50], Batch [3/184], Gradient of input_bn.bias: 4.539023734650982e-08\n",
      "Epoch [43/50], Batch [3/184], Gradient of hidden_bns.0.weight: -1.782865410859813e-08\n",
      "Epoch [43/50], Batch [3/184], Gradient of hidden_bns.0.bias: -3.696761723404052e-07\n",
      "Epoch [43/50], Batch [3/184], Gradient of input_layer.weight: 1.2021340589640772e-09\n",
      "Epoch [43/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.7941316627911874e-06\n",
      "Epoch [43/50], Batch [3/184], Gradient of output_layer.weight: 1.4018282854522113e-06\n",
      "Epoch [43/50], Batch [101/184], Gradient of input_bn.weight: 2.0861830307694618e-07\n",
      "Epoch [43/50], Batch [101/184], Gradient of input_bn.bias: 6.973370545892976e-06\n",
      "Epoch [43/50], Batch [101/184], Gradient of hidden_bns.0.weight: -6.278285127336858e-07\n",
      "Epoch [43/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.1829835532116704e-05\n",
      "Epoch [43/50], Batch [101/184], Gradient of input_layer.weight: -3.304786844182672e-08\n",
      "Epoch [43/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.4989333067205735e-05\n",
      "Epoch [43/50], Batch [101/184], Gradient of output_layer.weight: 8.4263963799458e-05\n",
      "Epoch [43/50], Batch [102/184], Gradient of input_bn.weight: 2.0642983145080507e-07\n",
      "Epoch [43/50], Batch [102/184], Gradient of input_bn.bias: 9.170634257316124e-06\n",
      "Epoch [43/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.189343260601163e-07\n",
      "Epoch [43/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.5441280740778893e-05\n",
      "Epoch [43/50], Batch [102/184], Gradient of input_layer.weight: -3.542610826912096e-08\n",
      "Epoch [43/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.0241491509077605e-05\n",
      "Epoch [43/50], Batch [102/184], Gradient of output_layer.weight: 9.290427988162264e-05\n",
      "Epoch [43/50], Batch [103/184], Gradient of input_bn.weight: 4.0160102798836306e-08\n",
      "Epoch [43/50], Batch [103/184], Gradient of input_bn.bias: 3.84291706723161e-06\n",
      "Epoch [43/50], Batch [103/184], Gradient of hidden_bns.0.weight: -3.058300990232965e-07\n",
      "Epoch [43/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.4179651770973578e-05\n",
      "Epoch [43/50], Batch [103/184], Gradient of input_layer.weight: -1.805259586262764e-08\n",
      "Epoch [43/50], Batch [103/184], Gradient of hidden_layers.0.weight: -2.9697936042794026e-05\n",
      "Epoch [43/50], Batch [103/184], Gradient of output_layer.weight: 4.385984721011482e-05\n",
      "Epoch [43/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████▋     | 43/50 [6:43:52<1:05:45, 563.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [44/50], Batch [1/184], Gradient of input_bn.weight: 5.3940084399073385e-08\n",
      "Epoch [44/50], Batch [1/184], Gradient of input_bn.bias: -7.967358897076338e-07\n",
      "Epoch [44/50], Batch [1/184], Gradient of hidden_bns.0.weight: -9.165386245513218e-07\n",
      "Epoch [44/50], Batch [1/184], Gradient of hidden_bns.0.bias: 8.970197995950002e-06\n",
      "Epoch [44/50], Batch [1/184], Gradient of input_layer.weight: -2.503422358302032e-08\n",
      "Epoch [44/50], Batch [1/184], Gradient of hidden_layers.0.weight: -3.3910696402017493e-06\n",
      "Epoch [44/50], Batch [1/184], Gradient of output_layer.weight: 3.356536035425961e-05\n",
      "Epoch [44/50], Batch [2/184], Gradient of input_bn.weight: 6.1272658058442175e-09\n",
      "Epoch [44/50], Batch [2/184], Gradient of input_bn.bias: 4.2153510548814666e-07\n",
      "Epoch [44/50], Batch [2/184], Gradient of hidden_bns.0.weight: 1.0723488230723888e-07\n",
      "Epoch [44/50], Batch [2/184], Gradient of hidden_bns.0.bias: 6.782398031646153e-06\n",
      "Epoch [44/50], Batch [2/184], Gradient of input_layer.weight: -3.60749496941537e-09\n",
      "Epoch [44/50], Batch [2/184], Gradient of hidden_layers.0.weight: -4.113222530577332e-05\n",
      "Epoch [44/50], Batch [2/184], Gradient of output_layer.weight: 2.314619268872775e-05\n",
      "Epoch [44/50], Batch [3/184], Gradient of input_bn.weight: 8.337173085237737e-08\n",
      "Epoch [44/50], Batch [3/184], Gradient of input_bn.bias: 5.942415555182379e-06\n",
      "Epoch [44/50], Batch [3/184], Gradient of hidden_bns.0.weight: 2.358867732255021e-06\n",
      "Epoch [44/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.8671622203546576e-05\n",
      "Epoch [44/50], Batch [3/184], Gradient of input_layer.weight: -2.1223319990326672e-08\n",
      "Epoch [44/50], Batch [3/184], Gradient of hidden_layers.0.weight: -1.7968145584745798e-06\n",
      "Epoch [44/50], Batch [3/184], Gradient of output_layer.weight: 7.78271205490455e-05\n",
      "Epoch [44/50], Batch [101/184], Gradient of input_bn.weight: 1.229520876222523e-07\n",
      "Epoch [44/50], Batch [101/184], Gradient of input_bn.bias: 7.910326530691236e-06\n",
      "Epoch [44/50], Batch [101/184], Gradient of hidden_bns.0.weight: 8.008169061213266e-08\n",
      "Epoch [44/50], Batch [101/184], Gradient of hidden_bns.0.bias: 6.377871613949537e-06\n",
      "Epoch [44/50], Batch [101/184], Gradient of input_layer.weight: 2.4212130966816403e-08\n",
      "Epoch [44/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.0556773304415401e-05\n",
      "Epoch [44/50], Batch [101/184], Gradient of output_layer.weight: 6.453527748817578e-05\n",
      "Epoch [44/50], Batch [102/184], Gradient of input_bn.weight: -5.872152541996911e-09\n",
      "Epoch [44/50], Batch [102/184], Gradient of input_bn.bias: 4.1183898247254547e-07\n",
      "Epoch [44/50], Batch [102/184], Gradient of hidden_bns.0.weight: -7.43090424748516e-08\n",
      "Epoch [44/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.2186886781128123e-06\n",
      "Epoch [44/50], Batch [102/184], Gradient of input_layer.weight: -6.71687105935348e-09\n",
      "Epoch [44/50], Batch [102/184], Gradient of hidden_layers.0.weight: -1.6795253031887114e-05\n",
      "Epoch [44/50], Batch [102/184], Gradient of output_layer.weight: 7.4765698627743404e-06\n",
      "Epoch [44/50], Batch [103/184], Gradient of input_bn.weight: 1.0317620535715832e-07\n",
      "Epoch [44/50], Batch [103/184], Gradient of input_bn.bias: 4.7199214350257535e-06\n",
      "Epoch [44/50], Batch [103/184], Gradient of hidden_bns.0.weight: -6.767888862668769e-07\n",
      "Epoch [44/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.8888149497797713e-05\n",
      "Epoch [44/50], Batch [103/184], Gradient of input_layer.weight: -4.425414701358932e-08\n",
      "Epoch [44/50], Batch [103/184], Gradient of hidden_layers.0.weight: 2.2561669084097957e-06\n",
      "Epoch [44/50], Batch [103/184], Gradient of output_layer.weight: 6.856901018181816e-05\n",
      "Epoch [44/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████▏    | 44/50 [6:53:15<56:21, 563.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [45/50], Batch [1/184], Gradient of input_bn.weight: 3.6359779187478125e-08\n",
      "Epoch [45/50], Batch [1/184], Gradient of input_bn.bias: 3.2888099212868838e-06\n",
      "Epoch [45/50], Batch [1/184], Gradient of hidden_bns.0.weight: 8.003613629625761e-07\n",
      "Epoch [45/50], Batch [1/184], Gradient of hidden_bns.0.bias: 8.551850442017894e-06\n",
      "Epoch [45/50], Batch [1/184], Gradient of input_layer.weight: -9.658632116327226e-09\n",
      "Epoch [45/50], Batch [1/184], Gradient of hidden_layers.0.weight: -2.0779498299816623e-05\n",
      "Epoch [45/50], Batch [1/184], Gradient of output_layer.weight: 2.4973434847197495e-05\n",
      "Epoch [45/50], Batch [2/184], Gradient of input_bn.weight: 3.05862158711534e-07\n",
      "Epoch [45/50], Batch [2/184], Gradient of input_bn.bias: 6.8192130129318684e-06\n",
      "Epoch [45/50], Batch [2/184], Gradient of hidden_bns.0.weight: -5.35136950929882e-06\n",
      "Epoch [45/50], Batch [2/184], Gradient of hidden_bns.0.bias: 8.443577826255932e-06\n",
      "Epoch [45/50], Batch [2/184], Gradient of input_layer.weight: -5.6500141454307595e-08\n",
      "Epoch [45/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.934001556946896e-05\n",
      "Epoch [45/50], Batch [2/184], Gradient of output_layer.weight: 8.202662138501182e-05\n",
      "Epoch [45/50], Batch [3/184], Gradient of input_bn.weight: 3.292788619546627e-07\n",
      "Epoch [45/50], Batch [3/184], Gradient of input_bn.bias: 9.672832675278187e-06\n",
      "Epoch [45/50], Batch [3/184], Gradient of hidden_bns.0.weight: -7.103301413735608e-07\n",
      "Epoch [45/50], Batch [3/184], Gradient of hidden_bns.0.bias: -4.9017718993127346e-05\n",
      "Epoch [45/50], Batch [3/184], Gradient of input_layer.weight: -6.712986788670605e-08\n",
      "Epoch [45/50], Batch [3/184], Gradient of hidden_layers.0.weight: 6.101429335103603e-06\n",
      "Epoch [45/50], Batch [3/184], Gradient of output_layer.weight: 9.977338777389377e-05\n",
      "Epoch [45/50], Batch [101/184], Gradient of input_bn.weight: -2.916976882261224e-07\n",
      "Epoch [45/50], Batch [101/184], Gradient of input_bn.bias: -1.4740487586095696e-06\n",
      "Epoch [45/50], Batch [101/184], Gradient of hidden_bns.0.weight: -5.20211358434608e-07\n",
      "Epoch [45/50], Batch [101/184], Gradient of hidden_bns.0.bias: 3.074458618357312e-06\n",
      "Epoch [45/50], Batch [101/184], Gradient of input_layer.weight: -5.246715204521024e-07\n",
      "Epoch [45/50], Batch [101/184], Gradient of hidden_layers.0.weight: -3.0812745535513386e-05\n",
      "Epoch [45/50], Batch [101/184], Gradient of output_layer.weight: 1.604206772753969e-05\n",
      "Epoch [45/50], Batch [102/184], Gradient of input_bn.weight: 7.318976713577285e-08\n",
      "Epoch [45/50], Batch [102/184], Gradient of input_bn.bias: 6.52430071568233e-06\n",
      "Epoch [45/50], Batch [102/184], Gradient of hidden_bns.0.weight: 1.2512059583968949e-06\n",
      "Epoch [45/50], Batch [102/184], Gradient of hidden_bns.0.bias: 2.5194529371219687e-05\n",
      "Epoch [45/50], Batch [102/184], Gradient of input_layer.weight: -4.825172084110818e-08\n",
      "Epoch [45/50], Batch [102/184], Gradient of hidden_layers.0.weight: 3.638548150775023e-05\n",
      "Epoch [45/50], Batch [102/184], Gradient of output_layer.weight: 7.595868373755366e-05\n",
      "Epoch [45/50], Batch [103/184], Gradient of input_bn.weight: 1.3818407751386985e-07\n",
      "Epoch [45/50], Batch [103/184], Gradient of input_bn.bias: 5.106624030304374e-06\n",
      "Epoch [45/50], Batch [103/184], Gradient of hidden_bns.0.weight: 5.902614930164418e-07\n",
      "Epoch [45/50], Batch [103/184], Gradient of hidden_bns.0.bias: -9.632905857870355e-06\n",
      "Epoch [45/50], Batch [103/184], Gradient of input_layer.weight: -3.196547382344761e-08\n",
      "Epoch [45/50], Batch [103/184], Gradient of hidden_layers.0.weight: 1.7252477846341208e-05\n",
      "Epoch [45/50], Batch [103/184], Gradient of output_layer.weight: 2.736767419264652e-05\n",
      "Epoch [45/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████    | 45/50 [7:02:40<46:59, 563.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [46/50], Batch [1/184], Gradient of input_bn.weight: 2.387951099080965e-07\n",
      "Epoch [46/50], Batch [1/184], Gradient of input_bn.bias: 5.104132469568867e-06\n",
      "Epoch [46/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.575607140897773e-07\n",
      "Epoch [46/50], Batch [1/184], Gradient of hidden_bns.0.bias: 2.1988351363688707e-05\n",
      "Epoch [46/50], Batch [1/184], Gradient of input_layer.weight: -4.2313903492186e-08\n",
      "Epoch [46/50], Batch [1/184], Gradient of hidden_layers.0.weight: 6.951342948013917e-05\n",
      "Epoch [46/50], Batch [1/184], Gradient of output_layer.weight: 8.274237188743427e-05\n",
      "Epoch [46/50], Batch [2/184], Gradient of input_bn.weight: 3.211415133819173e-09\n",
      "Epoch [46/50], Batch [2/184], Gradient of input_bn.bias: 7.297309139175923e-07\n",
      "Epoch [46/50], Batch [2/184], Gradient of hidden_bns.0.weight: 5.818883437314071e-07\n",
      "Epoch [46/50], Batch [2/184], Gradient of hidden_bns.0.bias: 8.402066669077612e-06\n",
      "Epoch [46/50], Batch [2/184], Gradient of input_layer.weight: -2.823258427042674e-08\n",
      "Epoch [46/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.8225266273930174e-07\n",
      "Epoch [46/50], Batch [2/184], Gradient of output_layer.weight: 2.7227682949160226e-05\n",
      "Epoch [46/50], Batch [3/184], Gradient of input_bn.weight: 4.0947952584247105e-08\n",
      "Epoch [46/50], Batch [3/184], Gradient of input_bn.bias: -3.703416950884275e-08\n",
      "Epoch [46/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.345434945207671e-07\n",
      "Epoch [46/50], Batch [3/184], Gradient of hidden_bns.0.bias: 7.135562555049546e-06\n",
      "Epoch [46/50], Batch [3/184], Gradient of input_layer.weight: -2.3586652631024663e-08\n",
      "Epoch [46/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.4415203622775152e-05\n",
      "Epoch [46/50], Batch [3/184], Gradient of output_layer.weight: 2.4004755687201396e-05\n",
      "Epoch [46/50], Batch [101/184], Gradient of input_bn.weight: 4.1193197830580175e-07\n",
      "Epoch [46/50], Batch [101/184], Gradient of input_bn.bias: 1.949846773641184e-05\n",
      "Epoch [46/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.4722166926949285e-06\n",
      "Epoch [46/50], Batch [101/184], Gradient of hidden_bns.0.bias: -0.00013479632616508752\n",
      "Epoch [46/50], Batch [101/184], Gradient of input_layer.weight: 2.9248035104956216e-08\n",
      "Epoch [46/50], Batch [101/184], Gradient of hidden_layers.0.weight: 6.316362942015985e-06\n",
      "Epoch [46/50], Batch [101/184], Gradient of output_layer.weight: 4.11141591030173e-05\n",
      "Epoch [46/50], Batch [102/184], Gradient of input_bn.weight: 3.043028300453443e-07\n",
      "Epoch [46/50], Batch [102/184], Gradient of input_bn.bias: 8.31868419481907e-07\n",
      "Epoch [46/50], Batch [102/184], Gradient of hidden_bns.0.weight: -4.411813279148191e-06\n",
      "Epoch [46/50], Batch [102/184], Gradient of hidden_bns.0.bias: 7.27550832380075e-06\n",
      "Epoch [46/50], Batch [102/184], Gradient of input_layer.weight: 1.0541656791929199e-07\n",
      "Epoch [46/50], Batch [102/184], Gradient of hidden_layers.0.weight: 1.9528530174284242e-05\n",
      "Epoch [46/50], Batch [102/184], Gradient of output_layer.weight: 8.541166607756168e-05\n",
      "Epoch [46/50], Batch [103/184], Gradient of input_bn.weight: 7.561311576864682e-10\n",
      "Epoch [46/50], Batch [103/184], Gradient of input_bn.bias: -1.0306621334166266e-06\n",
      "Epoch [46/50], Batch [103/184], Gradient of hidden_bns.0.weight: 4.0193361883211765e-07\n",
      "Epoch [46/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.870070147764636e-06\n",
      "Epoch [46/50], Batch [103/184], Gradient of input_layer.weight: 2.2689755629912156e-10\n",
      "Epoch [46/50], Batch [103/184], Gradient of hidden_layers.0.weight: 7.209619525383459e-06\n",
      "Epoch [46/50], Batch [103/184], Gradient of output_layer.weight: 8.049986718106084e-06\n",
      "Epoch [46/50], Loss: 0.3299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████▊   | 46/50 [7:12:03<37:34, 563.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [47/50], Batch [1/184], Gradient of input_bn.weight: 6.350524017761927e-08\n",
      "Epoch [47/50], Batch [1/184], Gradient of input_bn.bias: 1.9116409930575173e-06\n",
      "Epoch [47/50], Batch [1/184], Gradient of hidden_bns.0.weight: -2.123742206094903e-06\n",
      "Epoch [47/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.7049619600584265e-06\n",
      "Epoch [47/50], Batch [1/184], Gradient of input_layer.weight: -2.0024801372642287e-08\n",
      "Epoch [47/50], Batch [1/184], Gradient of hidden_layers.0.weight: 8.431684364040848e-06\n",
      "Epoch [47/50], Batch [1/184], Gradient of output_layer.weight: 2.0283478079363704e-05\n",
      "Epoch [47/50], Batch [2/184], Gradient of input_bn.weight: -1.2426198736648075e-08\n",
      "Epoch [47/50], Batch [2/184], Gradient of input_bn.bias: 6.642871539952466e-06\n",
      "Epoch [47/50], Batch [2/184], Gradient of hidden_bns.0.weight: -4.1140560824715067e-07\n",
      "Epoch [47/50], Batch [2/184], Gradient of hidden_bns.0.bias: 2.0068217054358684e-05\n",
      "Epoch [47/50], Batch [2/184], Gradient of input_layer.weight: -9.669209077856067e-08\n",
      "Epoch [47/50], Batch [2/184], Gradient of hidden_layers.0.weight: -9.542236512061208e-06\n",
      "Epoch [47/50], Batch [2/184], Gradient of output_layer.weight: 6.283278344199061e-05\n",
      "Epoch [47/50], Batch [3/184], Gradient of input_bn.weight: -2.701062840060331e-07\n",
      "Epoch [47/50], Batch [3/184], Gradient of input_bn.bias: 5.709901870432077e-06\n",
      "Epoch [47/50], Batch [3/184], Gradient of hidden_bns.0.weight: -3.887453203788027e-07\n",
      "Epoch [47/50], Batch [3/184], Gradient of hidden_bns.0.bias: 1.9354925825609826e-05\n",
      "Epoch [47/50], Batch [3/184], Gradient of input_layer.weight: -5.846762860528543e-07\n",
      "Epoch [47/50], Batch [3/184], Gradient of hidden_layers.0.weight: -2.9775170332868584e-05\n",
      "Epoch [47/50], Batch [3/184], Gradient of output_layer.weight: 6.96194329066202e-05\n",
      "Epoch [47/50], Batch [101/184], Gradient of input_bn.weight: 8.157971933542285e-07\n",
      "Epoch [47/50], Batch [101/184], Gradient of input_bn.bias: 6.73098475090228e-06\n",
      "Epoch [47/50], Batch [101/184], Gradient of hidden_bns.0.weight: -6.838853551016655e-06\n",
      "Epoch [47/50], Batch [101/184], Gradient of hidden_bns.0.bias: -3.344014839967713e-05\n",
      "Epoch [47/50], Batch [101/184], Gradient of input_layer.weight: -1.0409289075141714e-07\n",
      "Epoch [47/50], Batch [101/184], Gradient of hidden_layers.0.weight: -4.536478172667557e-06\n",
      "Epoch [47/50], Batch [101/184], Gradient of output_layer.weight: 0.00014540398842655122\n",
      "Epoch [47/50], Batch [102/184], Gradient of input_bn.weight: 7.055177775328048e-08\n",
      "Epoch [47/50], Batch [102/184], Gradient of input_bn.bias: 1.4037250366527587e-06\n",
      "Epoch [47/50], Batch [102/184], Gradient of hidden_bns.0.weight: -8.312832733281539e-07\n",
      "Epoch [47/50], Batch [102/184], Gradient of hidden_bns.0.bias: 6.49015100862016e-06\n",
      "Epoch [47/50], Batch [102/184], Gradient of input_layer.weight: -1.7268108720713826e-08\n",
      "Epoch [47/50], Batch [102/184], Gradient of hidden_layers.0.weight: 7.98025394033175e-06\n",
      "Epoch [47/50], Batch [102/184], Gradient of output_layer.weight: 2.956815660581924e-05\n",
      "Epoch [47/50], Batch [103/184], Gradient of input_bn.weight: 1.1845941116916947e-08\n",
      "Epoch [47/50], Batch [103/184], Gradient of input_bn.bias: 9.136088010563981e-07\n",
      "Epoch [47/50], Batch [103/184], Gradient of hidden_bns.0.weight: 2.595882051537046e-07\n",
      "Epoch [47/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.7660961475485237e-06\n",
      "Epoch [47/50], Batch [103/184], Gradient of input_layer.weight: -2.360839523873892e-09\n",
      "Epoch [47/50], Batch [103/184], Gradient of hidden_layers.0.weight: 3.1073445825313684e-06\n",
      "Epoch [47/50], Batch [103/184], Gradient of output_layer.weight: 7.987758181116078e-06\n",
      "Epoch [47/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████▌  | 47/50 [7:21:27<28:11, 563.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [48/50], Batch [1/184], Gradient of input_bn.weight: 4.233925210428424e-07\n",
      "Epoch [48/50], Batch [1/184], Gradient of input_bn.bias: 9.946202226274181e-06\n",
      "Epoch [48/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.124014715969679e-06\n",
      "Epoch [48/50], Batch [1/184], Gradient of hidden_bns.0.bias: 5.012187102693133e-06\n",
      "Epoch [48/50], Batch [1/184], Gradient of input_layer.weight: -9.119349186903491e-08\n",
      "Epoch [48/50], Batch [1/184], Gradient of hidden_layers.0.weight: 2.2422698748414405e-05\n",
      "Epoch [48/50], Batch [1/184], Gradient of output_layer.weight: 9.359008254250512e-05\n",
      "Epoch [48/50], Batch [2/184], Gradient of input_bn.weight: 2.2534300114784855e-07\n",
      "Epoch [48/50], Batch [2/184], Gradient of input_bn.bias: 1.0951589501928538e-05\n",
      "Epoch [48/50], Batch [2/184], Gradient of hidden_bns.0.weight: -3.5353846215002704e-06\n",
      "Epoch [48/50], Batch [2/184], Gradient of hidden_bns.0.bias: -1.2898375643999316e-05\n",
      "Epoch [48/50], Batch [2/184], Gradient of input_layer.weight: -5.0514575633542336e-08\n",
      "Epoch [48/50], Batch [2/184], Gradient of hidden_layers.0.weight: 6.507983925985172e-06\n",
      "Epoch [48/50], Batch [2/184], Gradient of output_layer.weight: 8.50765936775133e-05\n",
      "Epoch [48/50], Batch [3/184], Gradient of input_bn.weight: 3.2377386105508776e-07\n",
      "Epoch [48/50], Batch [3/184], Gradient of input_bn.bias: 6.7078808569931425e-06\n",
      "Epoch [48/50], Batch [3/184], Gradient of hidden_bns.0.weight: -2.4741602828726172e-06\n",
      "Epoch [48/50], Batch [3/184], Gradient of hidden_bns.0.bias: -6.983293133089319e-06\n",
      "Epoch [48/50], Batch [3/184], Gradient of input_layer.weight: -3.596931463789588e-08\n",
      "Epoch [48/50], Batch [3/184], Gradient of hidden_layers.0.weight: 1.1099717085016891e-05\n",
      "Epoch [48/50], Batch [3/184], Gradient of output_layer.weight: 6.706124258926138e-05\n",
      "Epoch [48/50], Batch [101/184], Gradient of input_bn.weight: 5.896890797885135e-08\n",
      "Epoch [48/50], Batch [101/184], Gradient of input_bn.bias: 4.285247086954769e-06\n",
      "Epoch [48/50], Batch [101/184], Gradient of hidden_bns.0.weight: 2.0990985376556637e-06\n",
      "Epoch [48/50], Batch [101/184], Gradient of hidden_bns.0.bias: 1.5861289284657687e-05\n",
      "Epoch [48/50], Batch [101/184], Gradient of input_layer.weight: -8.73396555078898e-09\n",
      "Epoch [48/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.569852975080721e-05\n",
      "Epoch [48/50], Batch [101/184], Gradient of output_layer.weight: 4.105286643607542e-05\n",
      "Epoch [48/50], Batch [102/184], Gradient of input_bn.weight: 2.9439434001687914e-08\n",
      "Epoch [48/50], Batch [102/184], Gradient of input_bn.bias: 2.7266771667200373e-06\n",
      "Epoch [48/50], Batch [102/184], Gradient of hidden_bns.0.weight: 4.842315775022143e-07\n",
      "Epoch [48/50], Batch [102/184], Gradient of hidden_bns.0.bias: 8.39349831949221e-06\n",
      "Epoch [48/50], Batch [102/184], Gradient of input_layer.weight: -3.2071699962443745e-08\n",
      "Epoch [48/50], Batch [102/184], Gradient of hidden_layers.0.weight: 2.3388784029521048e-05\n",
      "Epoch [48/50], Batch [102/184], Gradient of output_layer.weight: 2.5876872314256616e-05\n",
      "Epoch [48/50], Batch [103/184], Gradient of input_bn.weight: 9.168888936983421e-08\n",
      "Epoch [48/50], Batch [103/184], Gradient of input_bn.bias: 4.753075700136833e-06\n",
      "Epoch [48/50], Batch [103/184], Gradient of hidden_bns.0.weight: 1.6066364878497552e-06\n",
      "Epoch [48/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.246849751623813e-05\n",
      "Epoch [48/50], Batch [103/184], Gradient of input_layer.weight: -1.287217887835368e-08\n",
      "Epoch [48/50], Batch [103/184], Gradient of hidden_layers.0.weight: 4.118409924558364e-05\n",
      "Epoch [48/50], Batch [103/184], Gradient of output_layer.weight: 3.503998595988378e-05\n",
      "Epoch [48/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████▍ | 48/50 [7:30:50<18:47, 563.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Epoch [49/50], Batch [1/184], Gradient of input_bn.weight: 2.3490883904742077e-07\n",
      "Epoch [49/50], Batch [1/184], Gradient of input_bn.bias: 7.15633041181718e-06\n",
      "Epoch [49/50], Batch [1/184], Gradient of hidden_bns.0.weight: -6.812336323491763e-06\n",
      "Epoch [49/50], Batch [1/184], Gradient of hidden_bns.0.bias: -4.684927625930868e-05\n",
      "Epoch [49/50], Batch [1/184], Gradient of input_layer.weight: 5.6615679255855866e-08\n",
      "Epoch [49/50], Batch [1/184], Gradient of hidden_layers.0.weight: -1.0200595170317683e-05\n",
      "Epoch [49/50], Batch [1/184], Gradient of output_layer.weight: 7.912825094535947e-05\n",
      "Epoch [49/50], Batch [2/184], Gradient of input_bn.weight: 1.5356317817349918e-07\n",
      "Epoch [49/50], Batch [2/184], Gradient of input_bn.bias: 4.034543508169008e-06\n",
      "Epoch [49/50], Batch [2/184], Gradient of hidden_bns.0.weight: -5.289507498673629e-09\n",
      "Epoch [49/50], Batch [2/184], Gradient of hidden_bns.0.bias: -7.917155016912147e-06\n",
      "Epoch [49/50], Batch [2/184], Gradient of input_layer.weight: -4.57022331090684e-09\n",
      "Epoch [49/50], Batch [2/184], Gradient of hidden_layers.0.weight: -7.097373327269452e-06\n",
      "Epoch [49/50], Batch [2/184], Gradient of output_layer.weight: 3.414848470129073e-05\n",
      "Epoch [49/50], Batch [3/184], Gradient of input_bn.weight: 3.824141003860859e-08\n",
      "Epoch [49/50], Batch [3/184], Gradient of input_bn.bias: 2.0384675281093223e-06\n",
      "Epoch [49/50], Batch [3/184], Gradient of hidden_bns.0.weight: -3.9357246350846253e-07\n",
      "Epoch [49/50], Batch [3/184], Gradient of hidden_bns.0.bias: 4.118571268918458e-06\n",
      "Epoch [49/50], Batch [3/184], Gradient of input_layer.weight: -1.2066388777043358e-08\n",
      "Epoch [49/50], Batch [3/184], Gradient of hidden_layers.0.weight: -6.161852525110589e-06\n",
      "Epoch [49/50], Batch [3/184], Gradient of output_layer.weight: 2.3432032321579754e-05\n",
      "Epoch [49/50], Batch [101/184], Gradient of input_bn.weight: 1.6136755220941268e-07\n",
      "Epoch [49/50], Batch [101/184], Gradient of input_bn.bias: 9.48872184380889e-06\n",
      "Epoch [49/50], Batch [101/184], Gradient of hidden_bns.0.weight: 1.2770055946020875e-06\n",
      "Epoch [49/50], Batch [101/184], Gradient of hidden_bns.0.bias: 2.342140578548424e-05\n",
      "Epoch [49/50], Batch [101/184], Gradient of input_layer.weight: -1.9960216590675373e-08\n",
      "Epoch [49/50], Batch [101/184], Gradient of hidden_layers.0.weight: 1.9607612557592802e-05\n",
      "Epoch [49/50], Batch [101/184], Gradient of output_layer.weight: 7.338105933740735e-05\n",
      "Epoch [49/50], Batch [102/184], Gradient of input_bn.weight: 1.5240289030771237e-09\n",
      "Epoch [49/50], Batch [102/184], Gradient of input_bn.bias: 1.1448143766301655e-07\n",
      "Epoch [49/50], Batch [102/184], Gradient of hidden_bns.0.weight: 3.6533634784063906e-08\n",
      "Epoch [49/50], Batch [102/184], Gradient of hidden_bns.0.bias: 3.9162577536444587e-07\n",
      "Epoch [49/50], Batch [102/184], Gradient of input_layer.weight: -1.0544951023483407e-10\n",
      "Epoch [49/50], Batch [102/184], Gradient of hidden_layers.0.weight: -6.200937718858768e-07\n",
      "Epoch [49/50], Batch [102/184], Gradient of output_layer.weight: 1.1717041843439802e-06\n",
      "Epoch [49/50], Batch [103/184], Gradient of input_bn.weight: 2.2135665744826838e-07\n",
      "Epoch [49/50], Batch [103/184], Gradient of input_bn.bias: 3.115673735010205e-06\n",
      "Epoch [49/50], Batch [103/184], Gradient of hidden_bns.0.weight: -1.0049329830508213e-06\n",
      "Epoch [49/50], Batch [103/184], Gradient of hidden_bns.0.bias: 1.8626089513418265e-05\n",
      "Epoch [49/50], Batch [103/184], Gradient of input_layer.weight: -2.013570821191024e-08\n",
      "Epoch [49/50], Batch [103/184], Gradient of hidden_layers.0.weight: 2.3709892502665753e-06\n",
      "Epoch [49/50], Batch [103/184], Gradient of output_layer.weight: 7.432328129652888e-05\n",
      "Epoch [49/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████▏| 49/50 [7:40:13<09:23, 563.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3293\n",
      "Epoch [50/50], Batch [1/184], Gradient of input_bn.weight: 3.0268893169704825e-08\n",
      "Epoch [50/50], Batch [1/184], Gradient of input_bn.bias: 3.837144504359458e-06\n",
      "Epoch [50/50], Batch [1/184], Gradient of hidden_bns.0.weight: -1.927667199197458e-07\n",
      "Epoch [50/50], Batch [1/184], Gradient of hidden_bns.0.bias: 1.3225001566752326e-05\n",
      "Epoch [50/50], Batch [1/184], Gradient of input_layer.weight: -1.3810705468131346e-08\n",
      "Epoch [50/50], Batch [1/184], Gradient of hidden_layers.0.weight: -2.9994362193974666e-05\n",
      "Epoch [50/50], Batch [1/184], Gradient of output_layer.weight: 4.059905404574238e-05\n",
      "Epoch [50/50], Batch [2/184], Gradient of input_bn.weight: 9.573386705596931e-08\n",
      "Epoch [50/50], Batch [2/184], Gradient of input_bn.bias: 3.623121529017226e-06\n",
      "Epoch [50/50], Batch [2/184], Gradient of hidden_bns.0.weight: 2.104438408423448e-06\n",
      "Epoch [50/50], Batch [2/184], Gradient of hidden_bns.0.bias: 1.4189294233801775e-05\n",
      "Epoch [50/50], Batch [2/184], Gradient of input_layer.weight: 1.7719072431532368e-08\n",
      "Epoch [50/50], Batch [2/184], Gradient of hidden_layers.0.weight: 1.9554874597815797e-05\n",
      "Epoch [50/50], Batch [2/184], Gradient of output_layer.weight: 4.445171725819819e-05\n",
      "Epoch [50/50], Batch [3/184], Gradient of input_bn.weight: 1.225807864102535e-07\n",
      "Epoch [50/50], Batch [3/184], Gradient of input_bn.bias: 5.1313554649823345e-06\n",
      "Epoch [50/50], Batch [3/184], Gradient of hidden_bns.0.weight: 4.349748905951856e-06\n",
      "Epoch [50/50], Batch [3/184], Gradient of hidden_bns.0.bias: 2.6948073355015367e-05\n",
      "Epoch [50/50], Batch [3/184], Gradient of input_layer.weight: 9.701607517342836e-09\n",
      "Epoch [50/50], Batch [3/184], Gradient of hidden_layers.0.weight: 3.357438981765881e-05\n",
      "Epoch [50/50], Batch [3/184], Gradient of output_layer.weight: 6.847288750577718e-05\n",
      "Epoch [50/50], Batch [101/184], Gradient of input_bn.weight: 1.1038582670153119e-07\n",
      "Epoch [50/50], Batch [101/184], Gradient of input_bn.bias: 5.4723523135180585e-06\n",
      "Epoch [50/50], Batch [101/184], Gradient of hidden_bns.0.weight: -2.8103286240366288e-06\n",
      "Epoch [50/50], Batch [101/184], Gradient of hidden_bns.0.bias: -3.1927766031003557e-06\n",
      "Epoch [50/50], Batch [101/184], Gradient of input_layer.weight: -3.369671475184077e-08\n",
      "Epoch [50/50], Batch [101/184], Gradient of hidden_layers.0.weight: 2.0248497094144113e-05\n",
      "Epoch [50/50], Batch [101/184], Gradient of output_layer.weight: 3.523359555401839e-05\n",
      "Epoch [50/50], Batch [102/184], Gradient of input_bn.weight: 1.3009139365749434e-07\n",
      "Epoch [50/50], Batch [102/184], Gradient of input_bn.bias: 3.274239134043455e-06\n",
      "Epoch [50/50], Batch [102/184], Gradient of hidden_bns.0.weight: -3.43148599313281e-07\n",
      "Epoch [50/50], Batch [102/184], Gradient of hidden_bns.0.bias: -1.1550257113412954e-05\n",
      "Epoch [50/50], Batch [102/184], Gradient of input_layer.weight: -1.2272362681642335e-08\n",
      "Epoch [50/50], Batch [102/184], Gradient of hidden_layers.0.weight: 5.056144800619222e-06\n",
      "Epoch [50/50], Batch [102/184], Gradient of output_layer.weight: 3.232889139326289e-05\n",
      "Epoch [50/50], Batch [103/184], Gradient of input_bn.weight: 6.89451553625986e-08\n",
      "Epoch [50/50], Batch [103/184], Gradient of input_bn.bias: 4.871948931395309e-06\n",
      "Epoch [50/50], Batch [103/184], Gradient of hidden_bns.0.weight: 6.585698884009616e-07\n",
      "Epoch [50/50], Batch [103/184], Gradient of hidden_bns.0.bias: 2.1449961423058994e-05\n",
      "Epoch [50/50], Batch [103/184], Gradient of input_layer.weight: -7.472034013744633e-08\n",
      "Epoch [50/50], Batch [103/184], Gradient of hidden_layers.0.weight: 4.2675554141169414e-05\n",
      "Epoch [50/50], Batch [103/184], Gradient of output_layer.weight: 6.548872624989599e-05\n",
      "Epoch [50/50], Loss: 0.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 50/50 [7:49:37<00:00, 563.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for batch_idx, (playlist_indices, track_indices) in enumerate(train_loader):\n",
    "        playlist_indices = playlist_indices.to(device)\n",
    "        track_indices = track_indices.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Obtain embeddings from the KGAT model\n",
    "        track_embeddings_shared_album = model(shared_album_adj_tensor, track_features)\n",
    "        track_embeddings_shared_artist = model(shared_artist_adj_tensor, track_features)\n",
    "        track_embeddings_shared_genre = model(shared_genre_adj_tensor, track_features)\n",
    "        track_embeddings_cosine_similarity = model(cosine_similarity_adj_tensor, track_features)\n",
    "\n",
    "        # Combine the embeddings from different relationships\n",
    "        track_embeddings = track_embeddings_shared_album + track_embeddings_shared_artist + track_embeddings_shared_genre + track_embeddings_cosine_similarity\n",
    "\n",
    "        # Compute the predicted probability of a track belonging to a playlist\n",
    "        predicted_probs = torch.sigmoid(torch.sum(track_embeddings[track_indices] * track_embeddings[playlist_indices], dim=1))\n",
    "\n",
    "        # Compute the ground truth for the current batch\n",
    "        ground_truth = torch.tensor([1.0] * len(track_indices), device=device)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_function(predicted_probs, ground_truth)\n",
    "\n",
    "        # Perform backpropagation and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        if ((count % 100) == 0) or ((count % 100) == 1) or ((count % 100) == 2):\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Gradient of {name}: {param.grad.mean()}')\n",
    "        count += 1\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Compute the average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for playlist_indices, track_indices in val_loader:\n",
    "            playlist_indices = playlist_indices.to(device)\n",
    "            track_indices = track_indices.to(device)\n",
    "\n",
    "            # Obtain embeddings from the KGAT model\n",
    "            track_embeddings_shared_album = model(shared_album_adj_tensor, track_features)\n",
    "            track_embeddings_shared_artist = model(shared_artist_adj_tensor, track_features)\n",
    "            track_embeddings_shared_genre = model(shared_genre_adj_tensor, track_features)\n",
    "            track_embeddings_cosine_similarity = model(cosine_similarity_adj_tensor, track_features)\n",
    "\n",
    "            # Combine the embeddings from different relationships\n",
    "            track_embeddings = track_embeddings_shared_album + track_embeddings_shared_artist + track_embeddings_shared_genre + track_embeddings_cosine_similarity\n",
    "\n",
    "            # Compute the predicted probability of a track belonging to a playlist\n",
    "            predicted_probs = torch.sigmoid(torch.sum(track_embeddings[track_indices] * track_embeddings[playlist_indices], dim=1))\n",
    "\n",
    "            # Compute the ground truth for the current batch\n",
    "            ground_truth = torch.tensor([1.0] * len(track_indices), device=device)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(predicted_probs, ground_truth)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Compute the average validation loss for this epoch\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Validation Loss: {avg_val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08488878-2bcb-46a6-86d4-f05e5a767162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_kgat_model_v100.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d7ca1d-0445-4fd0-8bef-1d5e8736a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "\n",
    "class KGATLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(KGATLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        #self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features) * 0.1)  # multiply by 0.1 to increase values\n",
    "        self.reset_parameters()\n",
    "\n",
    "#    def reset_parameters(self):\n",
    "#        gain = nn.init.calculate_gain('relu') * math.sqrt(3)\n",
    "#        nn.init.uniform_(self.weight, -10, 10)\n",
    "#        self.weight.data.mul_(gain)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        #print(self.weight)\n",
    "        #nn.Parameter(torch.randn(11, out_features) * 0.1)  # multiply by 0.1 to increase values\n",
    "        nn.init.kaiming_uniform_(self.weight, mode='fan_in', nonlinearity='relu')\n",
    "        #print(self.weight)\n",
    "\n",
    "    def forward(self, adjacency_matrix, input_features):\n",
    "        output_features = torch.mm(input_features, self.weight)\n",
    "        return torch.mm(adjacency_matrix, output_features)\n",
    "\n",
    "class KGAT(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_layers):\n",
    "        super(KGAT, self).__init__()\n",
    "        self.input_bn = nn.BatchNorm1d(hidden_features)\n",
    "        self.hidden_bns = nn.ModuleList([nn.BatchNorm1d(hidden_features) for _ in range(num_layers - 1)])\n",
    "        self.in_features = in_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.out_features = out_features\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the input layer\n",
    "        self.input_layer = KGATLayer(in_features, hidden_features)\n",
    "\n",
    "        # Define the hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.hidden_layers.append(KGATLayer(hidden_features, hidden_features))\n",
    "\n",
    "        # Define the output layer\n",
    "        self.output_layer = KGATLayer(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, adjacency_matrix, input_features):\n",
    "        x = self.input_layer(adjacency_matrix, input_features)\n",
    "        x = x.unsqueeze(2)  # Add an extra dimension for Batch Normalization\n",
    "        x = F.relu(self.input_bn(x))\n",
    "        x = x.squeeze(2)  # Remove the extra dimension\n",
    "        for i, layer in enumerate(self.hidden_layers):\n",
    "            x = layer(adjacency_matrix, x)\n",
    "            x = x.unsqueeze(2)  # Add an extra dimension for Batch Normalization\n",
    "            x = F.relu(self.hidden_bns[i](x))\n",
    "            x = x.squeeze(2)  # Remove the extra dimension\n",
    "\n",
    "        # Pass through the output layer\n",
    "        x = self.output_layer(adjacency_matrix, x)\n",
    "\n",
    "        return x        \n",
    "\n",
    "hidden_features = 64  # Number of hidden features in the KGAT model\n",
    "out_features = 1  # Number of output features in the KGAT model\n",
    "num_layers = 2  # Number of layers in the KGAT model\n",
    "\n",
    "numeric_keys = [\n",
    "    'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    "    'liveness', 'loudness', 'popularity', 'speechiness', 'tempo', 'valence'\n",
    "]\n",
    "\n",
    "model = KGAT(num_layers=num_layers, in_features=len(numeric_keys), hidden_features=hidden_features, out_features=out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad68c738-7911-4b97-9589-b221f6447983",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = KGAT(num_layers=num_layers, in_features=len(numeric_keys), hidden_features=hidden_features, out_features=out_features)\n",
    "loaded_model.load_state_dict(torch.load('trained_kgat_model_v100.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e0616d-ff3f-4bdf-87cd-18b0e2fc1fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# connect to MongoDB\n",
    "username = \"...\"\n",
    "password = \"...\"\n",
    "cluster_name = \"...\"\n",
    "dbname = \"...\"\n",
    "client = MongoClient(f\"mongodb+srv://{username}:{password}@{cluster_name}.mongodb.net/{dbname}?retryWrites=true&w=majority\")\n",
    "db = client[dbname]\n",
    "collection = db[\"tune-users\"]\n",
    "\n",
    "# define the query\n",
    "query = { \"user_id\": \"...\" }\n",
    "\n",
    "result = collection.find(query, { \"top_tracks\": 1, \"_id\": 0 })\n",
    "\n",
    "track_ids = []\n",
    "\n",
    "for document in result:\n",
    "    for track in document['top_tracks']:\n",
    "        track_ids.append(track['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118607dc-9169-496d-ac82-effe73528589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "required_features = [\n",
    "    't.acousticness', 't.danceability', 't.duration_ms', 't.energy', 't.explicit',\n",
    "    't.liveness', 't.loudness', 't.popularity', 't.speechiness', 't.tempo', 't.valence'\n",
    "]\n",
    "track_features = []\n",
    "for track in track_result:\n",
    "    x_features = [track[feature] for feature in required_features]\n",
    "    track_features.append(x_features)\n",
    "track_features_tensor = torch.FloatTensor(track_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ba5fc4f-f6d9-4366-9016-50639918ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_adj_tensor = torch.FloatTensor(cosine_similarity_adj.toarray())\n",
    "def get_ranked_recommendations(user_songs, model, unique_track_ids, track_features):\n",
    "    # Move the model to the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create an input tensor containing user's input songs' features\n",
    "    user_song_indices = [unique_track_ids.index(track_id) for track_id in user_songs if track_id in unique_track_ids]\n",
    "    user_song_features = track_features[user_song_indices]\n",
    "\n",
    "    # Calculate the embeddings of the user's input songs using the trained model\n",
    "    user_song_embeddings = model(cosine_similarity_adj_tensor[:len(user_song_indices), :len(user_song_indices)], user_song_features)\n",
    "    user_song_embeddings += model(shared_album_adj_tensor[:len(user_song_indices), :len(user_song_indices)], user_song_features)\n",
    "    user_song_embeddings += model(shared_artist_adj_tensor[:len(user_song_indices), :len(user_song_indices)], user_song_features)\n",
    "    user_song_embeddings += model(shared_genre_adj_tensor[:len(user_song_indices), :len(user_song_indices)], user_song_features)\n",
    "    \n",
    "    # Calculate the average of the input songs' embeddings\n",
    "    avg_embedding = torch.mean(user_song_embeddings, dim=0, keepdim=True)\n",
    "\n",
    "    # Calculate the similarity score between the average embedding and all tracks in the dataset\n",
    "    similarity_scores = torch.mm(track_embeddings, avg_embedding.t()).squeeze()\n",
    "\n",
    "    # Sort similarity scores in descending order and get the corresponding indices\n",
    "    sorted_indices = torch.argsort(similarity_scores, descending=True)\n",
    "\n",
    "    # Convert the sorted indices to track IDs\n",
    "    ranked_track_ids = [unique_track_ids[idx] for idx in sorted_indices.tolist()]\n",
    "\n",
    "    # Remove the user's input songs from the ranked recommendations\n",
    "    recommendations = [track_id for track_id in ranked_track_ids if track_id not in user_songs]\n",
    "\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f17a703e-1ba7-4af8-9d85-0c384c22b1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert adjacency matrices to PyTorch tensors\n",
    "shared_album_adj_tensor = torch.FloatTensor(shared_album_adj.toarray())\n",
    "shared_artist_adj_tensor = torch.FloatTensor(shared_artist_adj.toarray())\n",
    "shared_genre_adj_tensor = torch.FloatTensor(shared_genre_adj.toarray())\n",
    "cosine_similarity_adj_tensor = torch.FloatTensor(cosine_similarity_adj.toarray())\n",
    "\n",
    "# Obtain embeddings from the KGAT model\n",
    "track_embeddings_shared_album = model(shared_album_adj_tensor, track_features_tensor)\n",
    "track_embeddings_shared_artist = model(shared_artist_adj_tensor, track_features_tensor)\n",
    "track_embeddings_shared_genre = model(shared_genre_adj_tensor, track_features_tensor)\n",
    "track_embeddings_cosine_similarity = model(cosine_similarity_adj_tensor, track_features_tensor)\n",
    "\n",
    "# Combine the embeddings from different relationships\n",
    "track_embeddings = track_embeddings_shared_album + track_embeddings_shared_artist + track_embeddings_shared_genre + track_embeddings_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d00c21d-7adb-4fc5-9bbc-5031e10e6504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recommendations = get_ranked_recommendations(track_ids, model, unique_track_ids, track_features_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29c62dfb-c856-435e-8faf-1fb57433f717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1yRl361oS9xXUIDN3GF7pd',\n",
       " '19dSGEa2qpyGM60nxoLv3q',\n",
       " '2qywCWdMFK2ew9ALHA4UfD',\n",
       " '4lIIOHPXeh74fbPUV74zRn',\n",
       " '7pN1FnWdKOx3GAciqfVVf7',\n",
       " '1Eq8p4OHjhVrSW0Wa815B1',\n",
       " '1Q5cjSmt4WTJyJ0EgAFfgg',\n",
       " '4o4nIPbrEAoCAq3zqWVA4E',\n",
       " '3msjyQTZr7gHspgJCzl4v5',\n",
       " '1HW3I6KUzjYPEMqZrlFN66',\n",
       " '20uX9Nz9dJBKD7MstFDFs0',\n",
       " '1ah3n5wpOQhFQzl9t3qGIu',\n",
       " '0gIsM9tn5pP1jnTSrkdHCL',\n",
       " '7f32ap55N5PhZBMEr8TnKV',\n",
       " '6rOVIb2PyUMBw8b6hUdxHj',\n",
       " '2eh3gUtf5GwwlEHPQOgTmV',\n",
       " '0OdX5KLktgTp3FAmUqWvLt',\n",
       " '2AYtjqogao6Fj3N7cx39Of',\n",
       " '0xuvCPMUrbr6xk3myTCqwF',\n",
       " '59YiIzi4C1KJwClBBRFucR',\n",
       " '4nwwj1bE8KHaBixtEtMu4d',\n",
       " '4uew5SER845c4iNj4sl8jG',\n",
       " '5deBKQ6qZaTHBRtRNZtL9X',\n",
       " '22sdeHdy5DcCVV7dJw4uRn',\n",
       " '5gAPTm517kIXqq9YUBLehU',\n",
       " '5O71be8zUY85FRBQJsQRWd',\n",
       " '2k4O9OqM4RmuGwOgrU272J',\n",
       " '4VRcCHaxMHugywsyc33xZa',\n",
       " '6JvK5IGgZ1rmenDKHufzIx',\n",
       " '0hESC8513XQKkf82EMXpiI',\n",
       " '2gc6W4zP2EYcimOCg0tg2v',\n",
       " '5eYO9lIshL5wbYDO0WWbbX',\n",
       " '2eIAizioh2hRmYRagndFb8',\n",
       " '4VfdRKABHsrA0ii7wGDjJm',\n",
       " '7uiJYByjnDGY8Z1sAsCSFC',\n",
       " '17uRlIf3SeM3VMptNbsZtP',\n",
       " '37oH03cQRwoyBUTyGDyixV',\n",
       " '5YNRlxmyLhNXsnLxkFhNZl',\n",
       " '584uhCy1HBOfCsAZEOz2xV',\n",
       " '24zhvGk1ygakcFQGV02xjN',\n",
       " '1mfBNwsoJ0y5EQjg3FDjQH',\n",
       " '7aJLyJIV2J9fxVIDXqQtE2',\n",
       " '1nmYzBfCvC1TD1FzUVt7XE',\n",
       " '5SFge5DNOcLvCGwfyJs0pT',\n",
       " '7rie7xDWKxfJGvvIXHXGJc',\n",
       " '2t7gnqkfT7UUohV1rgpNoT',\n",
       " '7q4YqM7hNcf6IS0T5aSvCT',\n",
       " '2GepxyLRRB3A1CEytSVn3E',\n",
       " '6gYnDmTiLa2AHH0VjrC4uc',\n",
       " '1EHIpqrauZPi65SDE9eTeL']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ec113c-db08-4b95-8d5a-0a26e3df5d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track name: Euryanthe, J. 291: Overture\n",
      "Artist(s): Carl Maria von Weber, Tapiola Sinfonietta, Jean-Jacques Kantorow\n",
      "\n",
      "Track name: Der Freischütz, J. 277 / Act III: \"Und ob die Wolke sie verhülle\"\n",
      "Artist(s): Carl Maria von Weber, Gundula Janowitz, Staatskapelle Dresden, Carlos Kleiber\n",
      "\n",
      "Track name: St Matthew Passion: Iii. Psalm\n",
      "Artist(s): Bent Sørensen, The Norwegian Soloists' Choir, Grete Pedersen, Ensemble Allegria\n",
      "\n",
      "Track name: Drei Romanzen, Op. 94: III. Nicht schnell\n",
      "Artist(s): Robert Schumann, Kim Dami\n",
      "\n",
      "Track name: Les berceaux, Op. 23, No. 1\n",
      "Artist(s): Gabriel Fauré, Mischa Maisky, Daria Hovora\n",
      "\n",
      "Track name: Les Pêcheurs de perles: Je crois entendre encore (Nadir)\n",
      "Artist(s): Georges Bizet, Nicolai Gedda, Pierre Dervaux, Orchestre du Theatre National de IOpera-Comique, Orchestre Du Theatre National De L'opera-comique\n",
      "\n",
      "Track name: Il Signor Bruschino: No. 1: Introduzione - Deh tu m’assisti amore\n",
      "Artist(s): Gioachino Rossini, Massimiliano Barbolini, Alessandro Codeluppi, Clara Giangaspero, Dario Giorgele, Maurizio Leoni, Antonio Marani, Vito Martino, Elena Rossi, I Virtuosi Italiani, Claudio Desderi\n",
      "\n",
      "Track name: Ach, dass ich Wassers gnug hätte (Excerpt) (Arr. for Baroque Ensemble by Holland Baroque Society and Eric Vloeimans)\n",
      "Artist(s): Johann Christoph Bach, Holland Baroque Society, Eric Vloeimans\n",
      "\n",
      "Track name: Chant Lithurgique (Paix Avec Nous)\n",
      "Artist(s): Ensemble des chants et choeurs russes orthodoxes\n",
      "\n",
      "Track name: Elgar: Salut d' Amour, Op. 12\n",
      "Artist(s): Edward Elgar, Min Kym\n",
      "\n",
      "Track name: Der Tag, mein Gott, ist nun vergangen\n",
      "Artist(s): Coro parrocchiale di S. Cristina\n",
      "\n",
      "Track name: Adoration (Version for Solo Violin and String Orchestra)\n",
      "Artist(s): Florence Beatrice Price, Daniel Hope, Zürcher Kammerorchester\n",
      "\n",
      "Track name: Verleih uns Frieden gnädiglich, WoO 5\n",
      "Artist(s): Felix Mendelssohn, György Bognár, Reinhard Werner, Deutsche Kammerphilharmonie Bremen, Stuttgart Chamber Orchestra, Kammerchor Stuttgart, Frieder Bernius\n",
      "\n",
      "Track name: Summer Love\n",
      "Artist(s): Felicia Sanders\n",
      "\n",
      "Track name: Spartacus: Adagio of Spartacus and Phrygia\n",
      "Artist(s): Aram Khachaturian, Mariinsky Orchestra, Valery Gergiev\n",
      "\n",
      "Track name: Piano Quintet in F-Sharp Minor, Op. 67: II. Adagio espressivo\n",
      "Artist(s): Amy Beach, Ambache\n",
      "\n",
      "Track name: Elegie in C, Chant pour violon avec piano Op. 10, No. 3: Adagio melancolio ed appassionato\n",
      "Artist(s): Heinrich Wilhelm Ernst, Ingolf Turban, Giovanni Bria\n",
      "\n",
      "Track name: Castor et Pollux: Acte I, scène 3 - Air de Télaïre: Tristes apprêts\n",
      "Artist(s): Jean-Philippe Rameau, Véronique Gens, Christophe Rousset, Les Talens Lyriques\n",
      "\n",
      "Track name: Lux aeterna: V. Agnus Dei - Lux Aeterna\n",
      "Artist(s): Morten Lauridsen, Chamber Choir Of Europe, I Virtuosi Italiani, Nicol Matt\n",
      "\n",
      "Track name: Symphonie fantastique, Op. 14: II. Un bal\n",
      "Artist(s): Hector Berlioz, Swedish Radio Symphony Orchestra, Daniel Harding\n",
      "\n",
      "Track name: Polovtsian Dances and Chorus\n",
      "Artist(s): Alexander Borodin, London Symphony Chorus, London Symphony Orchestra, Sir Georg Solti\n",
      "\n",
      "Track name: Elegie, Op. 24\n",
      "Artist(s): Gabriel Fauré, Maria Kliegel, Nina Tichman\n",
      "\n",
      "Track name: The Golden Cockerel (Suite): I. Tsar Dodon In His Palace (Arr. by Glazunov & Steinberg)\n",
      "Artist(s): Nikolai Rimsky-Korsakov, Orchestre Lamoureux, Igor Markevitch\n",
      "\n",
      "Track name: Concerto for Trombone and Orchestra: II. Lento, ben ritmato\n",
      "Artist(s): Nino Rota, Marzio Conti, I Virtuosi Italiani, Andrea Conti\n",
      "\n",
      "Track name: Petite messe solennelle: XVI. Sanctus\n",
      "Artist(s): Gioachino Rossini, Krassimira Stoyanova, Philip Mayers, Philip Moll, Ryoko Morooka, Birgit Remmert, Steve Davislim, Hanno Müller-Brachmann, RIAS Kammerchor, Marcus Creed\n",
      "\n",
      "Track name: Size of My Hero\n",
      "Artist(s): Alberto Moggi, Giuseppe Brittanni, Metasymphony, Geraldine Starling\n",
      "\n",
      "Track name: Messa Arcaica: Sanctus\n",
      "Artist(s): Franco Battiato, Akemi Sakamoto, Athestis Chorus Di Padova, Filippo Destrieri, I Virtuosi Italiani, Antonio Ballista\n",
      "\n",
      "Track name: String Sextet No. 1 in B flat major, Op. 18: Andante ma moderato\n",
      "Artist(s): Johannes Brahms, Nash Ensemble\n",
      "\n",
      "Track name: Ode for Saint Cecilia's Day, HWV76: \"What Passion Cannot Music Raise and Quell\"\n",
      "Artist(s): George Frideric Handel, Cecilia Bartoli, Sol Gabetta, Cappella Gabetta, Andrés Gabetta\n",
      "\n",
      "Track name: Vaughan Williams: Job, a Masque for Dancing, Scene 3: Minuet of the Sons of Job and Their Wives\n",
      "Artist(s): Ralph Vaughan Williams, Richard Hickox, Bournemouth Symphony Orchestra\n",
      "\n",
      "Track name: Violin Sonata in A Major, FWV 8: III. Recitativo - Fantasia (Ben moderato)\n",
      "Artist(s): César Franck, Renaud Capuçon, Martha Argerich\n",
      "\n",
      "Track name: Footprints\n",
      "Artist(s): James Wilson, Hyeyoon Park, Benjamin Grosvenor\n",
      "\n",
      "Track name: Rinaldo, HWV 7a: Lascia ch'io pianga\n",
      "Artist(s): George Frideric Handel, Sandrine Piau, Europa Galante, Fabio Biondi\n",
      "\n",
      "Track name: Cantique de Jean Racine, Op. 11\n",
      "Artist(s): Gabriel Fauré, Netherlands Chamber Choir, Limburg Symphony Orchestra, Ed Spanjaard\n",
      "\n",
      "Track name: Sonata For Violin & Piano No. 1 in G Major, Op. 78: I. Vivace ma non troppo\n",
      "Artist(s): Johannes Brahms, Augustin Dumay, Maria João Pires\n",
      "\n",
      "Track name: Sinfonia in E major, RV 132: II. Andante\n",
      "Artist(s): Karoly Botvay\n",
      "\n",
      "Track name: Moonlight Waves\n",
      "Artist(s): Chester Tan\n",
      "\n",
      "Track name: Lux aeterna: I. Introitus\n",
      "Artist(s): Morten Lauridsen, Chamber Choir Of Europe, I Virtuosi Italiani, Nicol Matt\n",
      "\n",
      "Track name: Tu solus qui facis mirabilia\n",
      "Artist(s): Josquin des Prez, The Hilliard Ensemble, Paul Hillier\n",
      "\n",
      "Track name: Variations on an Original Theme, Op. 36 \"Enigma\": 1. C.A.E. (L'istesso tempo)\n",
      "Artist(s): Edward Elgar, BBC Symphony Orchestra, Leonard Bernstein\n",
      "\n",
      "Track name: 21 Hungarian Dances, WoO 1: Hungarian Dance No. 11 in D Minor\n",
      "Artist(s): Seattle Symphony Orchestra, Johannes Brahms, Gerard Schwarz\n",
      "\n",
      "Track name: 21 Hungarian Dances, WoO 1: Hungarian Dance No. 16 in F Minor\n",
      "Artist(s): Seattle Symphony Orchestra, Johannes Brahms, Gerard Schwarz\n",
      "\n",
      "Track name: Symphony No. 3 in F Major, Op. 90: III. Poco allegretto\n",
      "Artist(s): Johannes Brahms, Gewandhausorchester, Riccardo Chailly\n",
      "\n",
      "Track name: Stabat Mater, P. 77: III. O quam tristis\n",
      "Artist(s): Giovanni Battista Pergolesi, Margaret Marshall, Lucia Valentini Terrani, London Symphony Orchestra, Claudio Abbado, Leslie Pearson\n",
      "\n",
      "Track name: The Winding Path\n",
      "Artist(s): Bernward Koch\n",
      "\n",
      "Track name: Lakmé / Act 1: Viens, Mallika, ... Dôme épais (Flower Duet) - Excerpt\n",
      "Artist(s): Léo Delibes, Anna Netrebko, Elina Garanca, SWR Symphony Orchestra, Marco Armiliato\n",
      "\n",
      "Track name: Concerto Grosso in G Minor, Op. 6, No. 8, \"Fatto per la Notte di Natale\": III. Adagio - Allegro - Adagio\n",
      "Artist(s): Arcangelo Corelli, Orpheus Chamber Orchestra, Naoko Tanaka, Eric Wyrick, Eric Bartlett, Edward Brewer\n",
      "\n",
      "Track name: Jellyfish in Paradise\n",
      "Artist(s): Shawn Bruce\n",
      "\n",
      "Track name: Tristan und Isolde, WWV 90 / Act II: O sink hernieder, Nacht der Liebe\n",
      "Artist(s): Richard Wagner, Jessye Norman, Thomas Moser, Gewandhausorchester, Kurt Masur\n",
      "\n",
      "Track name: Erbarm dich mein, o Herre Gott, SWV 148\n",
      "Artist(s): Heinrich Schütz, Bremen Weser-Renaissance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id='...', client_secret=\"...\")\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "def get_track_info(track_id):\n",
    "    track_info = sp.track(track_id)\n",
    "    track_name = track_info['name']\n",
    "    artist_info = track_info['artists']\n",
    "    artist_names = [artist['name'] for artist in artist_info]\n",
    "    return track_name, artist_names\n",
    "\n",
    "for track_id in recommendations[:50]:\n",
    "    track_name, artist_names = get_track_info(track_id)\n",
    "    print(f'Track name: {track_name}')\n",
    "    print(f'Artist(s): {\", \".join(artist_names)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa85ebf-aba9-4cac-a4e8-99b3500dde0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f6600-42f2-4049-b594-b067f38d9382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
